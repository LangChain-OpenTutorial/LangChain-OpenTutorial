{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation\n",
    "\n",
    "- Author: [Wonyoung Lee](https://github.com/BaBetterB)\n",
    "- Peer Review: \n",
    "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/BaBetterB/LangChain-OpenTutorial/blob/main/15-Agent/05-Iteration-HumanInTheLoop.ipynb)\n",
    "[![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/07-TextSplitter/04-SemanticChunker.ipynb)\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial compares two approaches to translating Chinese text into English using LangChain.\n",
    "\n",
    "The first approach utilizes a single LLM (e.g. GPT-4) to generate a straightforward translation. The second approach employs Retrieval-Augmented Generation (RAG), which enhances translation accuracy by retrieving relevant documents.\n",
    "\n",
    "The tutorial evaluates the translation accuracy and performance of each method, helping users choose the most suitable approach for their needs.\n",
    "\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [Overview](#overview)\n",
    "- [Environement Setup](#environment-setup)\n",
    "- [Translation using LLM](#translation-using-llm)\n",
    "- [Translation using RAG](#translation-using-rag)\n",
    "- [Evaluation of translation results](#evaluation-of-translation-resultsr)\n",
    "\n",
    "\n",
    "### References\n",
    "\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
    "\n",
    "**[Note]**\n",
    "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
    "- You can checkout the [ `langchain-opentutorial` ](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load sample text and output the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain-opentutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "from langchain_opentutorial import package\n",
    "\n",
    "\n",
    "package.install(\n",
    "    [\n",
    "        \"langsmith\",\n",
    "        \"langchain\",\n",
    "        \"langchain_core\",\n",
    "        \"langchain_community\",\n",
    "        \"load_dotenv\",\n",
    "        \"langchain_openai\",\n",
    "        \"transformers\",\n",
    "        \"faiss-cpu\",\n",
    "        \"sentence_transformers\",\n",
    "        \"sacrebleu\",\n",
    "        \"unbabel-comet\",\n",
    "        \"load_from_checkpoint\",\n",
    "    ],\n",
    "    verbose=False,\n",
    "    upgrade=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been set successfully.\n"
     ]
    }
   ],
   "source": [
    "# Set environment variables\n",
    "from langchain_opentutorial import set_env\n",
    "\n",
    "set_env(\n",
    "    {\n",
    "        \"OPENAI_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
    "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
    "        \"LANGCHAIN_PROJECT\": \"Translation\",  # title\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can alternatively set `OPENAI_API_KEY` in `.env` file and load it.\n",
    "\n",
    "[Note] This is not necessary if you've already set `OPENAI_API_KEY` in previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuration File for Managing API Keys as Environment Variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API Key Information\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation using LLM\n",
    "\n",
    "Translation using LLM refers to using a large language model (LLM), such as GPT-4, to translate text from one language to another. \n",
    "The model processes the input text and generates a direct translation based on its pre-trained knowledge. This approach is simple, fast, and effective.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chinese_text: 人工智能正在改变世界，各国都在加紧研究如何利用这一技术提高生产力。\n",
      "Translation: Artificial intelligence is transforming the world, and countries are intensifying their research on how to leverage this technology to enhance productivity.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableSequence\n",
    "\n",
    "# Create LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# Create PromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a professional translator.\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Please translate the following Chinese document into natural and accurate English.\"\n",
    "            \"Consider the context and vocabulary to ensure smooth and fluent sentences.:.\\n\\n\"\n",
    "            \"**Chinese Original Text:** {chinese_text}\\n\\n**English Translation:**\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "translation_chain = RunnableSequence(prompt, llm)\n",
    "\n",
    "chinese_text = \"人工智能正在改变世界，各国都在加紧研究如何利用这一技术提高生产力。\"\n",
    "\n",
    "response = translation_chain.invoke({\"chinese_text\": chinese_text})\n",
    "\n",
    "print(\"Chinese_text:\", chinese_text)\n",
    "print(\"Translation:\", response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation using RAG \n",
    "\n",
    "Translation using RAG (Retrieval-Augmented Generation) enhances translation accuracy by combining a pre-trained LLM with a retrieval mechanism. It first retrieves relevant documents or data related to the input text, then uses this additional context to generate a more precise and contextually accurate translation. This approach is particularly useful for technical terms, specialized content, or context-sensitive translations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Search Implementation Using FAISS\n",
    "\n",
    "FAISS (Facebook AI Similarity Search) is a library developed by Facebook AI for efficient similarity search and clustering of dense vectors. It is widely used for approximate nearest neighbor (ANN) search in large-scale datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search result\n",
      "1. 当地球员并非专业人士，而是农民、建筑工人、教师和学生，对足球的热爱将他们凝聚在一起\n",
      "2. ”卡卡说道\n",
      "3. “足球让我们结识新朋友，连接更广阔的世界\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "file_path = \"data/news_cn.txt\"\n",
    "if not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(f\"file not found!!: {file_path}\")\n",
    "\n",
    "loader = TextLoader(file_path, encoding=\"utf-8\")\n",
    "docs = loader.load()\n",
    "\n",
    "\n",
    "# Vectorizing Sentences Individually\n",
    "sentences = []\n",
    "for doc in docs:\n",
    "    text = doc.page_content\n",
    "    sentence_list = text.split(\"。\")  # Splitting Chinese sentences based on '.'\n",
    "    sentences.extend(\n",
    "        [sentence.strip() for sentence in sentence_list if sentence.strip()]\n",
    "    )\n",
    "\n",
    "\n",
    "# Store sentences in the FAISS vector database\n",
    "vector_store = FAISS.from_texts(sentences, embedding=embeddings)\n",
    "\n",
    "# Search vectors using keywords \"人工智能\"\n",
    "search_results = vector_store.similarity_search(\"人工智能\", k=3)\n",
    "\n",
    "# check result\n",
    "print(\"Search result\")\n",
    "for idx, result in enumerate(search_results, start=1):\n",
    "    print(f\"{idx}. {result.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's compare translation using LLM and translation using RAG.\n",
    "\n",
    "First, write the necessary functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "\n",
    "# Document Search Function (Used in RAG)\n",
    "def retrieve_relevant_docs(query, vector_store, k=3):\n",
    "    # Perform search and return relevant documents\n",
    "    search_results = vector_store.similarity_search(query, k=k)\n",
    "    return [doc.page_content for doc in search_results]\n",
    "\n",
    "\n",
    "# Translation using only LLM\n",
    "def translate_with_llm(chinese_text):\n",
    "    prompt_template_llm = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are a translation expert. Translate the following Chinese sentence into English:\",\n",
    "            ),\n",
    "            (\"user\", f'Chinese sentence: \"{chinese_text}\"'),\n",
    "            (\"user\", \"Please provide an accurate translation.\"),\n",
    "        ]\n",
    "    )\n",
    "    # translation_chain_llm = LLMChain(prompt=prompt_template_llm, llm=llm)\n",
    "    translation_chain_llm = RunnableSequence(prompt_template_llm, llm)\n",
    "    return translation_chain_llm.invoke({\"chinese_text\": chinese_text})\n",
    "\n",
    "\n",
    "# RAG-based Translation\n",
    "def translate_with_rag(chinese_text, vector_store):\n",
    "    retrieved_docs = retrieve_relevant_docs(chinese_text, vector_store)\n",
    "\n",
    "    # Add retrieved documents as context\n",
    "    context = \"\\n\".join(retrieved_docs)\n",
    "\n",
    "    # Construct prompt template (Using RAG)\n",
    "    prompt_template_rag = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are a translation expert. Below is the Chinese text that needs to be translated into English. Additionally, the following context has been provided from relevant documents that might help you in producing a more accurate and context-aware translation.\",\n",
    "            ),\n",
    "            (\"system\", f\"Context (Relevant Documents):\\n{context}\"),\n",
    "            (\"user\", f'Chinese sentence: \"{chinese_text}\"'),\n",
    "            (\n",
    "                \"user\",\n",
    "                \"Please provide a translation that is both accurate and reflects the context from the documents provided.\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    translation_chain_rag = RunnableSequence(prompt_template_rag, llm)\n",
    "\n",
    "    # Request translation using RAG\n",
    "    return translation_chain_rag.invoke({\"chinese_text\": chinese_text})\n",
    "\n",
    "\n",
    "# Function to store document text as a list\n",
    "def chinese_text_from_file_loader(path):\n",
    "    # Load data\n",
    "    loader = TextLoader(path, encoding=\"utf-8\")\n",
    "    docs = loader.load()\n",
    "\n",
    "    # Retrieve the page_content of the first document from docs and embed it\n",
    "    text = docs[0].page_content\n",
    "\n",
    "    # Vectorize sentences individually\n",
    "    sentences = []\n",
    "    for doc in docs:\n",
    "\n",
    "        text = docs[0].page_content\n",
    "        sentence_list = text.split(\n",
    "            \"。\"\n",
    "        )  # In Chinese, sentences are usually separated by '。'\n",
    "        sentences.extend(\n",
    "            [sentence.strip() for sentence in sentence_list if sentence.strip()]\n",
    "        )\n",
    "\n",
    "    print(len(sentences))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use the written functions to perform the comparison.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "当前，我国中医药领域高水平科技创新平台加速集聚2025年1月9日在北京举行的全国中医药科技工作会议上的数据显示，我国不断深化中医药科技创新体系建设，中医药科技创新成果接连涌现目前，已基本构建起覆盖“国家—行业—地方”三级中医药科技创新平台体系，各省级平台建设数量超过1200个中医药领域已有7个全国重点实验室、5个国家工程研究中心、4个国家医学攻关产教融合创新平台获批建设，46个国家中医药传承创新中心建设正在推进地方研究平台、科研院所建设力度加大，中医药广东省实验室、湖北时珍实验室、河南省中医药科学院等一批省级新型科研平台相继组建据介绍，我国对中医药原创理论的科学阐释与认识进一步深化，在研究上取得一批重要成果在心脑血管、代谢、消化等多个疾病领域，中医临床评价研究取得重要进展2023年以来，基于循证证据和大量临床实践，遴选发布了50个中医治疗优势病种、52个中西医结合诊疗方案、100项适宜技术、100个疗效独特的中药品种中药资源保护和创新研发也有不少新进展据介绍，我国建立了28个中药材种子种苗繁育基地，120多种大宗或道地药材实现规范化种植，100余种中药材开展生态种植2021年以来，43个中药新药获批上市，包括19个古代经典名方中药复方制剂，中药新药研发进程明显加快\n",
      "\n",
      "LLM\n",
      "Currently, high-level technological innovation platforms in the field of traditional Chinese medicine (TCM) in our country are accelerating their gathering. Data from the National TCM Science and Technology Work Conference held on January 9, 2025, in Beijing shows that our country is continuously deepening the construction of the TCM technological innovation system, with TCM technological innovation achievements emerging in succession. At present, a three-tiered TCM technological innovation platform system covering \"national - industry - local\" has basically been established, with the number of provincial-level platform constructions exceeding 1,200. In the field of TCM, seven national key laboratories, five national engineering research centers, and four national medical innovation platforms integrating industry and education have been approved for construction, and the construction of 46 national TCM inheritance and innovation centers is underway. \n",
      "\n",
      "The construction of local research platforms and research institutes has increased, with a number of new provincial-level research platforms such as the Guangdong Provincial Laboratory of TCM, Hubei Shizhen Laboratory, and Henan Provincial Academy of TCM being established successively. It is reported that our country's scientific interpretation and understanding of the original theories of TCM have further deepened, achieving a number of important results in research across various disease fields including cardiovascular, metabolic, and digestive diseases. Significant progress has been made in clinical evaluation research of TCM. Since 2023, based on evidence and a large amount of clinical practice, 50 advantageous diseases treated by TCM, 52 integrated TCM and Western medicine treatment plans, 100 appropriate technologies, and 100 uniquely effective Chinese medicinal varieties have been selected and released. \n",
      "\n",
      "There have also been several new advancements in the protection and innovative research and development of Chinese medicinal resources. It is reported that our country has established 28 seed and seedling breeding bases for Chinese medicinal materials, with standardized planting achieved for over 120 varieties of commonly used or authentic medicinal materials, and ecological planting being conducted for over 100 varieties of Chinese medicinal materials. Since 2021, 43 new Chinese medicinal drugs have been approved for market release, including 19 ancient classic prescriptions and compound formulations, and the research and development process for new Chinese medicinal drugs has significantly accelerated.\n",
      "\n",
      "RAG\n",
      "Currently, high-level technological innovation platforms in the field of traditional Chinese medicine (TCM) in our country are accelerating their aggregation. Data from the National TCM Science and Technology Work Conference held on January 9, 2025, in Beijing shows that our country is continuously deepening the construction of the TCM technological innovation system, with a steady stream of innovative achievements emerging. We have basically established a three-tier TCM technological innovation platform system covering \"national - industry - local\" levels, with the number of provincial-level platforms exceeding 1,200.\n",
      "\n",
      "In the TCM field, seven national key laboratories, five national engineering research centers, and four national medicine innovation platforms integrating production and education have been approved for construction. Furthermore, the construction of 46 national TCM inheritance and innovation centers is underway. The strength of local research platforms and research institutions has been significantly increased, with several new provincial-level research platforms such as the Guangdong Provincial TCM Laboratory, Hubei Shizhen Laboratory, and the Henan Provincial Academy of Traditional Chinese Medicine being established one after another.\n",
      "\n",
      "It is reported that our country has deepened the scientific interpretation and understanding of original TCM theories, achieving a number of important results in research across various disease areas, including cardiovascular diseases, metabolic disorders, and digestive issues. Important progress has been made in clinical evaluation research of TCM. Since 2023, based on evidence from clinical practices, 50 advantageous disease categories for TCM treatment, 52 integrated TCM and Western medicine treatment plans, 100 appropriate technologies, and 100 uniquely effective TCM herbal varieties have been selected and published.\n",
      "\n",
      "There have also been significant advances in the protection and innovative research and development of TCM resources. Our country has established 28 seed breeding bases for medicinal materials, with standardized cultivation achieved for over 120 commonly used or authentic medicinal materials and ecological cultivation initiated for more than 100 types of medicinal herbs. Since 2021, 43 new TCM drugs have been approved for market launch, including 19 formulations of ancient classic prescriptions, with the pace of new TCM drug development significantly accelerated.\n"
     ]
    }
   ],
   "source": [
    "sentences = chinese_text_from_file_loader(\"data/comparison_cn.txt\")\n",
    "chinese_text = \"\"\n",
    "\n",
    "for sentence in sentences:\n",
    "    chinese_text += sentence\n",
    "\n",
    "# LLM\n",
    "llm_translation = translate_with_llm(chinese_text)\n",
    "\n",
    "# RAG\n",
    "rag_translation = translate_with_rag(chinese_text, vector_store)\n",
    "\n",
    "\n",
    "print(chinese_text)\n",
    "\n",
    "print(\"\\nLLM\")\n",
    "\n",
    "print(llm_translation.content)\n",
    "\n",
    "print(\"\\nRAG\")\n",
    "print(rag_translation.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of translation results\n",
    "\n",
    "Evaluation of translation results using BLEU and TER scores.\n",
    "Considering the addition of COMET and GPT for further assessment.\n",
    "Aiming to improve accuracy and quality in translation evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📌 **Translation Quality Evaluation (BLEU & TER Scores)**\n",
      "\n",
      "╒════╤═══════════════╤════════════════════════════════════════════════╤════════╤═══════╕\n",
      "│    │ Category      │ Text                                           │ BLEU   │ TER   │\n",
      "╞════╪═══════════════╪════════════════════════════════════════════════╪════════╪═══════╡\n",
      "│  0 │ Source Text   │ 这个产品在市场上很受欢迎。                     │ -      │ -     │\n",
      "├────┼───────────────┼────────────────────────────────────────────────┼────────┼───────┤\n",
      "│  1 │ Translation 1 │ This product is very popular in the market.    │ 0.0    │ 800.0 │\n",
      "├────┼───────────────┼────────────────────────────────────────────────┼────────┼───────┤\n",
      "│  2 │ Translation 2 │ This product is well received in the market.   │ 0.0    │ 800.0 │\n",
      "├────┼───────────────┼────────────────────────────────────────────────┼────────┼───────┤\n",
      "│  3 │ Source Text   │ 人工智能正在改变世界。                         │ -      │ -     │\n",
      "├────┼───────────────┼────────────────────────────────────────────────┼────────┼───────┤\n",
      "│  4 │ Translation 1 │ Artificial intelligence is changing the world. │ 0.0    │ 600.0 │\n",
      "├────┼───────────────┼────────────────────────────────────────────────┼────────┼───────┤\n",
      "│  5 │ Translation 2 │ AI is transforming the world.                  │ 0.0    │ 500.0 │\n",
      "├────┼───────────────┼────────────────────────────────────────────────┼────────┼───────┤\n",
      "│  6 │ Source Text   │ 天气很好，我们去公园吧。                       │ -      │ -     │\n",
      "├────┼───────────────┼────────────────────────────────────────────────┼────────┼───────┤\n",
      "│  7 │ Translation 1 │ The weather is great, let's go to the park.    │ 0.0    │ 900.0 │\n",
      "├────┼───────────────┼────────────────────────────────────────────────┼────────┼───────┤\n",
      "│  8 │ Translation 2 │ It's nice outside, let's visit the park.       │ 0.0    │ 700.0 │\n",
      "╘════╧═══════════════╧════════════════════════════════════════════════╧════════╧═══════╛\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\herme\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import nltk\n",
    "import sacrebleu\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "\n",
    "#  BLEU\n",
    "def calculate_bleu(reference, candidate):\n",
    "    return round(sacrebleu.sentence_bleu(candidate, [reference]).score, 3)\n",
    "\n",
    "\n",
    "# TER\n",
    "def calculate_ter(reference, candidate):\n",
    "    ter_metric = sacrebleu.metrics.TER()\n",
    "    return round(ter_metric.corpus_score([candidate], [[reference]]).score, 3)\n",
    "\n",
    "\n",
    "json_file_path = \"data/translations_comparison.json\"\n",
    "\n",
    "\n",
    "def load_json_data(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "translations_data = load_json_data(json_file_path)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(translations_data)\n",
    "\n",
    "results = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    source_text = row[\"source_text\"]\n",
    "    translation_1 = row[\"translation_1\"]\n",
    "    translation_2 = row[\"translation_2\"]\n",
    "\n",
    "    # translation_1 evaluation\n",
    "    bleu_1 = calculate_bleu(source_text, translation_1)\n",
    "    ter_1 = calculate_ter(source_text, translation_1)\n",
    "\n",
    "    # translation_2 evaluation\n",
    "    bleu_2 = calculate_bleu(source_text, translation_2)\n",
    "    ter_2 = calculate_ter(source_text, translation_2)\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"Category\": \"Source Text\",\n",
    "            \"Text\": source_text,\n",
    "            \"BLEU\": \"-\",\n",
    "            \"TER\": \"-\",\n",
    "        }\n",
    "    )\n",
    "    results.append(\n",
    "        {\n",
    "            \"Category\": \"Translation 1\",\n",
    "            \"Text\": translation_1,\n",
    "            \"BLEU\": bleu_1,\n",
    "            \"TER\": ter_1,\n",
    "        }\n",
    "    )\n",
    "    results.append(\n",
    "        {\n",
    "            \"Category\": \"Translation 2\",\n",
    "            \"Text\": translation_2,\n",
    "            \"BLEU\": bleu_2,\n",
    "            \"TER\": ter_2,\n",
    "        }\n",
    "    )\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def display_results(dataframe):\n",
    "    print(\"\\n📌 **Translation Quality Evaluation (BLEU & TER Scores)**\\n\")\n",
    "    print(tabulate(dataframe, headers=\"keys\", tablefmt=\"fancy_grid\"))\n",
    "\n",
    "\n",
    "display_results(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-opentutorial-HDS-w_h3-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
