{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "635d8ebb",
      "metadata": {},
      "source": [
        "# Chroma-Multimodal\n",
        "\n",
        "- Author: [Gwangwon Jung](https://github.com/pupba)\n",
        "- Design: []()\n",
        "- Peer Review: \n",
        "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/09-VectorStore/02-Chroma-Multimodal.ipynb) [![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/09-VectorStore/02-Chroma-Multimodal.ipynb)\n",
        "\n",
        "## Overview\n",
        "\n",
        "This tutorial covers how to use `Chroma Vector Store` with `LangChain` .\n",
        "\n",
        "`Chroma` is an `open-source AI application database` .\n",
        "\n",
        "In this tutorial, after learning how to use `langchain-chroma` , we will implement examples of a simple **Text Search** engine and **Multimodal Search** engine using `Chroma` .\n",
        "\n",
        "![search-example](./assets/02-chroma-with-langchain-flow-search-example.png)\n",
        "\n",
        "### Table of Contents\n",
        "\n",
        "- [Overview](#overview)\n",
        "- [Environement Setup](#environment-setup)\n",
        "- [What is Chroma?](#what-is-chroma?)\n",
        "- [LangChain Chroma Basic](#langchain-chroma-basic)\n",
        "- [Text Search](#text-search)\n",
        "- [Multimodal Search](#multimodal-search)\n",
        "\n",
        "\n",
        "### References\n",
        "\n",
        "- [Chroma Docs](https://docs.trychroma.com/docs/overview/introduction)\n",
        "- [Langchain-Chroma](https://python.langchain.com/docs/integrations/vectorstores/chroma/)\n",
        "- [List of VectorStore supported by Langchain](https://python.langchain.com/docs/integrations/vectorstores/)\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6c7aba4",
      "metadata": {},
      "source": [
        "## Environment Setup\n",
        "\n",
        "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
        "\n",
        "**[Note]**\n",
        "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
        "- You can checkout the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "21943adb",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install langchain-opentutorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f25ec196",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "from langchain_opentutorial import package\n",
        "\n",
        "package.install(\n",
        "    [\n",
        "        \"langsmith\",\n",
        "        \"langchain-core\",\n",
        "        \"langchain-chroma\",\n",
        "        \"langchain-huggingface\",\n",
        "        \"langchain-experimental\",\n",
        "        \"pillow\",\n",
        "        \"open_clip_torch\",\n",
        "        \"scikit-learn\",\n",
        "        \"numpy\",\n",
        "        \"requests\",\n",
        "        \"python-dotenv\",\n",
        "        \"datasets >= 3.2.0\",  # Requirements >= 3.2.0\n",
        "    ],\n",
        "    verbose=False,\n",
        "    upgrade=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f9065ea",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set environment variables\n",
        "from langchain_opentutorial import set_env\n",
        "\n",
        "set_env(\n",
        "    {\n",
        "        \"OPENAI_API_KEY\": \"\",\n",
        "        \"LANGCHAIN_API_KEY\": \"\",\n",
        "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
        "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
        "        \"LANGCHAIN_PROJECT\": \"Chroma With Langchain\",  # title 과 동일하게 설정해 주세요\n",
        "        \"HUGGINGFACEHUB_API_TOKEN\": \"\",\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "690a9ae0",
      "metadata": {},
      "source": [
        "You can alternatively set API keys such as `OPENAI_API_KEY` in a `.env` file and load them.\n",
        "\n",
        "[Note] This is not necessary if you've already set the required API keys in previous steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f99b5b6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load API keys from .env file\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv(override=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77dbe5de",
      "metadata": {},
      "source": [
        "## What is Chroma?\n",
        "\n",
        "![logo](./assets/02-chroma-with-langchain-chroma-logo.png)\n",
        "\n",
        "`Chroma` is the `open-source vector database` designed for AI application. \n",
        "\n",
        "It specializes in storing high-dimensional vectors and performing fast similariy search, making it ideal for tasks like `semantic search` , `recommendation systems` and `multimodal search` .\n",
        "\n",
        "With its **developer-friendly APIs** and seamless integration with frameworks like `LangChain` , `Chroma` is powerful tool for building scalable, AI-driven solutions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "492fd4a1",
      "metadata": {},
      "source": [
        "## LangChain Chroma Basic\n",
        "\n",
        "### Load Text Documents Data(Temporary)\n",
        "\n",
        "The following code demonstrates how to load text documents into a structured format using the `Document` class from `langchain-core` .\n",
        "\n",
        "Each document contains `page_content` (the text) and `metadata` (additional information about the soruce).\n",
        "\n",
        "Unique **IDs** are also generated for each document using `uuid4` ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c4be6acb",
      "metadata": {},
      "outputs": [],
      "source": [
        "from uuid import uuid4\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "document_1 = Document(\n",
        "    page_content=\"I had chocolate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        "    id=1,\n",
        ")\n",
        "\n",
        "document_2 = Document(\n",
        "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        "    id=2,\n",
        ")\n",
        "\n",
        "document_3 = Document(\n",
        "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        "    id=3,\n",
        ")\n",
        "\n",
        "document_4 = Document(\n",
        "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        "    id=4,\n",
        ")\n",
        "\n",
        "document_5 = Document(\n",
        "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        "    id=5,\n",
        ")\n",
        "\n",
        "document_6 = Document(\n",
        "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
        "    metadata={\"source\": \"website\"},\n",
        "    id=6,\n",
        ")\n",
        "\n",
        "document_7 = Document(\n",
        "    page_content=\"The top 10 soccer players in the world right now.\",\n",
        "    metadata={\"source\": \"website\"},\n",
        "    id=7,\n",
        ")\n",
        "\n",
        "document_8 = Document(\n",
        "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        "    id=8,\n",
        ")\n",
        "\n",
        "document_9 = Document(\n",
        "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        "    id=9,\n",
        ")\n",
        "\n",
        "document_10 = Document(\n",
        "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        "    id=10,\n",
        ")\n",
        "\n",
        "documents = [\n",
        "    document_1,\n",
        "    document_2,\n",
        "    document_3,\n",
        "    document_4,\n",
        "    document_5,\n",
        "    document_6,\n",
        "    document_7,\n",
        "    document_8,\n",
        "    document_9,\n",
        "    document_10,\n",
        "]\n",
        "uuids = [str(uuid4()) for _ in range(len(documents))]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c65d74be",
      "metadata": {},
      "source": [
        "### Create Vector Store with Embedding\n",
        "\n",
        "First, load the **Embedding Model**. \n",
        "\n",
        "We use the `sentence-transformers/all-mpnet-base-v2` embedding model, which is loaded using the `HuggingFaceEmbeddings` class from `langchain-huggingface` integration.\n",
        "\n",
        "This model is a powerful choice for generating high-quality embeddings for text data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c86b1236",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "886f2498",
      "metadata": {},
      "source": [
        "Create a `Chroma DB` instance using the `Chroma` class from `langchain-chroma` .\n",
        "\n",
        "**Parameters**\n",
        "\n",
        "- `collection_name:str` – Name of the collection to create.\n",
        "\n",
        "- `embedding_function:Optional[Embeddings]` – Embedding class object. Used to embed texts.\n",
        "\n",
        "- `persist_directory:Optional[str]` – Directory to persist the collection.\n",
        "\n",
        "- `client_settings:Optional[chromadb.config.Settings]` – Chroma client settings\n",
        "\n",
        "- `collection_metadata:Optional[Dict]` – Collection configurations.\n",
        "\n",
        "- `client:Optional[chromadb.ClientAPI]` – Chroma client. Documentation: https://docs.trychroma.com/reference/python/client\n",
        "\n",
        "- `relevance_score_fn:Optional[Callable[[float], float]]` – Function to calculate relevance score from distance. Used only in similarity_search_with_relevance_scores\n",
        "\n",
        "- `create_collection_if_not_exists:Optional[bool]` – Whether to create collection if it doesn’t exist. Defaults to True.\n",
        "\n",
        "**Returns**\n",
        "\n",
        "- `Chroma:langchain_chroma.vectorstores.Chroma` - Chroma instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf99266b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create Vector DB\n",
        "from langchain_chroma import Chroma\n",
        "\n",
        "vector_store = Chroma(\n",
        "    collection_name=\"example_collection\",\n",
        "    embedding_function=embeddings,\n",
        "    persist_directory=\"./data/test_chroma_db\",\n",
        "    # Where to save data locally, remove if not necessary\n",
        ")\n",
        "print(vector_store)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae4cdb90",
      "metadata": {},
      "source": [
        "### Manage Vector Store\n",
        "\n",
        "Add `documents` into the vector store with `UUIDs` as identifiers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0452a852",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add documents\n",
        "vector_store.add_documents(documents=documents, ids=uuids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf999aab",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verifying saved data\n",
        "vector_store.get()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86bfa602",
      "metadata": {},
      "source": [
        "In addition to adding items this way, you can freely `update` or `delete` items in the vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "42194e3a",
      "metadata": {},
      "outputs": [],
      "source": [
        "updated_document_1 = Document(\n",
        "    page_content=\"I had fish&chip and fried eggs for breakfast this morning.\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        "    id=1,\n",
        ")\n",
        "\n",
        "updated_document_2 = Document(\n",
        "    page_content=\"The weather forecast for tomorrow is windy and cold, with a high of 82 degrees.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        "    id=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "0a9fd18d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Update exmpale\n",
        "\n",
        "vector_store.update_document(\n",
        "    document_id=uuids[0], document=updated_document_1\n",
        ")  # document update\n",
        "\n",
        "vector_store.update_documents(\n",
        "    ids=uuids[:2], documents=[updated_document_1, updated_document_2]\n",
        ")  # documents update"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fa2d993",
      "metadata": {},
      "outputs": [],
      "source": [
        "vector_store.get()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "4283f9c4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Delete exmple\n",
        "vector_store.delete(ids=uuids[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7557b967",
      "metadata": {},
      "outputs": [],
      "source": [
        "vector_store.get()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d515ad98",
      "metadata": {},
      "source": [
        "### Query Vector Store\n",
        "\n",
        "There are two ways to `Query` the `Vector Store` .\n",
        "\n",
        "- **Directly** : Query the vector store directly using methods like `similarity_search` or `similarity_search_with_score` .\n",
        "\n",
        "- **Turning into retriever** : Convert the vector store into a `retriever` object, which can be used in `LangChain` pipelines or chains."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d37c37fb",
      "metadata": {},
      "source": [
        "## Text Search\n",
        "\n",
        "With the `Directly` way, you can simply search for `Text` through `Similarity` without much implementation.\n",
        "\n",
        "The `Directly` way includes `similarity_search` and `similarity_search_with_score` .\n",
        "\n",
        "### similarity_search()\n",
        "\n",
        "`similarity_search()` is run similarity search with Chroma.\n",
        "\n",
        "**Parameters**\n",
        "\n",
        "- `query:str` - Query text to search for.\n",
        "\n",
        "- `k: int = DEFAULT_K` - Number of results to return. Defaults to 4.    \n",
        "\n",
        "- `filter: Dict[str, str] | None = None` - Filter by metadata. Defaults to None.\n",
        "\n",
        "- `**kwargs:Any` - Additional keyword arguments to pass to Chroma collection query.\n",
        "\n",
        "\n",
        "**Returns**\n",
        "- `List[Documents]` - List of documents most similar to the query text.\n",
        "\n",
        "\n",
        "\n",
        "### similarity_search_with_score()\n",
        "\n",
        "`similarity_search_with_score()` is run similarity search with Chroma with distance.\n",
        "\n",
        "**Parameters**\n",
        "\n",
        "- `query:str` - Query text to search for.\n",
        "\n",
        "- `k:int = DEFAULT_K` - Number of results to return. Defaults to 4.\n",
        "\n",
        "- `filter: Dict[str, str] | None = None` - Filter by metadata. Defaults to None.\n",
        "\n",
        "- `where_document: Dict[str, str] | None = None` - dict used to filter by the documents. E.g. {$contains: {\"text\": \"hello\"}}.\n",
        "\n",
        "- `**kwargs:Any` : Additional keyword arguments to pass to Chroma collection query.\n",
        "\n",
        "\n",
        "**Returns**\n",
        "- `List[Tuple[Document, float]]` - List of documents most similar to the query text and distance in float for each. Lower score represents more similarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04e592b0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Directly - similarity_search\n",
        "\n",
        "results = vector_store.similarity_search(\n",
        "    query=\"LangChain provides abstractions to make working with LLMs easy\",\n",
        "    k=2,\n",
        "    filter={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "for idx, res in enumerate(results):\n",
        "    print(f\"{idx}: {res.page_content} [{res.metadata}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63674e63",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Directly - similarity_search_with_score\n",
        "\n",
        "results = vector_store.similarity_search_with_score(\n",
        "    query=\"Will it be cold tomorrow?\",\n",
        "    k=1,\n",
        "    filter={\"source\": \"news\"},\n",
        ")\n",
        "\n",
        "for idx, (res, score) in enumerate(results):\n",
        "    print(\n",
        "        f\"{idx}: [Similarity Score: {round(score,3)*100}%] {res.page_content} [{res.metadata}]\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3de5b67",
      "metadata": {},
      "source": [
        "You can also use `Turning into retrievals` way to search for text.\n",
        "\n",
        "### as_retriever()\n",
        "\n",
        "The `as_retriever()` method converts a `VectorStore` object into a `Retriever` object.\n",
        "\n",
        "A `Retriever` is an interface used in `LangChain` to query a vector store and retrieve relevant documents.\n",
        "\n",
        "**Parameters**\n",
        "\n",
        "- `search_type:Optional[str]` - Defines the type of search that the Retriever should perform. Can be `similarity` (default), `mmr` , or `similarity_score_threshold`\n",
        "\n",
        "- `search_kwargs:Optional[Dict]` - Keyword arguments to pass to the search function. \n",
        "\n",
        "    Can include things like:\n",
        "\n",
        "    `k` : Amount of documents to return (Default: 4)\n",
        "\n",
        "    `score_threshold` : Minimum relevance threshold for similarity_score_threshold\n",
        "\n",
        "    `fetch_k` : Amount of documents to pass to `MMR` algorithm(Default: 20)\n",
        "        \n",
        "    `lambda_mult` : Diversity of results returned by MMR; 1 for minimum diversity and 0 for maximum. (Default: 0.5)\n",
        "\n",
        "    `filter` : Filter by document metadata\n",
        "\n",
        "\n",
        "**Returns**\n",
        "\n",
        "- `VectorStoreRetriever` - Retriever class for VectorStore.\n",
        "\n",
        "\n",
        "### invoke()\n",
        "\n",
        "Invoke the retriever to get relevant documents.\n",
        "\n",
        "Main entry point for synchronous retriever invocations.\n",
        "\n",
        "**Parameters**\n",
        "\n",
        "- `input:str` - The query string.\n",
        "- `config:RunnableConfig | None = None` - Configuration for the retriever. Defaults to None.\n",
        "- `**kwargs:Any` - Additional arguments to pass to the retriever.\n",
        "\n",
        "\n",
        "**Returns**\n",
        "\n",
        "- `List[Document]` : List of relevant documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84cd502e",
      "metadata": {},
      "outputs": [],
      "source": [
        "retriever = vector_store.as_retriever(\n",
        "    search_type=\"similarity\",\n",
        "    search_kwargs={\"k\": 2},\n",
        ")\n",
        "\n",
        "retriever.invoke(\"Stealing from the bank is a crime\", filter={\"source\": \"news\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f521c85b",
      "metadata": {},
      "source": [
        "## Multimodal Search\n",
        "\n",
        "`Chorma` supports `Multimodal Collections` , which means it can handle and store embeddings from different types of data, such as `text` , `images` , `audio` , or even `video` .\n",
        "\n",
        "We can search for `images` using `Chroma` ."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36e290b8",
      "metadata": {},
      "source": [
        "### Setting `image` and `image_info` data\n",
        "\n",
        "This dataset is made by `SDXL` . \n",
        "\n",
        "**Dataset: Animal-180**\n",
        "\n",
        "- [animal-180](https://huggingface.co/datasets/Pupba/animal-180)\n",
        "\n",
        "This dataset, named `animal-180` , is a collection of 180 realistic animal images generated using `Stable-Diffusion XL(SDXL)` .\n",
        "\n",
        "It includes images of `lions` , `rabbits` , `cats` , `dogs` , `elephants` and `tigers` , with 30 images per animal category.\n",
        "\n",
        "All images are free to use for any purpose, as they are synthetically generated and not subject to copyright restrictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "a12b636c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import tempfile\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def save_temp_gen_url(image: Image) -> str:\n",
        "    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".png\")\n",
        "    image.save(temp_file, format=\"PNG\")\n",
        "    temp_file.close()\n",
        "    return temp_file.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "af1593e3",
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"Pupba/animal-180\", split=\"train\")\n",
        "\n",
        "# slice 50 set\n",
        "images = dataset[:50][\"png\"]\n",
        "image_paths = [save_temp_gen_url(img) for img in images]\n",
        "metas = dataset[:50][\"json\"]\n",
        "prompts = [data[\"prompt\"] for data in metas]\n",
        "categories = [data[\"category\"] for data in metas]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05bef9ef",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Image Path:\", image_paths[0])\n",
        "print(\"Prompt:\", prompts[0])\n",
        "print(\"Category:\", categories[0])\n",
        "images[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa70bd4e",
      "metadata": {},
      "source": [
        "Load `OpenCLIP` for `Multimodal Embedding` .\n",
        "\n",
        "- [OpenCLIP](https://github.com/mlfoundations/open_clip/tree/main)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "e29d7f42",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_experimental.open_clip import OpenCLIPEmbeddings\n",
        "\n",
        "MODEL = \"ViT-H-14-quickgelu\"\n",
        "CHECKPOINT = \"dfn5b\"\n",
        "\n",
        "image_embedding = OpenCLIPEmbeddings(model_name=MODEL, checkpoint=CHECKPOINT)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64068df4",
      "metadata": {},
      "source": [
        "## Create a Multimodal Vector Store\n",
        "\n",
        "Create a `Multimodal Vector Store` and add the `Image uri` and `Metadata(file_path, category, prompt)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "312294b4",
      "metadata": {},
      "outputs": [],
      "source": [
        "image_vector_db = Chroma(\n",
        "    collection_name=\"multimodal\",\n",
        "    embedding_function=image_embedding,\n",
        ")\n",
        "\n",
        "image_vector_db.add_images(\n",
        "    uris=image_paths,\n",
        "    metadatas=[\n",
        "        {\"file_path\": file_path, \"category\": category, \"prompt\": prompt}\n",
        "        for file_path, category, prompt in zip(image_paths, categories, prompts)\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76799536",
      "metadata": {},
      "outputs": [],
      "source": [
        "image_vector_db.get()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76d8d70a",
      "metadata": {},
      "source": [
        "Make `ImageSearcher`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "de0383b6",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Optional, Dict\n",
        "\n",
        "\n",
        "class ImageSearcher:\n",
        "    def __init__(self, image_vector_store: Chroma):\n",
        "        self.__vector_store = image_vector_store\n",
        "\n",
        "    def searching_text_query(self, query: str) -> Optional[Dict]:\n",
        "        docs = self.__vector_store.as_retriever().invoke(query)\n",
        "\n",
        "        if docs and isinstance(docs[0], Document):\n",
        "            metadata = docs[0].metadata\n",
        "            return {\n",
        "                \"category\": metadata[\"category\"],\n",
        "                \"image\": Image.open(metadata[\"file_path\"]),\n",
        "                \"prompt\": metadata[\"prompt\"],\n",
        "            }\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def searching_image_query(self, image_uri: str) -> Optional[Dict]:\n",
        "        docs = self.__vector_store.similarity_search_by_image(uri=image_uri, k=1)\n",
        "        if docs and isinstance(docs[0], Document):\n",
        "            metadata = docs[0].metadata\n",
        "            return {\n",
        "                \"category\": metadata[\"category\"],\n",
        "                \"image\": Image.open(metadata[\"file_path\"]),\n",
        "                \"prompt\": metadata[\"prompt\"],\n",
        "            }\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "\n",
        "image_search = ImageSearcher(image_vector_store=image_vector_db)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a6cfffd",
      "metadata": {},
      "source": [
        "Text Query Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8e129d8",
      "metadata": {},
      "outputs": [],
      "source": [
        "result = image_search.searching_text_query(query=\"a elephant run\")\n",
        "\n",
        "print(f\"Category: {result['category']}\")\n",
        "print(f\"Prompt: {result['prompt']}\")\n",
        "result[\"image\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "420ca579",
      "metadata": {},
      "source": [
        "Image Query Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "54134cb9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# query image url\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "\n",
        "def load_image_from_url(url: str, resolution: int = 512) -> Image.Image:\n",
        "    \"\"\"\n",
        "    Load an image from a URL and return it as a PIL Image object.\n",
        "\n",
        "    Args:\n",
        "        url (str): The URL of the image.\n",
        "\n",
        "    Returns:\n",
        "        Image.Image: The loaded PIL Image object.\n",
        "    \"\"\"\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()  # Raise an error for failed requests\n",
        "    image = Image.open(BytesIO(response.content))\n",
        "    image = image.resize((resolution, resolution), resample=Image.Resampling.LANCZOS)\n",
        "    return image\n",
        "\n",
        "\n",
        "def save_image_to_tempfile(url: str) -> str:\n",
        "    \"\"\"\n",
        "    Download an image from a URL and save it to a temporary file.\n",
        "\n",
        "    Args:\n",
        "        url (str): The URL of the image.\n",
        "\n",
        "    Returns:\n",
        "        str: The file path to the saved image.\n",
        "    \"\"\"\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Raise an error for failed requests\n",
        "    response.raise_for_status()\n",
        "\n",
        "    # Create a temporary file\n",
        "    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".jpg\")\n",
        "    temp_file.write(response.content)\n",
        "\n",
        "    # Close the file to allow other processes to access it\n",
        "    temp_file.close()\n",
        "    return temp_file.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3c7c128",
      "metadata": {},
      "outputs": [],
      "source": [
        "# rabbit image\n",
        "img_url = \"https://i.pinimg.com/736x/b2/e9/f4/b2e9f449c1c5f8a29e31cafb8671c8b2.jpg\"\n",
        "\n",
        "image_query = load_image_from_url(img_url)\n",
        "image_query_url = save_image_to_tempfile(img_url)\n",
        "\n",
        "image_query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73acaa42",
      "metadata": {},
      "outputs": [],
      "source": [
        "result = image_search.searching_image_query(image_uri=image_query_url)\n",
        "\n",
        "print(f\"Category: {result['category']}\")\n",
        "print(f\"Prompt: {result['prompt']}\")\n",
        "result[\"image\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05f53e7c",
      "metadata": {},
      "source": [
        "Remove a `Huggingface Cache`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ffecd99",
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset.cleanup_cache_files()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0152d55b",
      "metadata": {},
      "source": [
        "Disconnect `Chroma` DB and Remove Local DB file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "85366da4",
      "metadata": {},
      "outputs": [],
      "source": [
        "del vector_store\n",
        "del image_vector_db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "51304c87",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "shutil.rmtree(os.path.join(os.getcwd(), \"data\", \"test_chroma_db\"))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "langchain-opentutorial",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
