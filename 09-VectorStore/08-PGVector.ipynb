{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PGVector\n",
        "\n",
        "- Author: [Min-su Jung](https://github.com/effort-type), [Joonha Jeon](https://github.com/realjoonha), [Jongho Lee](https://github.com/XaviereKU)\n",
        "- Design: \n",
        "- Peer Review : \n",
        "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/09-VectorStore/07-PGVector.ipynb) [![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/09-VectorStore/07-PGVector.ipynb)\n",
        "\n",
        "## Overview  \n",
        "\n",
        "[```PGVector```](https://github.com/pgvector/pgvector) is an open-source extension for PostgreSQL that allows you to store and search vector data alongside your regular database information.\n",
        "\n",
        "This notebook shows how to use functionality related to ```PGVector```, implementing LangChain vectorstore abstraction using postgres as the backend and utilizing the pgvector extension.\n",
        "\n",
        "### Table of Contents\n",
        "\n",
        "- [Overview](#overview)\n",
        "- [Environment Setup](#environment-setup)\n",
        "- [What is PGVector?](#what-is-pgvector)\n",
        "- [Initialization](#initialization)\n",
        "- [Manage vector store](#manage-vector-store)\n",
        "- [Query vector store](#query-vector-store)\n",
        "\n",
        "### References\n",
        "\n",
        "- [langchain-postgres](https://github.com/langchain-ai/langchain-postgres/)\n",
        "- [pgvector](https://github.com/pgvector/pgvector)\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Environment Setup\n",
        "\n",
        "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
        "\n",
        "**[Note]**\n",
        "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
        "- You can checkout the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install langchain-opentutorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "from langchain_opentutorial import package\n",
        "\n",
        "package.install(\n",
        "    [\n",
        "        \"langsmith\",\n",
        "        \"langchain\",\n",
        "        \"langchain_core\",\n",
        "        \"langchain_postgres\",\n",
        "        \"langchain_openai\",\n",
        "        \"psycopg[binary,pool]\",\n",
        "    ],\n",
        "    verbose=False,\n",
        "    upgrade=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment variables have been set successfully.\n"
          ]
        }
      ],
      "source": [
        "# Set environment variables\n",
        "from langchain_opentutorial import set_env\n",
        "\n",
        "set_env(\n",
        "    {\n",
        "        \"LANGCHAIN_API_KEY\": \"\",\n",
        "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
        "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
        "        \"LANGCHAIN_PROJECT\": \"PGVector\",\n",
        "        \"OPENAI_API_KEY\": \"\",\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv(override=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What is PGVector?\n",
        "\n",
        "`PGVector` is a ```PostgreSQL``` extension that enables vector similarity search directly within your ```PostgreSQL``` database, making it ideal for AI applications, semantic search, and recommendation systems.\n",
        "\n",
        "This is particularly valuable for who already use ```PostgreSQL``` who want to add vector search capabilities without managing separate infrastructure or learning new query languages.\n",
        "\n",
        "**Features** :\n",
        "1. Native ```PostgreSQL``` integration with standard SQL queries\n",
        "2. Multiple similarity search methods including L2, Inner Product, Cosine\n",
        "3. Several indexing options including HNSW and IVFFlat\n",
        "4. Support for up to 2,000 dimensions per vector\n",
        "5. ACID compliance inherited from ```PostgreSQL```\n",
        "\n",
        "**Advantages** :\n",
        "\n",
        "1. Free and open-source\n",
        "2. Easy integration with existing ```PostgreSQL``` databases\n",
        "3. Full SQL functionality and transactional support\n",
        "4. No additional infrastructure needed\n",
        "5. Supports hybrid searches combining vector and traditional SQL queries\n",
        "\n",
        "**Disadvantages** :\n",
        "1. Performance limitations with very large datasets (billions of vectors)\n",
        "2. Limited to single-node deployment\n",
        "3. Memory-intensive for large vector dimensions\n",
        "4. Requires manual optimization for best performance\n",
        "5. Less specialized features compared to dedicated vector databases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set up PGVector\n",
        "\n",
        "You can easily set up `PGVector` by running the following command that spins up a ```Docker``` container:\n",
        "\n",
        "```bash\n",
        "docker run --name pgvector-container -e POSTGRES_USER=langchain -e POSTGRES_PASSWORD=langchain -e POSTGRES_DB=langchain -p 6024:5432 -d pgvector/pgvector:pg16\n",
        "```\n",
        "\n",
        "For more detailed instructions, please refer to [the official documentation](https://github.com/pgvector/pgvector) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialization\n",
        "\n",
        "Once setting up an instance of postgres with pgvector enabled, you can directly instantiate a `PGVector` vector store to store embedded data and perform similarity search."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Select Embeddings model\n",
        "\n",
        "You should define an embedding model to use before instantiating `PGVector`.\n",
        "\n",
        "In this subsection we use ```text-embedding-3-large``` model of OpenAI here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
        "\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create collections\n",
        "\n",
        "You can create a collection to use by instantiating `PGVector` with a collection name. Note that the default value is `langchain`, and it is recommended to define your own to manage multiple collections. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.documents import Document\n",
        "from langchain_postgres import PGVector\n",
        "\n",
        "\n",
        "# See docker command above to launch a postgres instance with pgvector enabled.\n",
        "connection = \"postgresql+psycopg://langchain:langchain@localhost:6024/langchain\"  # Uses psycopg3!\n",
        "collection_name = \"my_docs\"\n",
        "\n",
        "vector_store = PGVector(\n",
        "    embeddings=embeddings,\n",
        "    collection_name=collection_name,\n",
        "    connection=connection,\n",
        "    use_jsonb=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Manage collections\n",
        "\n",
        "As postgres is basically a relational DB even with an extension of pgvector, the data management is quite different with other vector DBs. You can see that instantiating `PGVector` makes two default tables below `langchain` database.\n",
        "\n",
        "- `langchain_pg_collection`: stores metadata of collections\n",
        "- `langchain_pg_embedding`: stores actual data including document and embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tables in the database:\n",
            "langchain_pg_collection\n",
            "langchain_pg_embedding\n"
          ]
        }
      ],
      "source": [
        "import psycopg\n",
        "\n",
        "# Connection parameters\n",
        "conn_params = {\n",
        "    \"dbname\": \"langchain\",\n",
        "    \"user\": \"langchain\",\n",
        "    \"password\": \"langchain\",\n",
        "    \"host\": \"localhost\",\n",
        "    \"port\": \"6024\",\n",
        "}\n",
        "\n",
        "with psycopg.connect(**conn_params) as conn:\n",
        "    with conn.cursor() as cur:\n",
        "        cur.execute(\n",
        "            \"\"\"\n",
        "            SELECT table_name \n",
        "            FROM information_schema.tables \n",
        "            WHERE table_schema = 'public'\n",
        "            AND table_type = 'BASE TABLE';\n",
        "        \"\"\"\n",
        "        )\n",
        "\n",
        "        tables = cur.fetchall()\n",
        "\n",
        "        print(\"Tables in the database:\")\n",
        "        for table in tables:\n",
        "            print(table[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### List collections\n",
        "\n",
        "You can list all of the collections that are created in a dedicated database (`langchain`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['my_docs']\n"
          ]
        }
      ],
      "source": [
        "from psycopg.rows import dict_row\n",
        "\n",
        "with psycopg.connect(**conn_params) as conn:\n",
        "    with conn.cursor(row_factory=dict_row) as cur:\n",
        "        cur.execute(\"SELECT name FROM langchain_pg_collection;\")\n",
        "\n",
        "        rows = cur.fetchall()\n",
        "        names = [row[\"name\"] for row in rows]\n",
        "\n",
        "        print(names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Delete collections\n",
        "\n",
        "You can use below method to delete a collection with its name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deleted 0 collection(s) and 0 related embedding(s).\n"
          ]
        }
      ],
      "source": [
        "def delete_collection_and_embeddings(collection_name):\n",
        "    with psycopg.connect(**conn_params) as conn:\n",
        "        with conn.cursor() as cur:\n",
        "            # First, delete the corresponding embeddings\n",
        "            cur.execute(\n",
        "                \"\"\"\n",
        "                DELETE FROM langchain_pg_embedding\n",
        "                WHERE collection_id IN (\n",
        "                    SELECT uuid \n",
        "                    FROM langchain_pg_collection \n",
        "                    WHERE name = %s\n",
        "                );\n",
        "            \"\"\",\n",
        "                (collection_name,),\n",
        "            )\n",
        "\n",
        "            embeddings_deleted = cur.rowcount\n",
        "\n",
        "            # Then, delete the collection\n",
        "            cur.execute(\n",
        "                \"\"\"\n",
        "                DELETE FROM langchain_pg_collection\n",
        "                WHERE name = %s;\n",
        "            \"\"\",\n",
        "                (collection_name,),\n",
        "            )\n",
        "\n",
        "            collections_deleted = cur.rowcount\n",
        "\n",
        "        conn.commit()\n",
        "\n",
        "    return collections_deleted, embeddings_deleted\n",
        "\n",
        "\n",
        "# Usage\n",
        "collection_name_to_delete = \"your_collection_name\"\n",
        "collections, embeddings = delete_collection_and_embeddings(collection_name_to_delete)\n",
        "\n",
        "print(f\"Deleted {collections} collection(s) and {embeddings} related embedding(s).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Manage vector store\n",
        "\n",
        "Once you have instantiated your vector store, we can interact with it by adding and deleting different items."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Add items to vector store\n",
        "\n",
        "We can add items to our vector store by calling the ```add_documents``` function.\n",
        "\n",
        "In this tutorial, we will store **the little prince** by Saiot-Exupery.\n",
        "\n",
        "You can find the raw text file in the data directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This is a long document we can split up.\n",
        "data_path = \"./data/the_little_prince.txt\"\n",
        "with open(data_path, encoding=\"utf8\") as f:\n",
        "    raw_text = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='The Little Prince\n",
            "Written By Antoine de Saiot-Exupery (1900〜1944)'\n"
          ]
        }
      ],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from uuid import uuid4\n",
        "\n",
        "# define text splitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    # Set a really small chunk size, just to show.\n",
        "    chunk_size=100,\n",
        "    chunk_overlap=20,\n",
        "    length_function=len,\n",
        "    is_separator_regex=False,\n",
        ")\n",
        "\n",
        "# split raw text by splitter.\n",
        "split_docs = text_splitter.create_documents([raw_text])\n",
        "\n",
        "# print one of documents to check its structure\n",
        "print(split_docs[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define document preprocessor\n",
        "def preprocess_documents(\n",
        "    split_docs, metadata_keys, min_length, use_basename=False, **kwargs\n",
        "):\n",
        "    metadata = kwargs\n",
        "\n",
        "    if use_basename:\n",
        "        assert metadata.get(\"source\", None) is not None, \"source must be provided\"\n",
        "        metadata[\"source\"] = metadata[\"source\"].split(\"/\")[-1]\n",
        "\n",
        "    result_docs = []\n",
        "    for idx, doc in enumerate(split_docs):\n",
        "        if len(doc.page_content) < min_length:\n",
        "            continue\n",
        "        for k in metadata_keys:\n",
        "            doc.metadata.update({k: metadata.get(k, \"\")})\n",
        "        doc.metadata.update({\"page\": idx + 1, \"id\": str(uuid4())})\n",
        "        result_docs.append(doc)\n",
        "\n",
        "    return result_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='The Little Prince\n",
            "Written By Antoine de Saiot-Exupery (1900〜1944)' metadata={'source': 'the_little_prince.txt', 'page': 1, 'author': 'Saiot-Exupery', 'id': '5f1a9e6b-d310-48b2-b7b8-7e1e8d1a84ac'}\n"
          ]
        }
      ],
      "source": [
        "# preprocess raw documents\n",
        "processed_docs = preprocess_documents(\n",
        "    split_docs=split_docs,\n",
        "    metadata_keys=[\"source\", \"page\", \"author\"],\n",
        "    min_length=5,\n",
        "    use_basename=True,\n",
        "    source=data_path,\n",
        "    author=\"Saiot-Exupery\",\n",
        ")\n",
        "\n",
        "# print one of preprocessed document to chekc its structure\n",
        "print(processed_docs[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we have prepared documents (or chunks) with unique **ID**.\n",
        "\n",
        "To use it later, we store the IDs as ```uuids``` and pass it to the ```add_documents``` method.\n",
        "\n",
        "The ```add_documents``` method returns IDs of added documents.\n",
        "\n",
        "**Note**\n",
        "\n",
        "If one did not pass the ```ids```, ```add_documents``` method will create ID for each items."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gather uuids\n",
        "uuids = [doc.metadata[\"id\"] for doc in processed_docs]\n",
        "\n",
        "# Add documents to pgvector\n",
        "result = vector_store.add_documents(processed_docs, ids=uuids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['5f1a9e6b-d310-48b2-b7b8-7e1e8d1a84ac', '24bd3977-a6a7-4610-acd5-eaa6f738ad6b', 'db7cd9f5-97f0-4d43-ae86-fd2c13d8aa99', '92722c13-c47b-4566-94d4-587f74b97b7f', 'd1616c3f-23aa-4224-b9ea-158d5f10a4d2', '0a30c273-12c4-4849-92cb-93cd0eec05b5', '84530169-94a0-4e0a-875f-8ed980847565', '23c93c93-c3e8-48b0-8e2b-938af1897ef0', '414275b5-0c05-4ce5-a808-052b390df3a5', '787958a4-fa6b-459f-b8f0-4ed858c9da6d']\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "# Check result\n",
        "print(result[:10])\n",
        "\n",
        "# Check if given IDs used\n",
        "print(uuids[:10] == result[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Delete items from vector store\n",
        "We can delete one or more items with IDs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n"
          ]
        }
      ],
      "source": [
        "# delete an item\n",
        "vector_store.delete(ids=[uuids[2]])\n",
        "\n",
        "# check if it remains in DB.\n",
        "print(vector_store.get_by_ids([uuids[2]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Upsert items to vector store"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can upsert (update and insert) item by adding documents with **ID** that matches with an existing document's ID by over-writing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a new document that have last document's ID.\n",
        "id_to_update = uuids[-1]\n",
        "\n",
        "\n",
        "new_doc = Document(\n",
        "    page_content=\"cooking classes for beginners and novices are offered at the community center\",\n",
        "    metadata={\"id\": id_to_update, \"location\": \"community center\", \"topic\": \"classes\"},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['5a582662-5daf-4f38-838d-f60247bbe07d']"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# upsert document\n",
        "vector_store.add_documents([new_doc], ids=[id_to_update])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cooking classes for beginners and novices are offered at the community center\n"
          ]
        }
      ],
      "source": [
        "# print the document with last id in uuids.\n",
        "print(vector_store.get_by_ids([id_to_update])[0].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that the content of the last chunk have changed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Query vector store\n",
        "\n",
        "Once your vector store has been created and the relevant documents have been added you will most likely wish to query it during the running of your chain or agent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Query directly\n",
        "\n",
        "Performing a simple similarity search can be done as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Content: \"My friend the fox--\" the little prince said to me.\n",
            "  Metadata: {'id': 'bd960f88-5e22-46bf-af66-7e1788c303e4', 'page': 1087, 'author': 'Saiot-Exupery', 'source': 'the_little_prince.txt'}\n",
            "* Content: \"No,\" said the little prince. \"I am looking for friends. What does that mean-- ‘tame‘?\"\n",
            "  Metadata: {'id': '804826d9-ff01-437e-9463-473cb200c205', 'page': 958, 'author': 'Saiot-Exupery', 'source': 'the_little_prince.txt'}\n"
          ]
        }
      ],
      "source": [
        "results = vector_store.similarity_search(\"Does the little prince have a friend?\", k=2)\n",
        "for doc in results:\n",
        "    print(f\"* Content: {doc.page_content}\\n  Metadata: {doc.metadata}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Query with filters\n",
        "\n",
        "The vectorstore supports a set of filters that can be applied against the metadata fields of the documents.\n",
        "\n",
        "You can find a list of filtering operators:\n",
        "\n",
        "| Operator | Meaning/Category        |\n",
        "|----------|-------------------------|\n",
        "| \\$eq      | Equality (==)           |\n",
        "| \\$ne      | Inequality (!=)         |\n",
        "| \\$lt      | Less than (&lt;)           |\n",
        "| \\$lte     | Less than or equal (&lt;=) |\n",
        "| \\$gt      | Greater than (>)        |\n",
        "| \\$gte     | Greater than or equal (>=) |\n",
        "| \\$in      | Special Cased (in)      |\n",
        "| \\$nin     | Special Cased (not in)  |\n",
        "| \\$between | Special Cased (between) |\n",
        "| \\$like    | Text (like)             |\n",
        "| \\$ilike   | Text (case-insensitive like) |\n",
        "| \\$and     | Logical (and)           |\n",
        "| \\$or      | Logical (or)            |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Content: \"My friend the fox--\" the little prince said to me.\n",
            "  Metadata: {'id': 'bd960f88-5e22-46bf-af66-7e1788c303e4', 'page': 1087, 'author': 'Saiot-Exupery', 'source': 'the_little_prince.txt'}\n",
            "* Content: \"What do you do here?\" the little prince asked.\n",
            "  Metadata: {'id': '3085ebfd-8cce-4517-80b7-3baeabcd59cc', 'page': 1049, 'author': 'Saiot-Exupery', 'source': 'the_little_prince.txt'}\n"
          ]
        }
      ],
      "source": [
        "# search with filter\n",
        "result_with_filter = vector_store.similarity_search(\n",
        "    \"Does the little prince have a friend?\",\n",
        "\n",
        "    k=2,\n",
        "    filter={\"page\": {\"$between\": [1000, 1100]}},\n",
        ")\n",
        "\n",
        "for doc in result_with_filter:\n",
        "    print(f\"* Content: {doc.page_content}\\n  Metadata: {doc.metadata}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Similarity search with score\n",
        "\n",
        "You can also search with score:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Similarity: 0.368630\n",
            "  Content: \"My friend the fox--\" the little prince said to me.\n",
            "  Metadata: {'id': 'bd960f88-5e22-46bf-af66-7e1788c303e4', 'page': 1087, 'author': 'Saiot-Exupery', 'source': 'the_little_prince.txt'}\n",
            "* Similarity: 0.394863\n",
            "  Content: \"No,\" said the little prince. \"I am looking for friends. What does that mean-- ‘tame‘?\"\n",
            "  Metadata: {'id': '804826d9-ff01-437e-9463-473cb200c205', 'page': 958, 'author': 'Saiot-Exupery', 'source': 'the_little_prince.txt'}\n"
          ]
        }
      ],
      "source": [
        "results = vector_store.similarity_search_with_score(\n",
        "    query=\"Does the little prince have a friend?\", k=2\n",
        ")\n",
        "\n",
        "\n",
        "for doc, score in results:\n",
        "    print(\n",
        "        f\"* Similarity: {score:3f}\\n  Content: {doc.page_content}\\n  Metadata: {doc.metadata}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Query by turning into retreiver\n",
        "You can also transform the vector store into a retriever for easier usage in your chains."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Content: \"My friend the fox--\" the little prince said to me.\n",
            "  Metadata: {'id': 'bd960f88-5e22-46bf-af66-7e1788c303e4', 'page': 1087, 'author': 'Saiot-Exupery', 'source': 'the_little_prince.txt'}\n"
          ]
        }
      ],
      "source": [
        "retriever = vector_store.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 1})\n",
        "results = retriever.invoke(\"Does the little prince have a friend?\")\n",
        "\n",
        "for doc in results:\n",
        "    print(f\"* Content: {doc.page_content}\\n  Metadata: {doc.metadata}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cp311",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
