{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PGVector\n",
        "\n",
        "- Author: [Min-su Jung](https://github.com/effort-type), [Joonha Jeon](https://github.com/realjoonha)\n",
        "- Design: \n",
        "- Peer Review : \n",
        "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/09-VectorStore/07-PGVector.ipynb) [![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/09-VectorStore/07-PGVector.ipynb)\n",
        "\n",
        "## Overview  \n",
        "\n",
        "[PGVector](https://github.com/pgvector/pgvector) is an open-source extension for PostgreSQL that allows you to store and search vector data alongside your regular database information.\n",
        "\n",
        "This notebook shows how to use functionality related to `PGVector`, implementing LangChain vectorstore abstraction using postgres as the backend and utilizing the pgvector extension.\n",
        "\n",
        "### Table of Contents\n",
        "\n",
        "- [Overview](#overview)\n",
        "- [Environment Setup](#environment-setup)\n",
        "- [What is PGVector?](#what-is-pgvector)\n",
        "    - [Set up PGVector](#set-up-pgvector)\n",
        "- [Initialization](#initialization)\n",
        "    - [Select Embeddings model](#select-embeddings-model)\n",
        "    - [Create collections](#create-collections)\n",
        "    - [Manage collections](#manage-collections)\n",
        "    - [List collections](#list-collections)\n",
        "    - [Delete collections](#delete-collections)\n",
        "- [Manage vector store](#manage-vector-store)\n",
        "    - [Add items to vector store](#add-items-to-vector-store)\n",
        "    - [Delete items to vector store](#delete-items-from-vector-store)\n",
        "    - [Upsert items to vector store](#upsert-items-to-vector-store)\n",
        "- [Query vector store](#query-vector-store)\n",
        "    - [Query directly](#query-directly)\n",
        "    - [Query with filters](#query-with-filters)\n",
        "    - [Similarity search with score](#similarity-search-with-score)\n",
        "    - [Query by turning into retriever](#query-by-turning-into-retreiver)\n",
        "\n",
        "\n",
        "### References\n",
        "\n",
        "- [langchain-postgres](https://github.com/langchain-ai/langchain-postgres/)\n",
        "- [pgvector](https://github.com/pgvector/pgvector)\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Environment Setup\n",
        "\n",
        "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
        "\n",
        "**[Note]**\n",
        "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
        "- You can checkout the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install langchain-opentutorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "from langchain_opentutorial import package\n",
        "\n",
        "package.install(\n",
        "    [\n",
        "        \"langsmith\",\n",
        "        \"langchain\",\n",
        "        \"langchain_core\",\n",
        "        \"langchain_postgres\",\n",
        "        \"langchain_openai\",\n",
        "        \"psycopg[binary,pool]\",\n",
        "    ],\n",
        "    verbose=False,\n",
        "    upgrade=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment variables have been set successfully.\n"
          ]
        }
      ],
      "source": [
        "# Set environment variables\n",
        "from langchain_opentutorial import set_env\n",
        "\n",
        "set_env(\n",
        "    {\n",
        "        \"LANGCHAIN_API_KEY\": \"\",\n",
        "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
        "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
        "        \"LANGCHAIN_PROJECT\": \"PGVector\",\n",
        "        \"OPENAI_API_KEY\": \"\",\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv(override=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What is PGVector?\n",
        "\n",
        "`PGVector` is a PostgreSQL extension that enables vector similarity search directly within your PostgreSQL database, making it ideal for AI applications, semantic search, and recommendation systems.\n",
        "\n",
        "This is particularly valuable for who already use PostgreSQL who want to add vector search capabilities without managing separate infrastructure or learning new query languages.\n",
        "\n",
        "**Features** :\n",
        "1. Native PostgreSQL integration with standard SQL queries\n",
        "2. Multiple similarity search methods including L2, Inner Product, Cosine\n",
        "3. Several indexing options including HNSW and IVFFlat\n",
        "4. Support for up to 2,000 dimensions per vector\n",
        "5. ACID compliance inherited from PostgreSQL\n",
        "\n",
        "**Advantages** :\n",
        "\n",
        "1. Free and open-source\n",
        "2. Easy integration with existing PostgreSQL databases\n",
        "3. Full SQL functionality and transactional support\n",
        "4. No additional infrastructure needed\n",
        "5. Supports hybrid searches combining vector and traditional SQL queries\n",
        "\n",
        "**Disadvantages** :\n",
        "1. Performance limitations with very large datasets (billions of vectors)\n",
        "2. Limited to single-node deployment\n",
        "3. Memory-intensive for large vector dimensions\n",
        "4. Requires manual optimization for best performance\n",
        "5. Less specialized features compared to dedicated vector databases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set up PGVector\n",
        "\n",
        "You can easily set up `PGVector` by running the following command that spins up a docker container:\n",
        "\n",
        "```bash\n",
        "docker run --name pgvector-container -e POSTGRES_USER=langchain -e POSTGRES_PASSWORD=langchain -e POSTGRES_DB=langchain -p 6024:5432 -d pgvector/pgvector:pg16\n",
        "```\n",
        "\n",
        "For more detailed instructions, please refer to [the official documentation](https://github.com/pgvector/pgvector) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialization\n",
        "\n",
        "Once setting up an instance of postgres with pgvector enabled, you can directly instantiate a `PGVector` vector store to store embedded data and perform similarity search."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Select Embeddings model\n",
        "\n",
        "You should define an embedding model to use before instantiating `PGVector`.\n",
        "\n",
        "In this subsection we use ```text-embedding-3-large``` model of OpenAI here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
        "\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create collections\n",
        "\n",
        "You can create a collection to use by instantiating `PGVector` with a collection name. Note that the default value is `langchain`, and it is recommended to define your own to manage multiple collections. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.documents import Document\n",
        "from langchain_postgres import PGVector\n",
        "\n",
        "\n",
        "# See docker command above to launch a postgres instance with pgvector enabled.\n",
        "connection = \"postgresql+psycopg://langchain:langchain@localhost:6024/langchain\"  # Uses psycopg3!\n",
        "collection_name = \"my_docs\"\n",
        "\n",
        "vector_store = PGVector(\n",
        "    embeddings=embeddings,\n",
        "    collection_name=collection_name,\n",
        "    connection=connection,\n",
        "    use_jsonb=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Manage collections\n",
        "\n",
        "As postgres is basically a relational DB even with an extension of pgvector, the data management is quite different with other vector DBs. You can see that instantiating `PGVector` makes two default tables below `langchain` database.\n",
        "\n",
        "- `langchain_pg_collection`: stores metadata of collections\n",
        "- `langchain_pg_embedding`: stores actual data including document and embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tables in the database:\n",
            "langchain_pg_collection\n",
            "langchain_pg_embedding\n"
          ]
        }
      ],
      "source": [
        "import psycopg\n",
        "\n",
        "# Connection parameters\n",
        "conn_params = {\n",
        "    \"dbname\": \"langchain\",\n",
        "    \"user\": \"langchain\",\n",
        "    \"password\": \"langchain\",\n",
        "    \"host\": \"localhost\",\n",
        "    \"port\": \"6024\",\n",
        "}\n",
        "\n",
        "with psycopg.connect(**conn_params) as conn:\n",
        "    with conn.cursor() as cur:\n",
        "        cur.execute(\n",
        "            \"\"\"\n",
        "            SELECT table_name \n",
        "            FROM information_schema.tables \n",
        "            WHERE table_schema = 'public'\n",
        "            AND table_type = 'BASE TABLE';\n",
        "        \"\"\"\n",
        "        )\n",
        "\n",
        "        tables = cur.fetchall()\n",
        "\n",
        "        print(\"Tables in the database:\")\n",
        "        for table in tables:\n",
        "            print(table[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### List collections\n",
        "\n",
        "You can list all of the collections that are created in a dedicated database (`langchain`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['my_docs']\n"
          ]
        }
      ],
      "source": [
        "from psycopg.rows import dict_row\n",
        "\n",
        "with psycopg.connect(**conn_params) as conn:\n",
        "    with conn.cursor(row_factory=dict_row) as cur:\n",
        "        cur.execute(\"SELECT name FROM langchain_pg_collection;\")\n",
        "\n",
        "        rows = cur.fetchall()\n",
        "        names = [row[\"name\"] for row in rows]\n",
        "\n",
        "        print(names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Delete collections\n",
        "\n",
        "You can use below method to delete a collection with its name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def delete_collection_and_embeddings(collection_name):\n",
        "    with psycopg.connect(**conn_params) as conn:\n",
        "        with conn.cursor() as cur:\n",
        "            # First, delete the corresponding embeddings\n",
        "            cur.execute(\n",
        "                \"\"\"\n",
        "                DELETE FROM langchain_pg_embedding\n",
        "                WHERE collection_id IN (\n",
        "                    SELECT uuid \n",
        "                    FROM langchain_pg_collection \n",
        "                    WHERE name = %s\n",
        "                );\n",
        "            \"\"\",\n",
        "                (collection_name,),\n",
        "            )\n",
        "\n",
        "            embeddings_deleted = cur.rowcount\n",
        "\n",
        "            # Then, delete the collection\n",
        "            cur.execute(\n",
        "                \"\"\"\n",
        "                DELETE FROM langchain_pg_collection\n",
        "                WHERE name = %s;\n",
        "            \"\"\",\n",
        "                (collection_name,),\n",
        "            )\n",
        "\n",
        "            collections_deleted = cur.rowcount\n",
        "\n",
        "        conn.commit()\n",
        "\n",
        "    return collections_deleted, embeddings_deleted\n",
        "\n",
        "\n",
        "# Usage\n",
        "collection_name_to_delete = \"your_collection_name\"\n",
        "collections, embeddings = delete_collection_and_embeddings(collection_name_to_delete)\n",
        "\n",
        "print(f\"Deleted {collections} collection(s) and {embeddings} related embedding(s).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Manage vector store\n",
        "\n",
        "Once you have instantiated your vector store, we can interact with it by adding and deleting different items."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Add items to vector store\n",
        "\n",
        "We can add items to our vector store by using the add_documents function.\n",
        "\n",
        "In this tutorial, we will store **the little prince** by Saiot-Exupery.\n",
        "\n",
        "You can find the raw text file in data directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This is a long document we can split up.\n",
        "data_path = \"./data/the_little_prince.txt\"\n",
        "with open(data_path, encoding=\"utf8\") as f:\n",
        "    raw_text = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from uuid import uuid4\n",
        "\n",
        "# define text splitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    # Set a really small chunk size, just to show.\n",
        "    chunk_size=100,\n",
        "    chunk_overlap=20,\n",
        "    length_function=len,\n",
        "    is_separator_regex=False,\n",
        ")\n",
        "\n",
        "# split raw text by splitter.\n",
        "split_docs = text_splitter.create_documents([raw_text])\n",
        "\n",
        "# print one of documents to check its structure\n",
        "print(split_docs[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define document preprocessor\n",
        "def preprocess_documents(\n",
        "    split_docs, metadata_keys, min_length, use_basename=False, **kwargs\n",
        "):\n",
        "    metadata = kwargs\n",
        "\n",
        "    if use_basename:\n",
        "        assert metadata.get(\"source\", None) is not None, \"source must be provided\"\n",
        "        metadata[\"source\"] = metadata[\"source\"].split(\"/\")[-1]\n",
        "\n",
        "    result_docs = []\n",
        "    for idx, doc in enumerate(split_docs):\n",
        "        if len(doc.page_content) < min_length:\n",
        "            continue\n",
        "        for k in metadata_keys:\n",
        "            doc.metadata.update({k: metadata.get(k, \"\")})\n",
        "        doc.metadata.update({\"page\": idx + 1, \"id\": str(uuid4())})\n",
        "        result_docs.append(doc)\n",
        "\n",
        "    return result_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# preprocess raw documents\n",
        "processed_docs = preprocess_documents(\n",
        "    split_docs=split_docs,\n",
        "    metadata_keys=[\"source\", \"page\", \"author\"],\n",
        "    min_length=5,\n",
        "    use_basename=True,\n",
        "    source=data_path,\n",
        "    author=\"Saiot-Exupery\",\n",
        ")\n",
        "\n",
        "# print one of preprocessed document to chekc its structure\n",
        "print(processed_docs[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we have processed documents (or chunks) with unique **id**.\n",
        "\n",
        "To use it later, we will store the ids and pass it to ```add_documents``` method.\n",
        "\n",
        "**Note**\n",
        "\n",
        "If one did not pass the ids, randomly created id will be assigned for each items."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['da61d994-7cd8-4de7-86ad-e8dc3124ce67',\n",
              " '3b7eda28-21be-4d84-85fc-e5a7120c03e2',\n",
              " '8bb2273a-f7d2-42d7-85d4-8b80235845c4',\n",
              " '959886e7-bd55-4ea3-91f9-80cd7ba13132',\n",
              " '0cb6c40a-d948-41db-983a-4ecc35a1120b',\n",
              " '36342e32-f07c-4a11-999d-aabfba674c1c',\n",
              " '13a1a431-2f83-4fc4-ba93-ab249168b935',\n",
              " '8b2ce43e-a858-40fa-892b-b4f7411548a0',\n",
              " 'cf5a8530-a71d-4dd2-a498-ca7bfcfb758c',\n",
              " '9b8e364f-db57-46aa-9cde-62f56aff1ac5']"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#\n",
        "uuids = [doc.metadata[\"id\"] for doc in print(processed_docs[0])]\n",
        "vector_store.add_documents(print(processed_docs[0]), ids=uuids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Delete items from vector store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "vector_store.delete(ids=[uuids[2]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Upsert items to vector store"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can upsert (update and insert) item by adding documents with ID that matches with an existing document's ID by over-writing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "id_to_update = uuids[-1]\n",
        "new_doc = Document(\n",
        "    page_content=\"cooking classes for beginners and novices are offered at the community center\",\n",
        "    metadata={\"id\": id_to_update, \"location\": \"community center\", \"topic\": \"classes\"},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['9b8e364f-db57-46aa-9cde-62f56aff1ac5']"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector_store.add_documents([new_doc], ids=[id_to_update])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cooking classes for beginners and novices are offered at the community center\n"
          ]
        }
      ],
      "source": [
        "print(vector_store.get_by_ids([id_to_update])[0].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Query vector store\n",
        "\n",
        "Once your vector store has been created and the relevant documents have been added you will most likely wish to query it during the running of your chain or agent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Query directly\n",
        "\n",
        "Performing a simple similarity search can be done as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* there are cats in the pond [{'id': 'da61d994-7cd8-4de7-86ad-e8dc3124ce67', 'topic': 'animals', 'location': 'pond'}]\n",
            "* the book club meets at the library [{'id': '8b2ce43e-a858-40fa-892b-b4f7411548a0', 'topic': 'reading', 'location': 'library'}]\n",
            "* the library hosts a weekly story time for kids [{'id': 'cf5a8530-a71d-4dd2-a498-ca7bfcfb758c', 'topic': 'reading', 'location': 'library'}]\n",
            "* ducks are also found in the pond [{'id': '3b7eda28-21be-4d84-85fc-e5a7120c03e2', 'topic': 'animals', 'location': 'pond'}]\n",
            "* a new coffee shop opened on Main Street [{'id': '13a1a431-2f83-4fc4-ba93-ab249168b935', 'topic': 'food', 'location': 'Main Street'}]\n",
            "* the new art exhibit is fascinating [{'id': '0cb6c40a-d948-41db-983a-4ecc35a1120b', 'topic': 'art', 'location': 'museum'}]\n",
            "* a sculpture exhibit is also at the museum [{'id': '36342e32-f07c-4a11-999d-aabfba674c1c', 'topic': 'art', 'location': 'museum'}]\n",
            "* the market also sells fresh oranges [{'id': '959886e7-bd55-4ea3-91f9-80cd7ba13132', 'topic': 'food', 'location': 'market'}]\n",
            "* cooking classes for beginners and novices are offered at the community center [{'id': '9b8e364f-db57-46aa-9cde-62f56aff1ac5', 'topic': 'classes', 'location': 'community center'}]\n"
          ]
        }
      ],
      "source": [
        "results = vector_store.similarity_search(\"kitty\", k=10)\n",
        "for doc in results:\n",
        "    print(f\"* {doc.page_content} [{doc.metadata}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Query with filters\n",
        "\n",
        "The vectorstore supports a set of filters that can be applied against the metadata fields of the documents.\n",
        "\n",
        "You can find a list of filtering operators:\n",
        "\n",
        "| Operator | Meaning/Category        |\n",
        "|----------|-------------------------|\n",
        "| \\$eq      | Equality (==)           |\n",
        "| \\$ne      | Inequality (!=)         |\n",
        "| \\$lt      | Less than (&lt;)           |\n",
        "| \\$lte     | Less than or equal (&lt;=) |\n",
        "| \\$gt      | Greater than (>)        |\n",
        "| \\$gte     | Greater than or equal (>=) |\n",
        "| \\$in      | Special Cased (in)      |\n",
        "| \\$nin     | Special Cased (not in)  |\n",
        "| \\$between | Special Cased (between) |\n",
        "| \\$like    | Text (like)             |\n",
        "| \\$ilike   | Text (case-insensitive like) |\n",
        "| \\$and     | Logical (and)           |\n",
        "| \\$or      | Logical (or)            |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(id='3b7eda28-21be-4d84-85fc-e5a7120c03e2', metadata={'id': '3b7eda28-21be-4d84-85fc-e5a7120c03e2', 'topic': 'animals', 'location': 'pond'}, page_content='ducks are also found in the pond'),\n",
              " Document(id='da61d994-7cd8-4de7-86ad-e8dc3124ce67', metadata={'id': 'da61d994-7cd8-4de7-86ad-e8dc3124ce67', 'topic': 'animals', 'location': 'pond'}, page_content='there are cats in the pond'),\n",
              " Document(id='959886e7-bd55-4ea3-91f9-80cd7ba13132', metadata={'id': '959886e7-bd55-4ea3-91f9-80cd7ba13132', 'topic': 'food', 'location': 'market'}, page_content='the market also sells fresh oranges')]"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector_store.similarity_search(\n",
        "    \"ducks\",\n",
        "    k=10,\n",
        "    filter={\"location\": {\"$in\": [\"pond\", \"market\"]}},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Similarity search with score\n",
        "\n",
        "You can also search with score:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* [SIM=0.554739] there are cats in the pond [{'id': 'da61d994-7cd8-4de7-86ad-e8dc3124ce67', 'topic': 'animals', 'location': 'pond'}]\n"
          ]
        }
      ],
      "source": [
        "results = vector_store.similarity_search_with_score(query=\"cats\", k=1)\n",
        "for doc, score in results:\n",
        "    print(f\"* [SIM={score:3f}] {doc.page_content} [{doc.metadata}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Query by turning into retreiver\n",
        "You can also transform the vector store into a retriever for easier usage in your chains."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(id='da61d994-7cd8-4de7-86ad-e8dc3124ce67', metadata={'id': 'da61d994-7cd8-4de7-86ad-e8dc3124ce67', 'topic': 'animals', 'location': 'pond'}, page_content='there are cats in the pond')]"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever = vector_store.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 1})\n",
        "retriever.invoke(\"kitty\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
