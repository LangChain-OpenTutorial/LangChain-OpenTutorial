{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qdrant\n",
    "\n",
    "- Author: [HyeonJong Moon](https://github.com/hj0302)\n",
    "- Design: \n",
    "- Peer Review: \n",
    "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-4/sub-graph.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239937-lesson-2-sub-graphs)\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates how to utilize the features related to the `Qdrant` vector database.\n",
    "\n",
    "[`Qdrant`](https://python.langchain.com/docs/integrations/vectorstores/qdrant/) is an open-source vector similarity search engine designed to store, search, and manage high-dimensional vectors with additional payloads. It offers a production-ready service with a user-friendly API, suitable for applications such as semantic search, recommendation systems, and more.\n",
    "\n",
    "Qdrant's architecture is optimized for efficient vector similarity searches, employing advanced indexing techniques like Hierarchical Navigable Small World (HNSW) graphs to enable fast and scalable retrieval of relevant data.\n",
    "\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [Overview](#overview)\n",
    "- [Environment Setup](#environment-setup)\n",
    "- [Credentials](#credentials)\n",
    "- [Installation](#installation)\n",
    "- [Initialization](#initialization)\n",
    "- [Manage VectorStore](#manage-vectorstore)\n",
    "- [Query VectorStore](#query-vectorstore)\n",
    "\n",
    "### References\n",
    "\n",
    "- [LangChain Qdrant Reference](https://python.langchain.com/docs/integrations/vectorstores/qdrant/)\n",
    "- [Qdrant Official Reference](https://qdrant.tech/documentation/frameworks/langchain/)\n",
    "- [Qdrant Install Reference](https://qdrant.tech/documentation/guides/installation/)\n",
    "- [Qdrant Cloud Reference](https://cloud.qdrant.io)\n",
    "- [Qdrant Cloud Quickstart Reference](https://qdrant.tech/documentation/quickstart-cloud/)\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Set up the environment. You may refer to Environment Setup for more details.\n",
    "\n",
    "[Note]\n",
    "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials.\n",
    "- You can checkout the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain-opentutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "from langchain_opentutorial import package\n",
    "\n",
    "package.install(\n",
    "    [\n",
    "        \"langsmith\",\n",
    "        \"langchain_openai\",\n",
    "        \"langchain_qdrant\",\n",
    "        \"qdrant_client\",\n",
    "        \"langchain_core\",\n",
    "        \"fastembed\",\n",
    "    ],\n",
    "    verbose=False,\n",
    "    upgrade=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been set successfully.\n"
     ]
    }
   ],
   "source": [
    "# Set environment variables\n",
    "from langchain_opentutorial import set_env\n",
    "\n",
    "set_env(\n",
    "    {\n",
    "        \"OPEN_API_KEY\": \"\",\n",
    "        \"QDRANT_API_KEY\": \"\",\n",
    "        \"QDRANT_URL\": \"\",\n",
    "        \"LANGCHAIN_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
    "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
    "        \"LANGCHAIN_PROJECT\": \"Qdrant\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can alternatively set API keys such as `OPENAI_API_KEY` in a `.env` file and load them.\n",
    "\n",
    "**[Note]** If you are using a `.env` file, proceed as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credentials\n",
    "\n",
    "Create a new account or sign in to your existing one, and generate an API key for use in this notebook.\n",
    "\n",
    "1. **Log in to Qdrant Cloud** : Go to the [Qdrant Cloud](https://cloud.qdrant.io) website and log in using your email, Google account, or GitHub account.\n",
    "\n",
    "2. **Create a Cluster** : After logging in, navigate to the `\"Clusters\"` section and click the `\"Create\"` button. Choose your desired configurations and region, then click `\"Create\"` to start building your cluster. Once the cluster is created, an API key will be generated for you.\n",
    "\n",
    "3. **Retrieve and Store Your API Key** : When your cluster is created, you will receive an API key. Ensure you save this key in a secure location, as you will need it later. If you lose it, you will have to generate a new one.\n",
    "\n",
    "4. **Manage API Keys** : To create additional API keys or manage existing ones, go to the `\"Access Management\"` section in the Qdrant Cloud dashboard and select `\"Qdrant Cloud API Keys\"` Here, you can create new keys or delete existing ones.\n",
    "\n",
    "```\n",
    "QDRANT_API_KEY=\"YOUR_QDRANT_API_KEY\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "There are several main options for initializing and using the Qdrant vector store:\n",
    "\n",
    "- **Local Mode** : This mode doesn't require a separate server.\n",
    "    - **In-memory storage** (data is not persisted)\n",
    "    - **On-disk storage** (data is saved to your local machine)\n",
    "- **Docker Deployments** : You can run Qdrant using Docker.\n",
    "- **Qdrant Cloud** : Use Qdrant as a managed cloud service.\n",
    "\n",
    "For detailed instructions, see the [installation instructions](https://qdrant.tech/documentation/guides/installation/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-Memory\n",
    "\n",
    "For simple tests or quick experiments, you might choose to store data directly in memory. This means the data is automatically removed when your client terminates, typically at the end of your script or notebook session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Step 1: Initialize embeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "# Step 2: Initialize Qdrant client\n",
    "client = QdrantClient(\":memory:\")\n",
    "\n",
    "# Step 3: Create a Qdrant collection\n",
    "collection_name = \"demo_collection\"\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(size=3072, distance=Distance.COSINE),\n",
    ")\n",
    "\n",
    "# Step 4: Initialize QdrantVectorStore\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=collection_name,\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On-Disk Storage\n",
    "\n",
    "With on-disk storage, you can store your vectors directly on your hard drive without requiring a Qdrant server. This ensures that your data persists even when you restart the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Step 1: Initialize embeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "# Step 2: Initialize Qdrant client\n",
    "qdrant_path = \"./qdrant_memory\"\n",
    "client = QdrantClient(path=qdrant_path)\n",
    "\n",
    "# Step 3: Create a Qdrant collection\n",
    "collection_name = \"demo_collection\"\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(size=3072, distance=Distance.COSINE),\n",
    ")\n",
    "\n",
    "# Step 4: Initialize QdrantVectorStore\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=collection_name,\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docker Deployments\n",
    "\n",
    "You can deploy `Qdrant` in a production environment using [Docker](https://qdrant.tech/documentation/guides/installation/#docker) and [Docker Compose](https://qdrant.tech/documentation/guides/installation/#docker-compose). Refer to the Docker and Docker Compose setup instructions in the development section for detailed information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Step 1: Initialize embeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "# Step 2: Initialize Qdrant client\n",
    "url = \"http://localhost:6333\"\n",
    "client = QdrantClient(url=url)\n",
    "\n",
    "# Step 3: Create a Qdrant collection\n",
    "collection_name = \"demo_collection\"\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(size=3072, distance=Distance.COSINE),\n",
    ")\n",
    "\n",
    "# Step 4: Initialize QdrantVectorStore\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=collection_name,\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qdrant Cloud\n",
    "\n",
    "For a production environment, you can use [Qdrant Cloud](https://cloud.qdrant.io/). It offers fully managed `Qdrant` databases with features such as horizontal and vertical scaling, one-click setup and upgrades, monitoring, logging, backups, and disaster recovery. For more information, refer to the [Qdrant Cloud documentation](https://qdrant.tech/documentation/cloud/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "# Fetch the Qdrant server URL from environment variables or prompt for input\n",
    "if not os.getenv(\"QDRANT_URL\"):\n",
    "    os.environ[\"QDRANT_URL\"] = getpass.getpass(\"Enter your Qdrant Cloud URL key: \")\n",
    "url = os.environ.get(\"QDRANT_URL\")\n",
    "\n",
    "# Fetch the Qdrant API key from environment variables or prompt for input\n",
    "if not os.getenv(\"QDRANT_API_KEY\"):\n",
    "    os.environ[\"QDRANT_API_KEY\"] = getpass.getpass(\"Enter your Qdrant API key: \")\n",
    "api_key = os.environ.get(\"QDRANT_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Step 1: Initialize embeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "# Step 2: Initialize Qdrant client\n",
    "client = QdrantClient(\n",
    "    url=url,\n",
    "    api_key=api_key,\n",
    ")\n",
    "\n",
    "# Step 3: Create a Qdrant collection\n",
    "collection_name = \"demo_collection\"\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(size=3072, distance=Distance.COSINE),\n",
    ")\n",
    "\n",
    "# Step 4: Initialize QdrantVectorStore\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=collection_name,\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "Once you've established your vector store, you'll likely need to manage the collections within it. Here are some common operations you can perform:\n",
    "\n",
    "- Create a collection\n",
    "- List collections\n",
    "- Delete a collection\n",
    "- Use an existing collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Collection\n",
    "\n",
    "To create a new collection in your Qdrant instance, you can use the `QdrantClient` class from the `qdrant-client` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'my_new_collection' created successfully.\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import VectorParams, Distance\n",
    "\n",
    "# Step 1: Define collection name\n",
    "collection_name = \"my_new_collection\"\n",
    "\n",
    "# Initialize the Qdrant client\n",
    "client = QdrantClient(\n",
    "    url=url,\n",
    "    api_key=api_key,\n",
    ")\n",
    "\n",
    "# Create a new collection in Qdrant\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(size=3072, distance=Distance.COSINE),\n",
    ")\n",
    "\n",
    "# Print confirmation\n",
    "print(f\"Collection '{collection_name}' created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List Collections\n",
    "\n",
    "To list all existing collections in your Qdrant instance, you can use the `QdrantClient` class from the `qdrant-client` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection Name: my_new_collection\n",
      "Collection Name: demo_collection\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "# Initialize the Qdrant client\n",
    "client = QdrantClient(\n",
    "    url=url,\n",
    "    api_key=api_key,\n",
    ")\n",
    "\n",
    "# Retrieve and print collection names\n",
    "collections_response = client.get_collections()\n",
    "for collection in collections_response.collections:\n",
    "    print(f\"Collection Name: {collection.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete a Collection\n",
    "\n",
    "To delete a collection in Qdrant using the Python client, you can use the `delete_collection` method of the `QdrantClient` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'my_new_collection' has been deleted.\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "# Define collection name\n",
    "collection_name = \"my_new_collection\"\n",
    "\n",
    "# Initialize the Qdrant client\n",
    "client = QdrantClient(\n",
    "    url=url,\n",
    "    api_key=api_key,\n",
    ")\n",
    "\n",
    "# Delete the collection\n",
    "if client.delete_collection(collection_name=collection_name):\n",
    "    print(f\"Collection '{collection_name}' has been deleted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use an Existing Collection\n",
    "\n",
    "This code snippet demonstrates how to initialize a `QdrantVectorStore` using the `from_existing_collection` method provided by the langchain_qdrant library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "\n",
    "collection_name = \"demo_collection\"\n",
    "\n",
    "# Initialize QdrantVectorStore using from_existing_collection method\n",
    "vector_store = QdrantVectorStore.from_existing_collection(\n",
    "    embedding=embeddings,\n",
    "    collection_name=collection_name,\n",
    "    url=url,\n",
    "    api_key=api_key,\n",
    "    prefer_grpc=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Direct Initialization** \n",
    "- Offers more control by utilizing an existing `QdrantClient` instance, making it suitable for complex applications that require customized client configurations.\n",
    "\n",
    "**from_existing_collection Method** \n",
    "- Provides a simplified and concise way to connect to an existing collection, ideal for quick setups or simpler applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage VectorStore\n",
    "\n",
    "After you've created your vector store, you can interact with it by adding or deleting items. Here are some common operations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Items to the Vector Store\n",
    "\n",
    "With `Qdrant`, you can add items to your vector store using the `add_documents` function. If you add a document with an ID that already exists, the existing document will be updated with the new data. This process is called `upsert`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 222 documents to Qdrant collection 'little_prince_collection'\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from uuid import uuid4\n",
    "\n",
    "# Load the text file\n",
    "loader = TextLoader(\"./data/the_little_prince.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "# Initialize the text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len\n",
    ")\n",
    "split_docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# Generate unique IDs for documents\n",
    "uuids = [str(uuid4()) for _ in split_docs]\n",
    "\n",
    "# Add documents to the vector store\n",
    "vector_store.add_documents(documents=split_docs, ids=uuids)\n",
    "print(f\"Uploaded {len(split_docs)} documents to Qdrant collection 'little_prince_collection'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete Items from the Vector Store\n",
    "\n",
    "To remove items from your vector store, use the `delete` function. You can specify the items to delete using either IDs or filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector point with ID f2757b9a-f18e-4872-99ea-e2f180eff39c has been deleted.\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the last point ID from the list of UUIDs\n",
    "point_id = uuids[-1]\n",
    "\n",
    "# Delete the vector point by its point_id\n",
    "vector_store.delete(ids=[point_id])\n",
    "\n",
    "# Print confirmation of deletion\n",
    "print(f\"Vector point with ID {point_id} has been deleted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update items from vector store\n",
    "\n",
    "To update items in your vector store, use the `set_payload` function. This function allows you to modify the content or metadata of existing item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_point_payload(vector_store, point_id):\n",
    "    \"\"\"\n",
    "    Retrieve the payload of a point from the Qdrant collection using its ID.\n",
    "\n",
    "    Args:\n",
    "        vector_store (QdrantVectorStore): The vector store instance connected to the Qdrant collection.\n",
    "        point_id (str): The unique identifier of the point to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        dict: The payload of the retrieved point.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the point with the specified ID is not found in the collection.\n",
    "    \"\"\"\n",
    "    # Retrieve the vector point using the client\n",
    "    response = vector_store.client.retrieve(\n",
    "        collection_name=vector_store.collection_name,\n",
    "        ids=[point_id],\n",
    "    )\n",
    "\n",
    "    # Check if the response is empty\n",
    "    if not response:\n",
    "        raise ValueError(f\"Point ID {point_id} not found in the collection.\")\n",
    "\n",
    "    # Extract the payload from the retrieved point\n",
    "    point = response[0]\n",
    "    payload = point.payload\n",
    "    print(f\"Payload for point ID {point_id}: \\n{payload}\\n\")\n",
    "\n",
    "    return payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload for point ID d37cd6ce-a2a8-4550-9920-6ae885937d1b: \n",
      "{'page_content': 'The Little Prince\\nWritten By Antoine de Saiot-Exupery (1900〜1944)', 'metadata': {'source': './data/the_little_prince.txt'}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "point_id = uuids[0]\n",
    "\n",
    "# Retrieve the payload for the specified point ID\n",
    "payload = retrieve_point_payload(vector_store, point_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_point_payload(vector_store, point_id, new_payload):\n",
    "    \"\"\"\n",
    "    Update the payload of a specific point in a Qdrant collection.\n",
    "\n",
    "    Args:\n",
    "        vector_store (QdrantVectorStore): The vector store instance connected to the Qdrant collection.\n",
    "        point_id (str): The unique identifier of the point to update.\n",
    "        new_payload (dict): A dictionary containing the new payload data to set for the point.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Raises:\n",
    "        Exception: If the update operation fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Update the payload for the specified point\n",
    "        vector_store.client.set_payload(\n",
    "            collection_name=vector_store.collection_name,\n",
    "            payload=new_payload,\n",
    "            points=[point_id],\n",
    "        )\n",
    "        print(f\"Successfully updated payload for point ID {point_id}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to update payload for point ID {point_id}: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully updated payload for point ID d37cd6ce-a2a8-4550-9920-6ae885937d1b.\n"
     ]
    }
   ],
   "source": [
    "point_id = uuids[0]\n",
    "new_payload = {\"page_content\": \"The Little Prince (1943)\"}\n",
    "\n",
    "# Update the point's payload\n",
    "update_point_payload(vector_store, point_id, new_payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsert items to vector store (parallel)\n",
    "\n",
    "Use the `set_payload` function in parallel to efficiently add or update multiple items in the vector store using unique IDs, data, and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "\n",
    "def update_payloads_parallel(\n",
    "    vector_store, updates: List[Tuple[str, Dict]], num_workers: int\n",
    "):\n",
    "    \"\"\"\n",
    "    Update the payloads of multiple points in a Qdrant collection in parallel.\n",
    "\n",
    "    Args:\n",
    "        updates (List[Tuple[str, Dict]]): A list of tuples containing point IDs and their corresponding new payloads.\n",
    "        num_workers (int): Number of worker threads to use for parallel execution.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Create a ThreadPoolExecutor\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        # Submit update tasks to the executor\n",
    "        future_to_point_id = {\n",
    "            executor.submit(\n",
    "                update_point_payload, vector_store, point_id, new_payload\n",
    "            ): point_id\n",
    "            for point_id, new_payload in updates\n",
    "        }\n",
    "\n",
    "        # Process completed futures\n",
    "        for future in as_completed(future_to_point_id):\n",
    "            point_id = future_to_point_id[future]\n",
    "            try:\n",
    "                future.result()\n",
    "            except Exception as e:\n",
    "                print(f\"Error updating point ID {point_id}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload for point ID 826c9c2c-b1eb-4b11-976b-d915dff2fbff: \n",
      "{'page_content': 'Born in 1900 in Lyons, France, young Antoine was filled with a passion for adventure. When he failed an entrance exam for the Naval Academy, his interest in aviation took hold. He joined the French Army Air Force in 1921 where he first learned to fly a plane. Five years later, he would leave the military in order to begin flying air mail between remote settlements in the Sahara desert.', 'metadata': {'source': './data/the_little_prince.txt'}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "payload = retrieve_point_payload(vector_store, uuids[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully updated payload for point ID 826c9c2c-b1eb-4b11-976b-d915dff2fbff.\n",
      "Successfully updated payload for point ID 6b452e07-ff14-469d-b511-690696d709cd.\n"
     ]
    }
   ],
   "source": [
    "# Update example\n",
    "updates = [\n",
    "    (uuids[1], {\"page_content\": \"Antoine de Saint-Exupéry's passion for aviation not only fueled remarkable stories but also reflected the enduring allure of flight, inspiring technological advancements and daring feats that captivated the world over the past century.\"}),\n",
    "    (uuids[2], {\"page_content\": \"Antoine de Saint-Exupéry, born in 1900 in Lyons, France, had an adventurous spirit from a young age. After failing the Naval Academy entrance exam, his fascination with aviation began to take flight. In 1921, he joined the French Army Air Force and learned to pilot an aircraft. By 1926, he left the military to embark on a career as an airmail pilot, delivering letters to isolated communities in the vast Sahara desert\"}),\n",
    "    # Add more (point_id, new_payload) tuples as needed\n",
    "]\n",
    "\n",
    "# Update payloads in parallel\n",
    "num_workers = 4\n",
    "update_payloads_parallel(vector_store, updates, num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query VectorStore\n",
    "\n",
    "Once your vector store has been created and the relevant documents have been added you will most likely wish to query it during the running of your chain or agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query directly\n",
    "\n",
    "The most straightforward use case for the `Qdrant` vector store is performing similarity searches. Internally, your query is converted into a vector embedding, which is then used to identify similar documents within the `Qdrant` collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* \"Go and look again at the roses. You will understand now that yours is unique in all the world. Then come back to say goodbye to me, and I will make you a present of a secret.\" \n",
      "The little prince went\n",
      " [{'source': './data/the_little_prince.txt', '_id': '43256805-f69e-4f1c-b7a1-a77848f213a7', '_collection_name': 'demo_collection'}]\n",
      "\n",
      "\n",
      "* [ Chapter 8 ]\n",
      "- the rose arrives at the little prince‘s planet\n",
      " [{'source': './data/the_little_prince.txt', '_id': '33218839-ee8e-4b05-b0e3-640d14a179f6', '_collection_name': 'demo_collection'}]\n",
      "\n",
      "\n",
      "* As his lips opened slightly with the suspicious of a half-smile, I said to myself, again: \"What moves me so deeply, about this little prince who is sleeping here, is his loyalty to a flower-- the imag\n",
      " [{'source': './data/the_little_prince.txt', '_id': '108f3ac8-9931-42d0-a15a-783172f6a424', '_collection_name': 'demo_collection'}]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the significance of the rose in The Little Prince?\"\n",
    "\n",
    "# Perform similarity search in the vector store\n",
    "results = vector_store.similarity_search(\n",
    "    query=query,\n",
    "    k=3,\n",
    ")\n",
    "\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content[:200]}\\n [{res.metadata}]\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity search with score\n",
    "\n",
    "You can also search with score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [SIM=0.584964] \"Go and look again at the roses. You will understand now that yours is unique in all the world. Then come back to say goodbye to me, and I will make you a present of a secret.\" \n",
      "The little prince went\n",
      " [{'source': './data/the_little_prince.txt', '_id': '43256805-f69e-4f1c-b7a1-a77848f213a7', '_collection_name': 'demo_collection'}]\n",
      "\n",
      "\n",
      "* [SIM=0.542256] [ Chapter 8 ]\n",
      "- the rose arrives at the little prince‘s planet\n",
      " [{'source': './data/the_little_prince.txt', '_id': '33218839-ee8e-4b05-b0e3-640d14a179f6', '_collection_name': 'demo_collection'}]\n",
      "\n",
      "\n",
      "* [SIM=0.539363] As his lips opened slightly with the suspicious of a half-smile, I said to myself, again: \"What moves me so deeply, about this little prince who is sleeping here, is his loyalty to a flower-- the imag\n",
      " [{'source': './data/the_little_prince.txt', '_id': '108f3ac8-9931-42d0-a15a-783172f6a424', '_collection_name': 'demo_collection'}]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the significance of the rose in The Little Prince?\"\n",
    "\n",
    "results = vector_store.similarity_search_with_score(\n",
    "    query=query,\n",
    "    k=3,\n",
    ")\n",
    "for doc, score in results:\n",
    "    print(f\"* [SIM={score:3f}] {doc.page_content[:200]}\\n [{doc.metadata}]\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query by turning into retreiver\n",
    "\n",
    "You can also transform the vector store into a `retriever` for easier usage in your workflows or chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* \"Go and look again at the roses. You will understand now that yours is unique in all the world. Then come back to say goodbye to me, and I will make you a present of a secret.\" \n",
      "The little prince went\n",
      " [{'source': './data/the_little_prince.txt', '_id': '43256805-f69e-4f1c-b7a1-a77848f213a7', '_collection_name': 'demo_collection'}]\n",
      "\n",
      "\n",
      "* [ Chapter 8 ]\n",
      "- the rose arrives at the little prince‘s planet\n",
      " [{'source': './data/the_little_prince.txt', '_id': '33218839-ee8e-4b05-b0e3-640d14a179f6', '_collection_name': 'demo_collection'}]\n",
      "\n",
      "\n",
      "* As his lips opened slightly with the suspicious of a half-smile, I said to myself, again: \"What moves me so deeply, about this little prince who is sleeping here, is his loyalty to a flower-- the imag\n",
      " [{'source': './data/the_little_prince.txt', '_id': '108f3ac8-9931-42d0-a15a-783172f6a424', '_collection_name': 'demo_collection'}]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the significance of the rose in The Little Prince?\"\n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"k\": 3, \"score_threshold\": 0.5},\n",
    ")\n",
    "\n",
    "results = retriever.invoke(query)\n",
    "\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content[:200]}\\n [{res.metadata}]\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search with Filtering\n",
    "\n",
    "This code demonstrates how to search for and retrieve records from a Qdrant vector database based on specific metadata field values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.http.models import Filter, FieldCondition, MatchValue, MatchText\n",
    "\n",
    "def filter_and_retrieve_records(vector_store, filter_condition):\n",
    "    \"\"\"\n",
    "    Retrieve records from a Qdrant vector store based on a given filter condition.\n",
    "\n",
    "    Args:\n",
    "        vector_store (QdrantVectorStore): The vector store instance connected to the Qdrant collection.\n",
    "        filter_condition (Filter): The filter condition to apply for retrieving records.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of records matching the filter condition.\n",
    "    \"\"\"\n",
    "    all_records = []\n",
    "    next_page_offset = None\n",
    "\n",
    "    while True:\n",
    "        response, next_page_offset = vector_store.client.scroll(\n",
    "            collection_name=vector_store.collection_name,\n",
    "            scroll_filter=filter_condition,\n",
    "            limit=10,\n",
    "            offset=next_page_offset,\n",
    "            with_payload=True,\n",
    "        )\n",
    "        all_records.extend(response)\n",
    "        if next_page_offset is None:\n",
    "            break\n",
    "\n",
    "    return all_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 826c9c2c-b1eb-4b11-976b-d915dff2fbff\n",
      "Payload: {'page_content': 'Antoine de Saint-Exupéry, born in 1900 in Lyons, France, had an adventurous spirit from a young age. After failing the Naval Academy entrance exam, his fascination with aviation began to take flight. In 1921, he joined the French Army Air Force and learned to pilot an aircraft. By 1926, he left the military to embark on a career as an airmail pilot, delivering letters to isolated communities in the vast Sahara desert', 'metadata': {'source': './data/the_little_prince.txt'}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filter_condition = Filter(\n",
    "    must=[\n",
    "        FieldCondition(\n",
    "            key=\"page_content\",  # Ensure this key matches your payload structure\n",
    "            match=MatchText(text=\"Academy\")  # Use MatchValue for exact matches\n",
    "            # key=\"metadata.source\",\n",
    "            # match=MatchValue(value=\"./data/the_little_prince.txt\") \n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Retrieve records based on the filter condition\n",
    "records = filter_and_retrieve_records(vector_store, filter_condition)\n",
    "\n",
    "# Print the retrieved records\n",
    "for record in records:\n",
    "    print(f\"ID: {record.id}\\nPayload: {record.payload}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete with Filtering\n",
    "\n",
    "This code demonstrates how to delete records from a Qdrant vector database based on specific metadata field values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delete operation completed.\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client.http.models import Filter, FieldCondition, MatchValue\n",
    "\n",
    "# Define the filter condition\n",
    "filter_condition = Filter(\n",
    "    must=[\n",
    "        FieldCondition(\n",
    "            key=\"page_content\",  # Ensure this key matches your payload structure\n",
    "            match=MatchText(text=\"Academy\")  # Use MatchValue for exact matches\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Perform the delete operation\n",
    "client.delete(\n",
    "    collection_name=vector_store.collection_name,\n",
    "    points_selector=filter_condition,\n",
    "    wait=True,\n",
    ")\n",
    "\n",
    "print(\"Delete operation completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering and Updating Records\n",
    "\n",
    "This code demonstrates how to retrieve and display records from a Qdrant collection based on a specific metadata field value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully updated payload for point ID 0886275c-7e45-4995-a21f-5be3d3167982.\n",
      "Successfully updated payload for point ID 0eb82de9-c76d-4a28-8c8f-6b56111fc4d1.\n",
      "Successfully updated payload for point ID 25499f1d-ea05-41dd-a446-a43a715de9c8.\n",
      "Successfully updated payload for point ID 33218839-ee8e-4b05-b0e3-640d14a179f6.\n",
      "Successfully updated payload for point ID 4190a87e-ec1c-4d3b-a6d4-751d6063c1ca.\n",
      "Successfully updated payload for point ID 591705b9-9d39-4ea1-b008-3d5b737c0893.\n",
      "Successfully updated payload for point ID 5c091d91-a5d9-4c74-8ec2-68bc3b1b0cd9.\n",
      "Successfully updated payload for point ID 664251ca-40a4-4943-be07-bb5fafda5512.\n",
      "Successfully updated payload for point ID 6faeb5c4-687e-4e86-8d93-cef2d09432fe.\n",
      "Successfully updated payload for point ID 727bfecb-3b52-4d95-8bcd-c2d56f2c4a83.\n",
      "Successfully updated payload for point ID 76904308-4fcf-43c2-bd3c-8b5cfdfc92c2.\n",
      "Successfully updated payload for point ID 77b070d5-f44b-4ea4-b53d-a4a39fac3920.\n",
      "Successfully updated payload for point ID 7dd5df98-f2f2-4164-981b-3752775deac0.\n",
      "Successfully updated payload for point ID 834d3268-7276-4a07-8279-73e84d7cd11c.\n",
      "Successfully updated payload for point ID 92c53c2d-e95a-46ea-a962-904033d85c23.\n",
      "Successfully updated payload for point ID 95351a76-508f-417a-b6ea-2f070b7e859b.\n",
      "Successfully updated payload for point ID b2729083-ea25-484e-90fc-cf90792e7b66.\n",
      "Successfully updated payload for point ID b5363073-5cf4-4122-b8bf-df1838c97e11.\n",
      "Successfully updated payload for point ID c1588619-d102-4019-b441-53f0316ea7f7.\n",
      "Successfully updated payload for point ID cde33a15-73c1-421b-b76e-52eaaccff7af.\n",
      "Successfully updated payload for point ID d8f601f3-d8a6-4735-82d5-1c682f2e2a3d.\n",
      "Successfully updated payload for point ID db89c4dd-fa9b-4f50-844b-cf529866c82b.\n",
      "Successfully updated payload for point ID db950c23-6591-4470-8923-7512a3aace0b.\n",
      "Successfully updated payload for point ID dcf14d5a-dc40-4cec-bdb0-12802b797a7d.\n",
      "Successfully updated payload for point ID df6f5c9f-0b6f-47f6-a314-290e681f3553.\n",
      "Successfully updated payload for point ID e277e2af-7081-4d2b-a8cd-990414a665ef.\n",
      "Successfully updated payload for point ID ee1774e9-5e26-495c-b4d2-da13bbb70b73.\n",
      "Update operation completed.\n"
     ]
    }
   ],
   "source": [
    "# Define the filter condition\n",
    "filter_condition = Filter(\n",
    "    must=[\n",
    "        FieldCondition(\n",
    "            key=\"page_content\",  # Ensure this key matches your payload structure\n",
    "            match=MatchText(text=\"Chapter\")  # Use MatchValue for exact matches\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "# Retrieve matching records using the existing function\n",
    "matching_points = filter_and_retrieve_records(vector_store, filter_condition)\n",
    "\n",
    "# Prepare updates for matching points\n",
    "for point in matching_points:\n",
    "    updated_payload = point.payload.copy()\n",
    "    \n",
    "    # Update the page_content field by replacing \"Chapter\" with \"Chapter -\"\n",
    "    updated_payload[\"page_content\"] = updated_payload[\"page_content\"].replace(\"Chapter\", \"Chapter -\")\n",
    "\n",
    "    # Update the payload using the existing function\n",
    "    update_point_payload(vector_store, point.id, updated_payload)\n",
    "\n",
    "print(\"Update operation completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Search Options\n",
    "\n",
    "When using `QdrantVectorStore`, you have three options for performing similarity searches. You can select the desired search mode using the retrieval_mode parameter when you set up the class. The available modes are:\n",
    "\n",
    "- Dense Vector Search (Default)\n",
    "- Sparse Vector Search\n",
    "- Hybrid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense Vector Search\n",
    "\n",
    "To perform a search using only dense vectors:\n",
    "\n",
    "The `retrieval_mode` parameter must be set to `RetrievalMode.DENSE`. This is also the default setting.\n",
    "You need to provide a [dense embeddings](https://python.langchain.com/docs/integrations/text_embedding/) value through the embedding parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* \"Go and look again at the roses. You will understand now that yours is unique in all the world. Then come back to say goodbye to me, and I will make you a present of a secret.\" \n",
      "The little prince went\n",
      " [{'source': './data/the_little_prince.txt', '_id': '4d929432-384c-4ebc-a1fc-b6f1a9e55f65', '_collection_name': 'dense_collection'}]\n",
      "\n",
      "\n",
      "* [ Chapter 8 ]\n",
      "- the rose arrives at the little prince‘s planet\n",
      " [{'source': './data/the_little_prince.txt', '_id': 'ca9dc685-9534-40a3-b4f6-87246c294441', '_collection_name': 'dense_collection'}]\n",
      "\n",
      "\n",
      "* As his lips opened slightly with the suspicious of a half-smile, I said to myself, again: \"What moves me so deeply, about this little prince who is sleeping here, is his loyalty to a flower-- the imag\n",
      " [{'source': './data/the_little_prince.txt', '_id': '4fdeac62-8bf6-492f-a6fe-2ae9d287edbf', '_collection_name': 'dense_collection'}]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_qdrant import RetrievalMode\n",
    "\n",
    "query = \"What is the significance of the rose in The Little Prince?\"\n",
    "\n",
    "# Initialize QdrantVectorStore\n",
    "vector_store = QdrantVectorStore.from_documents(\n",
    "    documents=split_docs,\n",
    "    embedding=embeddings,\n",
    "    url=url,\n",
    "    api_key=api_key,\n",
    "    collection_name=\"dense_collection\",\n",
    "    retrieval_mode=RetrievalMode.DENSE,\n",
    ")\n",
    "\n",
    "# Perform similarity search in the vector store\n",
    "results = vector_store.similarity_search(\n",
    "    query=query,\n",
    "    k=3,\n",
    ")\n",
    "\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content[:200]}\\n [{res.metadata}]\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Vector Search\n",
    "\n",
    "To search with only sparse vectors,\n",
    "\n",
    "The `retrieval_mode` parameter should be set to `RetrievalMode.SPARSE` .\n",
    "An implementation of the [SparseEmbeddings](https://github.com/langchain-ai/langchain/blob/master/libs/partners/qdrant/langchain_qdrant/sparse_embeddings.py) interface using any sparse embeddings provider has to be provided as value to the `sparse_embedding` parameter.\n",
    "The `langchain-qdrant` package provides a FastEmbed based implementation out of the box.\n",
    "\n",
    "To use it, install the [FastEmbed](https://github.com/qdrant/fastembed) package.\n",
    "\n",
    "pip install fastembed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [ Chapter 20 ]\n",
      "- the little prince discovers a garden of roses\n",
      "But it happened that after walking for a long time through sand, and rocks, and snow, the little prince at last came upon a road. And all\n",
      " [{'source': './data/the_little_prince.txt', '_id': '5b985962-0382-41ab-92c3-26dece2f6bee', '_collection_name': 'sparse_collection'}]\n",
      "\n",
      "\n",
      "* And he went back to meet the fox. \n",
      "\"Goodbye,\" he said. \n",
      "\"Goodbye,\" said the fox. \"And now here is my secret, a very simple secret: It is only with the heart that one can see rightly; what is essential\n",
      " [{'source': './data/the_little_prince.txt', '_id': '9f494e66-602a-48f6-8b46-f2f0685592e9', '_collection_name': 'sparse_collection'}]\n",
      "\n",
      "\n",
      "* \"The men where you live,\" said the little prince, \"raise five thousand roses in the same garden-- and they do not find in it what they are looking for.\" \n",
      "\"They do not find it,\" I replied. \n",
      "\"And yet wh\n",
      " [{'source': './data/the_little_prince.txt', '_id': 'e7bab202-40c9-4d46-9b2a-f15f76344281', '_collection_name': 'sparse_collection'}]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_qdrant import FastEmbedSparse, RetrievalMode\n",
    "\n",
    "sparse_embeddings = FastEmbedSparse(model_name=\"Qdrant/bm25\")\n",
    "\n",
    "query = \"What is the significance of the rose in The Little Prince?\"\n",
    "\n",
    "# Initialize QdrantVectorStore\n",
    "vector_store = QdrantVectorStore.from_documents(\n",
    "    documents=split_docs,\n",
    "    embedding=embeddings,\n",
    "    sparse_embedding=sparse_embeddings,\n",
    "    url=url,\n",
    "    api_key=api_key,\n",
    "    collection_name=\"sparse_collection\",\n",
    "    retrieval_mode=RetrievalMode.SPARSE,\n",
    ")\n",
    "\n",
    "# Perform similarity search in the vector store\n",
    "results = vector_store.similarity_search(\n",
    "    query=query,\n",
    "    k=3,\n",
    ")\n",
    "\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content[:200]}\\n [{res.metadata}]\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid Vector Search\n",
    "To perform a hybrid search using dense and sparse vectors with score fusion,\n",
    "\n",
    "- The `retrieval_mode` parameter should be set to `RetrievalMode.HYBRID` .\n",
    "- A [ `dense embeddings` ](https://python.langchain.com/docs/integrations/text_embedding/) value should be provided to the `embedding` parameter.\n",
    "- An implementation of the [ `SparseEmbeddings` ](https://github.com/langchain-ai/langchain/blob/master/libs/partners/qdrant/langchain_qdrant/sparse_embeddings.py) interface using any sparse embeddings provider has to be provided as value to the `sparse_embedding` parameter.\n",
    "\n",
    "Note that if you've added documents with the `HYBRID` mode, you can switch to any retrieval mode when searching. Since both the dense and sparse vectors are available in the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* \"Go and look again at the roses. You will understand now that yours is unique in all the world. Then come back to say goodbye to me, and I will make you a present of a secret.\" \n",
      "The little prince went\n",
      " [{'source': './data/the_little_prince.txt', '_id': '32ad860b-6540-4e4a-a069-4d3c379fdeef', '_collection_name': 'hybrid_collection'}]\n",
      "\n",
      "\n",
      "* [ Chapter 20 ]\n",
      "- the little prince discovers a garden of roses\n",
      "But it happened that after walking for a long time through sand, and rocks, and snow, the little prince at last came upon a road. And all\n",
      " [{'source': './data/the_little_prince.txt', '_id': 'fceaaa24-8e21-4e22-9733-2587cf648ac8', '_collection_name': 'hybrid_collection'}]\n",
      "\n",
      "\n",
      "* [ Chapter 8 ]\n",
      "- the rose arrives at the little prince‘s planet\n",
      " [{'source': './data/the_little_prince.txt', '_id': '7de49cb2-7e0e-41c9-ad2a-6cccbb6daa5d', '_collection_name': 'hybrid_collection'}]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_qdrant import FastEmbedSparse, RetrievalMode\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "query = \"What is the significance of the rose in The Little Prince?\"\n",
    "\n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "sparse_embeddings = FastEmbedSparse(model_name=\"Qdrant/bm25\")\n",
    "\n",
    "# Initialize QdrantVectorStore\n",
    "vector_store = QdrantVectorStore.from_documents(\n",
    "    documents=split_docs,\n",
    "    embedding=embedding,\n",
    "    sparse_embedding=sparse_embeddings,\n",
    "    url=url,\n",
    "    api_key=api_key,\n",
    "    collection_name=\"hybrid_collection\",\n",
    "    retrieval_mode=RetrievalMode.HYBRID,\n",
    ")\n",
    "\n",
    "# Perform similarity search in the vector store\n",
    "results = vector_store.similarity_search(\n",
    "    query=query,\n",
    "    k=3,\n",
    ")\n",
    "\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content[:200]}\\n [{res.metadata}]\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-opentutorial-FZ3yxgZW-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
