{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pinecone\n",
    "\n",
    "- Author: [ro__o_jun](https://github.com/ro-jun)\n",
    "- Design: []()\n",
    "- Peer Review: \n",
    "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/08-Embeeding/01-OpenAIEmbeddings.ipynb) [![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/08-Embeeding/01-OpenAIEmbeddings.ipynb)\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial provides a comprehensive guide to integrating `Pinecone` with `LangChain` for creating and managing high-performance vector databases.  \n",
    "It explains how to set up Pinecone, `preprocess documents` , `handle stop words` , and utilize Pinecone's APIs for vector indexing and `document retrieval` . \n",
    "Additionally, it demonstrates advanced features like `hybrid search` using dense and `sparse embeddings` , `metadata filtering` , and `dynamic reranking` to build efficient and scalable search systems.  \n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [Overview](#overview)\n",
    "- [Environment Setup](#environment-setup)\n",
    "- [What is Pinecone?](#what-is-pinecone)\n",
    "- [Pinecone setup guide](#Pinecone-setup-guide)\n",
    "- [Handling Stop Words](#handling-stop-words)\n",
    "- [Data preprocessing](#data-preprocessing)\n",
    "- [Pinecone and LangChain Integration Guide: Step by Step](#pinecone-and-langchain-integration-guide-step-by-step)\n",
    "- [Create Retriever](#create-retriever)\n",
    "- [License Information](#license-information)\n",
    "\n",
    "\n",
    "\n",
    "### References\n",
    "\n",
    "- [Pinecone-LangChain](https://python.langchain.com/api_reference/pinecone/vectorstores/langchain_pinecone.vectorstores.PineconeVectorStore.html)\n",
    "- [Pinecone-official-website](https://docs.pinecone.io/integrations/langchain)\n",
    "- [Automated Summarisation and Evaluation Framework - arXiv](https://arxiv.org/abs/2310.02759)\n",
    "- [Pinecone Rerank Document](https://docs.pinecone.io/guides/inference/rerank)\n",
    "- [Model and fee structure](https://docs.pinecone.io/models/overview)\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
    "\n",
    "**[Note]**\n",
    "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
    "- You can checkout the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain-opentutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "from langchain_opentutorial import package\n",
    "\n",
    "package.install(\n",
    "    [\n",
    "        \"langchain-pinecone\",\n",
    "        \"pinecone-client\",\n",
    "        \"nltk\",\n",
    "        \"langchain_community\",\n",
    "    ],\n",
    "    verbose=False,\n",
    "    upgrade=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been set successfully.\n"
     ]
    }
   ],
   "source": [
    "# Set environment variables\n",
    "from langchain_opentutorial import set_env\n",
    "\n",
    "set_env(\n",
    "    {\n",
    "        \"OPENAI_API_KEY\": \"\",\n",
    "        \"PINECONE_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
    "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
    "        \"LANGCHAIN_PROJECT\": \"Pinecone\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Note] If you are using a `.env` file, proceed as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Pinecone?\n",
    "\n",
    "`Pinecone` is a **cloud-based** , high-performance vector database for **efficient vector storage and retrieval** in AI and machine learning applications.\n",
    "\n",
    "**Features** :\n",
    "1. **Supports SDKs** for Python, Node.js, Java, and Go.\n",
    "2. **Fully managed** : Reduces the burden of infrastructure management.\n",
    "3. **Real-time updates** : Supports real-time insertion, updates, and deletions.\n",
    "\n",
    "**Advantages** :\n",
    "1. Scalability for large datasets.\n",
    "2. Real-time data processing.\n",
    "3. High availability with cloud infrastructure.\n",
    "\n",
    "**Disadvantages** :\n",
    "1. Relatively higher cost compared to other vector databases.\n",
    "2. Limited customization options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pinecone setup guide\n",
    "\n",
    "This section explains how to set up Pinecone, including API key creation.\n",
    "\n",
    "**[steps]**\n",
    "\n",
    "1. Log in to [Pinecone](https://www.pinecone.io/)\n",
    "2. Create an API key under the `API Keys` tab.\n",
    "\n",
    "![example](./assets/04-pinecone-api-key.png)  \n",
    "![example](./assets/04-pinecone-api-key-name.png)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### notification\n",
    "\n",
    "Since the functions below are **custom implemented**, you must update the libraries below before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymupdf\n",
      "  Using cached pymupdf-1.25.1-cp39-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Using cached pymupdf-1.25.1-cp39-abi3-win_amd64.whl (16.6 MB)\n",
      "Installing collected packages: pymupdf\n",
      "Successfully installed pymupdf-1.25.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pymupdf\n",
    "# %pip install -U langchain-teddynote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Stop Words\n",
    "- Process stopwords before vectorizing text data to improve the quality of embeddings and focus on meaningful words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\thdgh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\thdgh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stop words : 179\n",
      "Print 10 stop words : ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words(\"english\")\n",
    "print(\"Number of stop words :\", len(stop_words))\n",
    "print(\"Print 10 stop words :\", stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "Below is the preprocessing process for general documents.  \n",
    "Reads all `.pdf` files under `ROOT_DIR` and saves them in `document_lsit.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import glob\n",
    "\n",
    "# Split text\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "\n",
    "split_docs = []\n",
    "\n",
    "# Convert text file to load -> List[Document] format\n",
    "files = sorted(glob.glob(\"data/*.pdf\"))\n",
    "\n",
    "for file in files:\n",
    "    loader = PyMuPDFLoader(file)\n",
    "    split_docs.extend(loader.load_and_split(text_splitter))\n",
    "\n",
    "# Check document count\n",
    "len(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Comparative Study and Framework for Automated Summariser\\nEvaluation: LangChain and Hybrid Algorithms\\nBagiya Lakshmi S (bagiyalakshmi59@gmail.com), Sanjjushri Varshini R\\n(sanjjushrivarshini@gmail.com), Rohith Mahadevan (rohithmahadev30@gmail.com), Raja CSP\\nRaman (raja.csp@gmail.com)\\nAbstract'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'data\\\\final-Research-Paper-5.pdf',\n",
       " 'file_path': 'data\\\\final-Research-Paper-5.pdf',\n",
       " 'page': 0,\n",
       " 'total_pages': 9,\n",
       " 'format': 'PDF 1.4',\n",
       " 'title': 'final-Research-Paper-5',\n",
       " 'author': '',\n",
       " 'subject': '',\n",
       " 'keywords': '',\n",
       " 'creator': '',\n",
       " 'producer': 'Skia/PDF m119 Google Docs Renderer',\n",
       " 'creationDate': '',\n",
       " 'modDate': '',\n",
       " 'trapped': ''}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_docs[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performs document processing to save DB in Pinecone. You can select `Metadata_Keys` during this process.\n",
    "\n",
    "You can additionally tag metadata and, if desired, add and process metadata ahead of time in a preprocessing task.\n",
    "\n",
    "- `split_docs` : List[Document] containing the results of document splitting.\n",
    "- `metadata_keys` : List containing metadata keys to be added to the document.\n",
    "- `min_length` : Specifies the minimum length of the document. Documents shorter than this length are excluded.\n",
    "- `use_basename` : Specifies whether to use the file name based on the source path. The default is `False` ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing of documents**\n",
    "\n",
    "- Extract the required `metadata` information.\n",
    "- Filters only data longer than the minimum length.\n",
    "- Specifies whether to use the document's `basename` . The default is `False` .\n",
    "- Here, `basename` refers to the very last part of the file.\n",
    "- For example, `/data/final-Research-Paper-5.pdf` becomes `final-Research-Paper-5.pdf`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'data\\\\final-Research-Paper-5.pdf',\n",
       " 'file_path': 'data\\\\final-Research-Paper-5.pdf',\n",
       " 'page': 0,\n",
       " 'total_pages': 9,\n",
       " 'format': 'PDF 1.4',\n",
       " 'title': 'final-Research-Paper-5',\n",
       " 'author': '',\n",
       " 'subject': '',\n",
       " 'keywords': '',\n",
       " 'creator': '',\n",
       " 'producer': 'Skia/PDF m119 Google Docs Renderer',\n",
       " 'creationDate': '',\n",
       " 'modDate': '',\n",
       " 'trapped': ''}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d45928cec57b42969e07ecef37d5afc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_teddynote.community.pinecone import preprocess_documents\n",
    "\n",
    "contents, metadatas = preprocess_documents(\n",
    "    split_docs=split_docs,\n",
    "    metadata_keys=[\"source\", \"page\", \"author\"],\n",
    "    min_length=5,\n",
    "    use_basename=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'split_docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m {key: [] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m metadata_keys}\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# 문서 전처리 작업\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[43msplit_docs\u001b[49m):\n\u001b[0;32m     19\u001b[0m     content \u001b[38;5;241m=\u001b[39m doc\u001b[38;5;241m.\u001b[39mpage_content\u001b[38;5;241m.\u001b[39mstrip()  \u001b[38;5;66;03m# 공백 제거\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(content) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m min_length:  \u001b[38;5;66;03m# 조건: 비어있지 않고 최소 길이 이상\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'split_docs' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# 입력 데이터: split_docs\n",
    "# 예시 split_docs: List[Document] 형태의 데이터\n",
    "# split_docs = [...]  # 데이터를 여기에 삽입하세요.\n",
    "\n",
    "# 설정 값\n",
    "metadata_keys = [\"source\", \"page\", \"author\"]\n",
    "min_length = 5\n",
    "use_basename = True\n",
    "\n",
    "# 결과를 저장할 변수 초기화\n",
    "contents = []\n",
    "metadatas = {key: [] for key in metadata_keys}\n",
    "\n",
    "# 문서 전처리 작업\n",
    "for doc in tqdm(split_docs):\n",
    "    content = doc.page_content.strip()  # 공백 제거\n",
    "    if content and len(content) >= min_length:  # 조건: 비어있지 않고 최소 길이 이상\n",
    "        contents.append(content)  # 콘텐츠 저장\n",
    "        for k in metadata_keys:\n",
    "            value = doc.metadata.get(k)  # 메타데이터 키 가져오기\n",
    "            if k == \"source\" and use_basename:  # use_basename 처리\n",
    "                value = os.path.basename(value)\n",
    "            try:\n",
    "                metadatas[k].append(int(value))  # 정수 변환\n",
    "            except (ValueError, TypeError):\n",
    "                metadatas[k].append(value)  # 실패 시 원본 값 저장\n",
    "\n",
    "# 결과 확인\n",
    "print(\"Processed contents:\", contents[:5])\n",
    "print(\"------------------------------------\")\n",
    "print(\"Processed metadatas keys:\", metadatas.keys())\n",
    "print(\"------------------------------------\")\n",
    "print(\"Source metadata examples:\", metadatas[\"source\"][:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Comparative Study and Framework for Automated Summariser\\nEvaluation: LangChain and Hybrid Algorithms\\nBagiya Lakshmi S (bagiyalakshmi59@gmail.com), Sanjjushri Varshini R\\n(sanjjushrivarshini@gmail.com), Rohith Mahadevan (rohithmahadev30@gmail.com), Raja CSP\\nRaman (raja.csp@gmail.com)\\nAbstract',\n",
       " 'Raman (raja.csp@gmail.com)\\nAbstract\\nAutomated Essay Score (AES) is proven to be one of the cutting-edge technologies. Scoring\\ntechniques are used for various purposes. Reliable scores are calculated based on influential',\n",
       " \"variables. Such variables can be computed by different methods based on the domain. The\\nresearch is concentrated on the user's understanding of a given topic. The analysis is based on\\na scoring index by using Large Language Models. The user can then compare and contrast the\",\n",
       " \"understanding of a topic that they recently learned. The results are then contributed towards\\nlearning analytics and progression is made for enhancing the learning ability. In this research,\\nthe focus is on summarizing a PDF document and gauging a user's understanding of its content.\",\n",
       " 'The process involves utilizing a Langchain tool to summarize the PDF and extract the essential\\ninformation. By employing this technique, the research aims to determine how well the user\\ncomprehends the summarized content.']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check documents to be saved in VectorStore\n",
    "contents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['source', 'page', 'author'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check metadata to be saved in VectorStore\n",
    "metadatas.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['final-Research-Paper-5.pdf',\n",
       " 'final-Research-Paper-5.pdf',\n",
       " 'final-Research-Paper-5.pdf',\n",
       " 'final-Research-Paper-5.pdf',\n",
       " 'final-Research-Paper-5.pdf']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the source in metadata.\n",
    "metadatas[\"source\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85, 85, 85)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check number of documents, check number of sources, check number of pages\n",
    "len(contents), len(metadatas[\"source\"]), len(metadatas[\"page\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pinecone and LangChain Integration Guide: Step by Step\n",
    "\n",
    "This guide outlines the integration of Pinecone and LangChain to set up and utilize a vector database. \n",
    "\n",
    "Below are the key steps to complete the integration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pinecone client initialization and vector database setup\n",
    "\n",
    "The provided code performs the initialization of a Pinecone client, sets up an index in Pinecone, and defines a vector database to store embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[caution]**    \n",
    "If you are considering HybridSearch, specify the metric as dotproduct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pinecone index settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[create_index]\n",
      "{'dimension': 3072,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'langchain-open-tutorial-02': {'vector_count': 85}},\n",
      " 'total_vector_count': 85}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_teddynote.community.pinecone import create_index\n",
    "\n",
    "# Initializes a connection to Pinecone using an API key from environment variables.\n",
    "pc = create_index(\n",
    "    api_key=os.environ.get(\"PINECONE_API_KEY\"),\n",
    "    index_name=\"langchain-opentutorial-index\",  # change if desired\n",
    "    dimension=3072,  # It is suitable for embedding work. (OpenAIEmbeddings: 1536, UpstageEmbeddings: 4096)\n",
    "    metric=\"dotproduct\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setting up an index using paid pods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ForbiddenException",
     "evalue": "(403)\nReason: Forbidden\nHTTP response headers: HTTPHeaderDict({'content-type': 'text/plain; charset=utf-8', 'access-control-allow-origin': '*', 'vary': 'origin,access-control-request-method,access-control-request-headers', 'access-control-expose-headers': '*', 'x-pinecone-api-version': '2024-07', 'X-Cloud-Trace-Context': '003dc97ea1faba8a2bb7756d85da15b3', 'Date': 'Wed, 08 Jan 2025 14:38:14 GMT', 'Server': 'Google Frontend', 'Content-Length': '193', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\nHTTP response body: {\"error\":{\"code\":\"FORBIDDEN\",\"message\":\"Request failed. You've reach the max pod-based indexes allowed in project Q&A Chat (0). To add more pod-based indexes, upgrade your plan.\"},\"status\":403}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mForbiddenException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpinecone\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PodSpec\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Initializes a connection to Pinecone using an API key from environment variables.\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m pc \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_index\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPINECONE_API_KEY\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlangchain-opentutorial-index-2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# change if desired\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdimension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3072\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# It is suitable for embedding work. (OpenAIEmbeddings: 1536, UpstageEmbeddings: 4096)\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdotproduct\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpod_spec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPodSpec\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43menvironment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mus-west1-gcp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpod_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mp1.x1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpods\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use Paid Pods\u001b[39;49;00m\n\u001b[0;32m     14\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thdgh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-opentutorial-XrZComUd-py3.11\\Lib\\site-packages\\langchain_teddynote\\community\\pinecone.py:51\u001b[0m, in \u001b[0;36mcreate_index\u001b[1;34m(api_key, index_name, dimension, metric, pod_spec)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pod_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     50\u001b[0m     pod_spec \u001b[38;5;241m=\u001b[39m ServerlessSpec(cloud\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maws\u001b[39m\u001b[38;5;124m\"\u001b[39m, region\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mus-east-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 51\u001b[0m \u001b[43mpc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_index\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdimension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdimension\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpod_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pc\u001b[38;5;241m.\u001b[39mdescribe_index(index_name)\u001b[38;5;241m.\u001b[39mstatus[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mready\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m     58\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\thdgh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-opentutorial-XrZComUd-py3.11\\Lib\\site-packages\\pinecone\\control\\pinecone.py:384\u001b[0m, in \u001b[0;36mPinecone.create_index\u001b[1;34m(self, name, dimension, spec, metric, timeout, deletion_protection)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspec must be of type dict, ServerlessSpec, or PodSpec\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 384\u001b[0m \u001b[43mapi_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_index\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_index_request\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCreateIndexRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdimension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdimension\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeletion_protection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_ready\u001b[39m():\n\u001b[0;32m    395\u001b[0m     status \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_status(name)\n",
      "File \u001b[1;32mc:\\Users\\thdgh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-opentutorial-XrZComUd-py3.11\\Lib\\site-packages\\pinecone\\core\\openapi\\shared\\api_client.py:761\u001b[0m, in \u001b[0;36mEndpoint.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    750\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    751\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This method is invoked when endpoints are called\u001b[39;00m\n\u001b[0;32m    752\u001b[0m \u001b[38;5;124;03m    Example:\u001b[39;00m\n\u001b[0;32m    753\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    759\u001b[0m \n\u001b[0;32m    760\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 761\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thdgh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-opentutorial-XrZComUd-py3.11\\Lib\\site-packages\\pinecone\\core\\openapi\\control\\api\\manage_indexes_api.py:273\u001b[0m, in \u001b[0;36mManageIndexesApi.__init__.<locals>.__create_index\u001b[1;34m(self, create_index_request, **kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_host_index\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_host_index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    272\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreate_index_request\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m create_index_request\n\u001b[1;32m--> 273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_with_http_info\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thdgh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-opentutorial-XrZComUd-py3.11\\Lib\\site-packages\\pinecone\\core\\openapi\\shared\\api_client.py:819\u001b[0m, in \u001b[0;36mEndpoint.call_with_http_info\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    816\u001b[0m     header_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_client\u001b[38;5;241m.\u001b[39mselect_header_content_type(content_type_headers_list)\n\u001b[0;32m    817\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheader\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m header_list\n\u001b[1;32m--> 819\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    820\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mendpoint_path\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    821\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttp_method\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mheader\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbody\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mform\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfile\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_req\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43masync_req\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_check_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_check_return_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_return_http_data_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_return_http_data_only\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_preload_content\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_request_timeout\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_formats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcollection_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thdgh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-opentutorial-XrZComUd-py3.11\\Lib\\site-packages\\pinecone\\core\\openapi\\shared\\api_client.py:380\u001b[0m, in \u001b[0;36mApiClient.call_api\u001b[1;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, async_req, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Makes the HTTP request (synchronous) and returns deserialized data.\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \n\u001b[0;32m    328\u001b[0m \u001b[38;5;124;03mTo make an async_req request, set the async_req parameter.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;124;03m    then the method will return the response directly.\u001b[39;00m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m async_req:\n\u001b[1;32m--> 380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__call_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresource_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheader_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mauth_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_return_http_data_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcollection_formats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_check_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mapply_async(\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__call_api,\n\u001b[0;32m    401\u001b[0m     (\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    418\u001b[0m     ),\n\u001b[0;32m    419\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\thdgh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-opentutorial-XrZComUd-py3.11\\Lib\\site-packages\\pinecone\\core\\openapi\\shared\\api_client.py:187\u001b[0m, in \u001b[0;36mApiClient.__call_api\u001b[1;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m PineconeApiException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    186\u001b[0m     e\u001b[38;5;241m.\u001b[39mbody \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mbody\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_response \u001b[38;5;241m=\u001b[39m response_data\n\u001b[0;32m    191\u001b[0m return_data \u001b[38;5;241m=\u001b[39m response_data\n",
      "File \u001b[1;32mc:\\Users\\thdgh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-opentutorial-XrZComUd-py3.11\\Lib\\site-packages\\pinecone\\core\\openapi\\shared\\api_client.py:175\u001b[0m, in \u001b[0;36mApiClient.__call_api\u001b[1;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[0;32m    171\u001b[0m     url \u001b[38;5;241m=\u001b[39m _host \u001b[38;5;241m+\u001b[39m resource_path\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;66;03m# perform request and return response\u001b[39;00m\n\u001b[1;32m--> 175\u001b[0m     response_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m PineconeApiException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    186\u001b[0m     e\u001b[38;5;241m.\u001b[39mbody \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mbody\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\thdgh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-opentutorial-XrZComUd-py3.11\\Lib\\site-packages\\pinecone\\core\\openapi\\shared\\api_client.py:460\u001b[0m, in \u001b[0;36mApiClient.request\u001b[1;34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrest_client\u001b[38;5;241m.\u001b[39mOPTIONS(\n\u001b[0;32m    451\u001b[0m         url,\n\u001b[0;32m    452\u001b[0m         query_params\u001b[38;5;241m=\u001b[39mquery_params,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    457\u001b[0m         body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    458\u001b[0m     )\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrest_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPOST\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPUT\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrest_client\u001b[38;5;241m.\u001b[39mPUT(\n\u001b[0;32m    471\u001b[0m         url,\n\u001b[0;32m    472\u001b[0m         query_params\u001b[38;5;241m=\u001b[39mquery_params,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    477\u001b[0m         body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    478\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\thdgh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-opentutorial-XrZComUd-py3.11\\Lib\\site-packages\\pinecone\\core\\openapi\\shared\\rest.py:345\u001b[0m, in \u001b[0;36mRESTClientObject.POST\u001b[1;34m(self, url, headers, query_params, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mPOST\u001b[39m(\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    337\u001b[0m     url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    343\u001b[0m     _request_timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    344\u001b[0m ):\n\u001b[1;32m--> 345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thdgh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-opentutorial-XrZComUd-py3.11\\Lib\\site-packages\\pinecone\\core\\openapi\\shared\\rest.py:271\u001b[0m, in \u001b[0;36mRESTClientObject.request\u001b[1;34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnauthorizedException(http_resp\u001b[38;5;241m=\u001b[39mr)\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m r\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m403\u001b[39m:\n\u001b[1;32m--> 271\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ForbiddenException(http_resp\u001b[38;5;241m=\u001b[39mr)\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m r\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m404\u001b[39m:\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFoundException(http_resp\u001b[38;5;241m=\u001b[39mr)\n",
      "\u001b[1;31mForbiddenException\u001b[0m: (403)\nReason: Forbidden\nHTTP response headers: HTTPHeaderDict({'content-type': 'text/plain; charset=utf-8', 'access-control-allow-origin': '*', 'vary': 'origin,access-control-request-method,access-control-request-headers', 'access-control-expose-headers': '*', 'x-pinecone-api-version': '2024-07', 'X-Cloud-Trace-Context': '003dc97ea1faba8a2bb7756d85da15b3', 'Date': 'Wed, 08 Jan 2025 14:38:14 GMT', 'Server': 'Google Frontend', 'Content-Length': '193', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\nHTTP response body: {\"error\":{\"code\":\"FORBIDDEN\",\"message\":\"Request failed. You've reach the max pod-based indexes allowed in project Q&A Chat (0). To add more pod-based indexes, upgrade your plan.\"},\"status\":403}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_teddynote.community.pinecone import create_index\n",
    "from pinecone import PodSpec\n",
    "\n",
    "# Initializes a connection to Pinecone using an API key from environment variables.\n",
    "pc = create_index(\n",
    "    api_key=os.environ.get(\"PINECONE_API_KEY\"),\n",
    "    index_name=\"langchain-opentutorial-index-2\",  # change if desired\n",
    "    dimension=3072,  # It is suitable for embedding work. (OpenAIEmbeddings: 1536, UpstageEmbeddings: 4096)\n",
    "    metric=\"dotproduct\",\n",
    "    pod_spec=PodSpec(\n",
    "        environment=\"us-west1-gcp\", pod_type=\"p1.x1\", pods=1\n",
    "    ),  # Use Paid Pods\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sparse Encoder\n",
    "\n",
    "- Create a sparse encoder.\n",
    "\n",
    "- Perform stopword processing.\n",
    "\n",
    "- Learn contents using Sparse Encoder. The encode learned here is used to create a Sparse Vector when storing documents in VectorStore.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.community.pinecone import (\n",
    "    create_sparse_encoder,\n",
    "    fit_sparse_encoder,\n",
    ")\n",
    "\n",
    "sparse_encoder = create_sparse_encoder(stopwords.words(\"english\"), mode=\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn Corpus on Sparse Encoder.\n",
    "\n",
    "- `save_path` : Path to save Sparse Encoder. Later, the Sparse Encoder saved in pickle format will be loaded and used for query embedding. Therefore, specify the path to save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6adf0c18afe44801988a7e08de985bcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fit_sparse_encoder]\n",
      "Saved Sparse Encoder to: ./sparse_encoder.pkl\n"
     ]
    }
   ],
   "source": [
    "# Learn contents using Sparse Encoder\n",
    "saved_path = fit_sparse_encoder(\n",
    "    sparse_encoder=sparse_encoder, contents=contents, save_path=\"./sparse_encoder.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Optional]  \n",
    "Below is the code to use when you need to reload the learned and saved Sparse Encoder later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[load_sparse_encoder]\n",
      "Loaded Sparse Encoder from: ./sparse_encoder.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<function langchain_teddynote.community.pinecone.load_sparse_encoder(file_path: str) -> Any>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_teddynote.community.pinecone import load_sparse_encoder\n",
    "\n",
    "# It is used later to load the learned sparse encoder.\n",
    "sparse_encoder = load_sparse_encoder(\"./sparse_encoder.pkl\")\n",
    "[load_sparse_encoder]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pinecone: Add to DB Index (Upsert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![04-pinecone-upsert-data](./assets/04-pinecone-upsert-data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `context`: This is the content of the document.\n",
    "- `page` : The page number of the document.\n",
    "- `source` : This is the source of the document.\n",
    "- `values` : This is an embedding of a document obtained through Embedder.\n",
    "- `sparse values` : This is an embedding of a document obtained through Sparse Encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "openai_embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upsert documents in batches without distributed processing.\n",
    "If the amount of documents is not large, use the method below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ba38d55671467b89c1f6974773deb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************-pcA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:3\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\thdgh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-opentutorial-XrZComUd-py3.11\\Lib\\site-packages\\langchain_teddynote\\community\\pinecone.py:143\u001b[0m, in \u001b[0;36mupsert_documents\u001b[1;34m(index, namespace, contents, metadatas, sparse_encoder, embedder, batch_size)\u001b[0m\n\u001b[0;32m    137\u001b[0m batch_result \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    138\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: context, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{key: metadata_batches[key][j] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m keys}}\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j, context \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(context_batch)\n\u001b[0;32m    140\u001b[0m ]\n\u001b[0;32m    142\u001b[0m ids \u001b[38;5;241m=\u001b[39m [generate_hash() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(i, i_end)]\n\u001b[1;32m--> 143\u001b[0m dense_embeds \u001b[38;5;241m=\u001b[39m \u001b[43membedder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m sparse_embeds \u001b[38;5;241m=\u001b[39m sparse_encoder\u001b[38;5;241m.\u001b[39mencode_documents(context_batch)\n\u001b[0;32m    146\u001b[0m vectors \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    147\u001b[0m     {\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: _id,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    155\u001b[0m     )\n\u001b[0;32m    156\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\thdgh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-opentutorial-XrZComUd-py3.11\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:588\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[1;34m(self, texts, chunk_size)\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[0;32m    586\u001b[0m \u001b[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[0;32m    587\u001b[0m engine \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeployment)\n\u001b[1;32m--> 588\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_len_safe_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thdgh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-opentutorial-XrZComUd-py3.11\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:483\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[1;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[0;32m    481\u001b[0m batched_embeddings: List[List[\u001b[38;5;28mfloat\u001b[39m]] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m _iter:\n\u001b[1;32m--> 483\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokens\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_chunk_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invocation_params\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    486\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    487\u001b[0m         response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mmodel_dump()\n",
      "File \u001b[1;32mc:\\Users\\thdgh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-opentutorial-XrZComUd-py3.11\\Lib\\site-packages\\openai\\resources\\embeddings.py:124\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[1;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    118\u001b[0m         embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[0;32m    119\u001b[0m             base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    120\u001b[0m         )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/embeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thdgh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-opentutorial-XrZComUd-py3.11\\Lib\\site-packages\\openai\\_base_client.py:1280\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1267\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1268\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1275\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1277\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1278\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1279\u001b[0m     )\n\u001b[1;32m-> 1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\thdgh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-opentutorial-XrZComUd-py3.11\\Lib\\site-packages\\openai\\_base_client.py:957\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    955\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 957\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thdgh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-opentutorial-XrZComUd-py3.11\\Lib\\site-packages\\openai\\_base_client.py:1061\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1058\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1060\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1061\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1064\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1065\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1069\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1070\u001b[0m )\n",
      "\u001b[1;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************-pcA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from langchain_teddynote.community.pinecone import upsert_documents\n",
    "\n",
    "upsert_documents(\n",
    "    index=pc,  # Pinecone Index\n",
    "    namespace=\"langchain-open-tutorial-01\",  # Pinecone namespace\n",
    "    contents=contents,  # Previously preprocessed document content\n",
    "    metadatas=metadatas,  # Previously preprocessed document metadata\n",
    "    sparse_encoder=sparse_encoder,  # Sparse encoder\n",
    "    embedder=openai_embeddings,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, distributed processing is performed to quickly upsert large documents. Use this for large uploads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec58eb20975472585968709a7117ea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "문서 Upsert 중:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************-pcA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:3\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\thdgh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-opentutorial-XrZComUd-py3.11\\Lib\\site-packages\\langchain_teddynote\\community\\pinecone.py:225\u001b[0m, in \u001b[0;36mupsert_documents_parallel\u001b[1;34m(index, namespace, contents, metadatas, sparse_encoder, embedder, batch_size, max_workers)\u001b[0m\n\u001b[0;32m    221\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m tqdm(\n\u001b[0;32m    223\u001b[0m     as_completed(futures), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(futures), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m문서 Upsert 중\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    224\u001b[0m ):\n\u001b[1;32m--> 225\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[0;32m    227\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(result)\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mc:\\Users\\thdgh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-opentutorial-XrZComUd-py3.11\\Lib\\site-packages\\langchain_teddynote\\community\\pinecone.py:195\u001b[0m, in \u001b[0;36mupsert_documents_parallel.<locals>.process_batch\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    186\u001b[0m batch_result \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    187\u001b[0m     {\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: context[:\u001b[38;5;241m1000\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j, context \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(context_batch)\n\u001b[0;32m    192\u001b[0m ]\n\u001b[0;32m    194\u001b[0m ids \u001b[38;5;241m=\u001b[39m [generate_hash() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(batch))]\n\u001b[1;32m--> 195\u001b[0m dense_embeds \u001b[38;5;241m=\u001b[39m \u001b[43membedder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    196\u001b[0m sparse_embeds \u001b[38;5;241m=\u001b[39m sparse_encoder\u001b[38;5;241m.\u001b[39mencode_documents(context_batch)\n\u001b[0;32m    198\u001b[0m vectors \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    199\u001b[0m     {\n\u001b[0;32m    200\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: _id,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    207\u001b[0m     )\n\u001b[0;32m    208\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\thdgh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-opentutorial-XrZComUd-py3.11\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:588\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[1;34m(self, texts, chunk_size)\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[0;32m    586\u001b[0m \u001b[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[0;32m    587\u001b[0m engine \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeployment)\n\u001b[1;32m--> 588\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_len_safe_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thdgh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-opentutorial-XrZComUd-py3.11\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:483\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[1;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[0;32m    481\u001b[0m batched_embeddings: List[List[\u001b[38;5;28mfloat\u001b[39m]] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m _iter:\n\u001b[1;32m--> 483\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokens\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_chunk_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invocation_params\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    486\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    487\u001b[0m         response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mmodel_dump()\n",
      "File \u001b[1;32mc:\\Users\\thdgh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-opentutorial-XrZComUd-py3.11\\Lib\\site-packages\\openai\\resources\\embeddings.py:124\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[1;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    118\u001b[0m         embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[0;32m    119\u001b[0m             base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    120\u001b[0m         )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/embeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thdgh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-opentutorial-XrZComUd-py3.11\\Lib\\site-packages\\openai\\_base_client.py:1280\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1267\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1268\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1275\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1277\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1278\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1279\u001b[0m     )\n\u001b[1;32m-> 1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\thdgh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-opentutorial-XrZComUd-py3.11\\Lib\\site-packages\\openai\\_base_client.py:957\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    955\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 957\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thdgh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-opentutorial-XrZComUd-py3.11\\Lib\\site-packages\\openai\\_base_client.py:1061\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1058\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1060\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1061\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1064\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1065\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1069\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1070\u001b[0m )\n",
      "\u001b[1;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************-pcA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from langchain_teddynote.community.pinecone import upsert_documents_parallel\n",
    "\n",
    "upsert_documents_parallel(\n",
    "    index=pc,  # Pinecone Index\n",
    "    namespace=\"langchain-open-tutorial-01\",  # Pinecone namespace\n",
    "    contents=contents,  # Previously preprocessed document content\n",
    "    metadatas=metadatas,  # Previously preprocessed document metadata\n",
    "    sparse_encoder=sparse_encoder,  # Sparse encoder\n",
    "    embedder=openai_embeddings,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index inquiry/delete\n",
    "\n",
    "The `describe_index_stats` method provides statistical information about the contents of an index. This method allows you to obtain information such as the number of vectors and dimensions per namespace.\n",
    "\n",
    "**Parameter** * `filter` (Optional[Dict[str, Union[str, float, int, bool, List, dict]]]): A filter that returns statistics only for vectors that meet certain conditions. Default is None * `**kwargs`: Additional keyword arguments\n",
    "\n",
    "**Return value** * `DescribeIndexStatsResponse`: Object containing statistical information about the index\n",
    "\n",
    "**Usage example** * Default usage: `index.describe_index_stats()` * Apply filter: `index.describe_index_stats(filter={'key': 'value'})`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Note] - metadata filtering is only available to paid users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 3072,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'langchain-open-tutorial-02': {'vector_count': 85}},\n",
       " 'total_vector_count': 85}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index lookup\n",
    "pc.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Delete namespace**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace 'langchain-open-tutorial-01' does not exist.\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.community.pinecone import delete_namespace\n",
    "\n",
    "delete_namespace(\n",
    "    pinecone_index=pc,\n",
    "    namespace=\"langchain-open-tutorial-01\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 3072,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'langchain-open-tutorial-02': {'vector_count': 85}},\n",
       " 'total_vector_count': 85}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are features exclusive to paid users. Metadata filtering is available to paid users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "필터를 사용한 삭제 중 오류 발생:\n",
      "UNKNOWN:Error received from peer  {created_time:\"2025-01-08T14:42:48.8544859+00:00\", grpc_status:3, grpc_message:\"Invalid request.\"}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dimension': 3072,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'langchain-open-tutorial-02': {'vector_count': 85}},\n",
       " 'total_vector_count': 85}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_teddynote.community.pinecone import delete_by_filter\n",
    "\n",
    "# Delete with metadata filtering (paid feature)\n",
    "delete_by_filter(\n",
    "    pinecone_index=pc,\n",
    "    namespace=\"angchain-open-tutorial-02\",\n",
    "    filter={\"source\": {\"$eq\": \"final-Research-Paper-5.pdf\"}},\n",
    ")\n",
    "pc.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PineconeKiwiHybridRetriever initialization parameter settings**\n",
    "\n",
    "The `init_pinecone_index` function and the `PineconeKiwiHybridRetriever` class implement a hybrid search system using Pinecone. This system combines dense and sparse vectors to perform effective document retrieval.\n",
    "\n",
    "Pinecone index initialization\n",
    "\n",
    "The `init_pinecone_index` function initializes the Pinecone index and sets up the necessary components.\n",
    "\n",
    "Parameters * `index_name` (str): Pinecone index name * `namespace` (str): Namespace to use * `api_key` (str): Pinecone API key * `sparse_encoder_pkl_path` (str): Sparse encoder pickle file path * ` stopwords` (List[str]): List of stop words * `tokenizer` (str): Tokenizer to use (default: \"kiwi\") * `embeddings` (Embeddings): Embedding model * `top_k` (int): Maximum number of documents to return (default: 10) * `alpha` (float): Weight of dense and sparse vectors Adjustment parameter (default: 0.5)\n",
    "\n",
    "**주요 기능** \n",
    "1. Pinecone index initialization and statistical information output\n",
    "2. Sparse encoder (BM25) loading and tokenizer settings\n",
    "3. Specify namespace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[init_pinecone_index]\n",
      "{'dimension': 3072,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'langchain-open-tutorial-02': {'vector_count': 85}},\n",
      " 'total_vector_count': 85}\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.community.pinecone import init_pinecone_index\n",
    "\n",
    "pinecone_params = init_pinecone_index(\n",
    "    index_name=\"langchain-opentutorial-index\",  # Pinecone 인덱스 이름\n",
    "    namespace=\"langchain-open-tutorial-02\",  # Pinecone Namespace\n",
    "    api_key=os.environ[\"PINECONE_API_KEY\"],  # Pinecone API Key\n",
    "    sparse_encoder_path=\"./sparse_encoder.pkl\",  # Sparse Encoder 저장경로(save_path)\n",
    "    stopwords=stopwords.words(\"english\"),  # 불용어 사전\n",
    "    tokenizer=\"english\",\n",
    "    embeddings=OpenAIEmbeddings(model=\"text-embedding-3-large\"),  # Dense Embedder\n",
    "    top_k=5,  # Top-K 문서 반환 개수\n",
    "    alpha=0.5,  # alpha=0.75로 설정한 경우, (0.75: Dense Embedding, 0.25: Sparse Embedding)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PineconeKiwiHybridRetriever**\n",
    "\n",
    "The class `PineconeKiwiHybridRetriever` implements a hybrid retriever combining Pinecone and Kiwi.\n",
    "\n",
    "**Main properties** * `embeddings`: Embedding model for dense vector transformations * `sparse_encoder:` Encoder for sparse vector transformations * `index`: Pinecone index object * `top_k`: Maximum number of documents to return * `alpha`: Weight adjustment parameters for dense and sparse vectors * `namespace`: Namespace within the Pinecone index.\n",
    "\n",
    "**Features** * HybridSearch Retriever combining dense and sparse vectors * Search strategy can be optimized through weight adjustment * Various dynamic metadata filtering can be applied (using `search_kwargs`: `filter`, `k`, `rerank`, ` rerank_model`, `top_n`, etc.)\n",
    "\n",
    "**Use example** \n",
    "1. Initialize required components with the `init_pinecone_index` function   \n",
    "2. Create a `PineconeKiwiHybridRetriever` instance with initialized components.  \n",
    "3. Perform a hybrid search using the generated retriever to create a `PineconeKiwiHybridRetriever`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.community.pinecone import PineconeKiwiHybridRetriever\n",
    "\n",
    "# Create a searcher\n",
    "pinecone_retriever = PineconeKiwiHybridRetriever(**pinecone_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "general search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "framework designed for summarization tasks. LangChain is employed to summarize PDF\n",
      "content, creating a condensed version of the information that retains key insights and context.\n",
      "3.3 Summarizing Content and User's Understanding Comparison\n",
      "{'context': \"framework designed for summarization tasks. LangChain is employed to summarize PDF\\ncontent, creating a condensed version of the information that retains key insights and context.\\n3.3 Summarizing Content and User's Understanding Comparison\", 'page': 4.0, 'author': '', 'source': 'final-Research-Paper-5.pdf'}\n",
      "\n",
      "====================\n",
      "\n",
      "The process involves utilizing a Langchain tool to summarize the PDF and extract the essential\n",
      "information. By employing this technique, the research aims to determine how well the user\n",
      "comprehends the summarized content.\n",
      "{'context': 'The process involves utilizing a Langchain tool to summarize the PDF and extract the essential\\ninformation. By employing this technique, the research aims to determine how well the user\\ncomprehends the summarized content.', 'page': 0.0, 'author': '', 'source': 'final-Research-Paper-5.pdf'}\n",
      "\n",
      "====================\n",
      "\n",
      "Following the summarization process using LangChain, we compare this summarized content\n",
      "with the user's understanding of the PDF content. Cosine similarity is applied to this\n",
      "comparison, generating a similarity score that indicates the degree of alignment between the\n",
      "{'context': \"Following the summarization process using LangChain, we compare this summarized content\\nwith the user's understanding of the PDF content. Cosine similarity is applied to this\\ncomparison, generating a similarity score that indicates the degree of alignment between the\", 'page': 4.0, 'author': '', 'source': 'final-Research-Paper-5.pdf'}\n",
      "\n",
      "====================\n",
      "\n",
      "It endeavours to bridge the chasm between knowledge acquisition and comprehension through\n",
      "a meticulously structured methodology. It capitalizes on the capabilities of the Langchain tool, an\n",
      "instrument\n",
      "renowned\n",
      "for\n",
      "its\n",
      "prowess\n",
      "in\n",
      "summarizing\n",
      "complex\n",
      "PDF\n",
      "documents\n",
      "while\n",
      "{'context': 'It endeavours to bridge the chasm between knowledge acquisition and comprehension through\\na meticulously structured methodology. It capitalizes on the capabilities of the Langchain tool, an\\ninstrument\\nrenowned\\nfor\\nits\\nprowess\\nin\\nsummarizing\\ncomplex\\nPDF\\ndocuments\\nwhile', 'page': 1.0, 'author': '', 'source': 'final-Research-Paper-5.pdf'}\n",
      "\n",
      "====================\n",
      "\n",
      "a comprehensive analysis of the outcomes, shedding light on the performance of different\n",
      "similarity metrics and the impact of text summarization using LangChain.\n",
      "5.1 Performance Metrics\n",
      "The evaluation was conducted on a diverse set of PDF documents, and performance was\n",
      "{'context': 'a comprehensive analysis of the outcomes, shedding light on the performance of different\\nsimilarity metrics and the impact of text summarization using LangChain.\\n5.1 Performance Metrics\\nThe evaluation was conducted on a diverse set of PDF documents, and performance was', 'page': 6.0, 'author': '', 'source': 'final-Research-Paper-5.pdf'}\n",
      "\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# execution result\n",
    "search_results = pinecone_retriever.invoke(\"Summarize PDF with LangChain\")\n",
    "for result in search_results:\n",
    "    print(result.page_content)\n",
    "    print(result.metadata)\n",
    "    print(\"\\n====================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using dynamic search_kwargs - k: specify maximum number of documents to return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "framework designed for summarization tasks. LangChain is employed to summarize PDF\n",
      "content, creating a condensed version of the information that retains key insights and context.\n",
      "3.3 Summarizing Content and User's Understanding Comparison\n",
      "{'context': \"framework designed for summarization tasks. LangChain is employed to summarize PDF\\ncontent, creating a condensed version of the information that retains key insights and context.\\n3.3 Summarizing Content and User's Understanding Comparison\", 'page': 4.0, 'author': '', 'source': 'final-Research-Paper-5.pdf'}\n",
      "\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# execution result\n",
    "search_results = pinecone_retriever.invoke(\n",
    "    \"Summarize PDF with LangChain\", search_kwargs={\"k\": 1}\n",
    ")\n",
    "for result in search_results:\n",
    "    print(result.page_content)\n",
    "    print(result.metadata)\n",
    "    print(\"\\n====================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Use dynamic `search_kwargs` - `alpha` : Weight adjustment parameters for dense and sparse vectors. Specify a value between 0 and 1. `0.5` is the default, the closer it is to 1, the higher the weight of the dense vector is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langchain. It quantifies the congruence between these two sources of information, affording\n",
      "users a tangible score that reflects their grasp of the topic. Furthermore, the research delves\n",
      "even deeper by comparing the user's understanding with the original PDF content, affording yet\n",
      "{'context': \"Langchain. It quantifies the congruence between these two sources of information, affording\\nusers a tangible score that reflects their grasp of the topic. Furthermore, the research delves\\neven deeper by comparing the user's understanding with the original PDF content, affording yet\", 'page': 1.0, 'author': '', 'source': 'final-Research-Paper-5.pdf'}\n",
      "\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# execution result\n",
    "search_results = pinecone_retriever.invoke(\n",
    "    \"Langchain and pdf\", search_kwargs={\"alpha\": 1, \"k\": 1}\n",
    ")\n",
    "for result in search_results:\n",
    "    print(result.page_content)\n",
    "    print(result.metadata)\n",
    "    print(\"\\n====================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The process involves utilizing a Langchain tool to summarize the PDF and extract the essential\n",
      "information. By employing this technique, the research aims to determine how well the user\n",
      "comprehends the summarized content.\n",
      "{'context': 'The process involves utilizing a Langchain tool to summarize the PDF and extract the essential\\ninformation. By employing this technique, the research aims to determine how well the user\\ncomprehends the summarized content.', 'page': 0.0, 'author': '', 'source': 'final-Research-Paper-5.pdf'}\n",
      "\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# execution result\n",
    "search_results = pinecone_retriever.invoke(\n",
    "    \"Langchain and pdf\", search_kwargs={\"alpha\": 0, \"k\": 1}\n",
    ")\n",
    "for result in search_results:\n",
    "    print(result.page_content)\n",
    "    print(result.metadata)\n",
    "    print(\"\\n====================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metadata 필터링**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![example](./assets/04-pinecone-metadata.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using dynamic search_kwargs - filter: Apply metadata filtering\n",
    "\n",
    "(Example) Only documents with page less than 5 are searched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "framework designed for summarization tasks. LangChain is employed to summarize PDF\n",
      "content, creating a condensed version of the information that retains key insights and context.\n",
      "3.3 Summarizing Content and User's Understanding Comparison\n",
      "{'context': \"framework designed for summarization tasks. LangChain is employed to summarize PDF\\ncontent, creating a condensed version of the information that retains key insights and context.\\n3.3 Summarizing Content and User's Understanding Comparison\", 'page': 4.0, 'author': '', 'source': 'final-Research-Paper-5.pdf'}\n",
      "\n",
      "====================\n",
      "\n",
      "The process involves utilizing a Langchain tool to summarize the PDF and extract the essential\n",
      "information. By employing this technique, the research aims to determine how well the user\n",
      "comprehends the summarized content.\n",
      "{'context': 'The process involves utilizing a Langchain tool to summarize the PDF and extract the essential\\ninformation. By employing this technique, the research aims to determine how well the user\\ncomprehends the summarized content.', 'page': 0.0, 'author': '', 'source': 'final-Research-Paper-5.pdf'}\n",
      "\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# execution result\n",
    "search_results = pinecone_retriever.invoke(\n",
    "    \"Summarize PDF with LangChain\",\n",
    "    search_kwargs={\"filter\": {\"page\": {\"$lt\": 5}}, \"k\": 2},\n",
    ")\n",
    "for result in search_results:\n",
    "    print(result.page_content)\n",
    "    print(result.metadata)\n",
    "    print(\"\\n====================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reranking applied**\n",
    "\n",
    "You can get **retrieval - reranker** results with a simple `search_kwargs` application.\n",
    "\n",
    "(However, reranker is a paid function, so please check the fee structure in advance.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reranker not used\n",
    "retrieval_results = pinecone_retriever.invoke(\n",
    "    \"pdf and langchain\",\n",
    ")\n",
    "\n",
    "# Use BGE-reranker-v2-m3 model\n",
    "reranked_results = pinecone_retriever.invoke(\n",
    "    \"pdf and langchain\",\n",
    "    search_kwargs={\"rerank\": True, \"rerank_model\": \"bge-reranker-v2-m3\", \"top_n\": 3},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Retrieval]\n",
      "The process involves utilizing a Langchain tool to summarize the PDF and extract the essential\n",
      "information. By employing this technique, the research aims to determine how well the user\n",
      "comprehends the summarized content.\n",
      "\n",
      "------------------\n",
      "\n",
      "[Reranked] rerank_score:  0.9884919\n",
      "framework designed for summarization tasks. LangChain is employed to summarize PDF\n",
      "content, creating a condensed version of the information that retains key insights and context.\n",
      "3.3 Summarizing Content and User's Understanding Comparison\n",
      "[Retrieval]\n",
      "framework designed for summarization tasks. LangChain is employed to summarize PDF\n",
      "content, creating a condensed version of the information that retains key insights and context.\n",
      "3.3 Summarizing Content and User's Understanding Comparison\n",
      "\n",
      "------------------\n",
      "\n",
      "[Reranked] rerank_score:  0.97903574\n",
      "The process involves utilizing a Langchain tool to summarize the PDF and extract the essential\n",
      "information. By employing this technique, the research aims to determine how well the user\n",
      "comprehends the summarized content.\n",
      "[Retrieval]\n",
      "It endeavours to bridge the chasm between knowledge acquisition and comprehension through\n",
      "a meticulously structured methodology. It capitalizes on the capabilities of the Langchain tool, an\n",
      "instrument\n",
      "renowned\n",
      "for\n",
      "its\n",
      "prowess\n",
      "in\n",
      "summarizing\n",
      "complex\n",
      "PDF\n",
      "documents\n",
      "while\n",
      "\n",
      "------------------\n",
      "\n",
      "[Reranked] rerank_score:  0.86130506\n",
      "Following the summarization process using LangChain, we compare this summarized content\n",
      "with the user's understanding of the PDF content. Cosine similarity is applied to this\n",
      "comparison, generating a similarity score that indicates the degree of alignment between the\n"
     ]
    }
   ],
   "source": [
    "# Compare retrieval_results and reranked_results.\n",
    "for res1, res2 in zip(retrieval_results, reranked_results):\n",
    "    print(\"[Retrieval]\")\n",
    "    print(res1.page_content)\n",
    "    print(\"\\n------------------\\n\")\n",
    "    print(\"[Reranked] rerank_score: \", res2.metadata[\"rerank_score\"])\n",
    "    print(res2.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License Information\n",
    "\n",
    "This document includes content from external sources licensed under **Creative Commons Attribution 4.0 International (CC BY 4.0)**. Proper attribution is provided as follows:\n",
    "\n",
    "- Title: *Automated Summarisation and Evaluation Framework*  \n",
    "- Authors: [Author Names]  \n",
    "- Source: [arXiv](https://arxiv.org/abs/2310.02759)  \n",
    "- License: [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)  \n",
    "\n",
    "The license permits sharing and adaptation with proper attribution. For further details, visit [Creative Commons](https://creativecommons.org/licenses/by/4.0/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-opentutorial-XrZComUd-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
