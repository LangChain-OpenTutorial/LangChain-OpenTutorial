{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25733da0",
   "metadata": {},
   "source": [
    "# {VectorStore Name}\n",
    "\n",
    "- Author: [Author Name](#Author's-Profile-Link)\n",
    "- Design: [Designer](#Designer's-Profile-Link)\n",
    "- Peer Review: [Reviewer Name](#Reviewer-Profile-Link)\n",
    "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/09-VectorStore/your-notebook-file-name) [![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/09-VectorStore/your-notebook-file-name)\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial covers how to use **{Vector Store Name}** with **LangChain** .\n",
    "\n",
    "{A short introduction to vectordb}\n",
    "\n",
    "This tutorial walks you through using **CRUD** operations with the **{VectorDB}** **storing** , **updating** , **deleting** documents, and performing **similarity-based retrieval** .\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [Overview](#overview)\n",
    "- [Environment Setup](#environment-setup)\n",
    "- [What is {vectordb}?](#what-is-{vectordb}?)\n",
    "- [Data](#data)\n",
    "- [Initial Setting {vectordb}](#initial-setting-{vectordb})\n",
    "- [Document Manager](#document-manager)\n",
    "\n",
    "\n",
    "### References\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fac085",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
    "\n",
    "**[Note]**\n",
    "- ```langchain-opentutorial``` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
    "- You can checkout the [```langchain-opentutorial```](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98da7994",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain-opentutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "800c732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "from langchain_opentutorial import package\n",
    "\n",
    "package.install(\n",
    "    [\n",
    "        \"langsmith\",\n",
    "        \"langchain-core\",\n",
    "        \"python-dotenv\",\n",
    "        \"langchain_openai\",\n",
    "        \"langchain_community\",\n",
    "        \"pymongo\",\n",
    "        \"certifi\",\n",
    "    ],\n",
    "    verbose=False,\n",
    "    upgrade=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b36bafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been set successfully.\n"
     ]
    }
   ],
   "source": [
    "# Set environment variables\n",
    "from langchain_opentutorial import set_env\n",
    "\n",
    "set_env(\n",
    "    {\n",
    "        \"OPENAI_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
    "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
    "        \"LANGCHAIN_PROJECT\": \"{Project Name}\",\n",
    "        \"MONGODB_ATLAS_CLUSTER_URI\": \"{Your Atlas URI}\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8011a0c7",
   "metadata": {},
   "source": [
    "You can alternatively set API keys such as ```OPENAI_API_KEY``` in a ```.env``` file and load them.\n",
    "\n",
    "[Note] This is not necessary if you've already set the required API keys in previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70d7e764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6890920d",
   "metadata": {},
   "source": [
    "## What is {vectordb}?\n",
    "\n",
    "Please write down what you need to set up the Vectorstore here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3b5bd2",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "This part walks you through the **data preparation process** .\n",
    "\n",
    "This section includes the following components:\n",
    "\n",
    "- Introduce Data\n",
    "\n",
    "- Preprocessing Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508ae7f7",
   "metadata": {},
   "source": [
    "### Introduce Data\n",
    "\n",
    "In this tutorial, we will use the fairy tale **ðŸ“— The Little Prince** in PDF format as our data.\n",
    "\n",
    "This material complies with the **Apache 2.0 license** .\n",
    "\n",
    "The data is used in a text (.txt) format converted from the original PDF.\n",
    "\n",
    "You can view the data at the link below.\n",
    "- [Data Link](https://huggingface.co/datasets/sohyunwriter/the_little_prince)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004ea4f4",
   "metadata": {},
   "source": [
    "### Preprocessing Data\n",
    "\n",
    "In this tutorial section, we will preprocess the text data from The Little Prince and convert it into a list of ```LangChain Document``` objects with metadata. \n",
    "\n",
    "Each document chunk will include a ```title``` field in the metadata, extracted from the first line of each section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e4cac64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import re\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def preprocessing_data(content: str) -> List[Document]:\n",
    "    # 1. Split the text by double newlines to separate sections\n",
    "    blocks = content.split(\"\\n\\n\")\n",
    "\n",
    "    # 2. Initialize the text splitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,  # Maximum number of characters per chunk\n",
    "        chunk_overlap=50,  # Overlap between chunks to preserve context\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \"],  # Order of priority for splitting\n",
    "    )\n",
    "\n",
    "    documents = []\n",
    "\n",
    "    # 3. Loop through each section\n",
    "    for block in blocks:\n",
    "        lines = block.strip().splitlines()\n",
    "        if not lines:\n",
    "            continue\n",
    "\n",
    "        # Extract title from the first line using square brackets [ ]\n",
    "        first_line = lines[0]\n",
    "        title_match = re.search(r\"\\[(.*?)\\]\", first_line)\n",
    "        title = title_match.group(1).strip() if title_match else \"\"\n",
    "\n",
    "        # Remove the title line from content\n",
    "        body = \"\\n\".join(lines[1:]).strip()\n",
    "        if not body:\n",
    "            continue\n",
    "\n",
    "        # 4. Chunk the section using the text splitter\n",
    "        chunks = text_splitter.split_text(body)\n",
    "\n",
    "        # 5. Create a LangChain Document for each chunk with the same title metadata\n",
    "        for chunk in chunks:\n",
    "            documents.append(Document(page_content=chunk, metadata={\"title\": title}))\n",
    "\n",
    "    print(f\"Generated {len(documents)} chunked documents.\")\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d091a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 262 chunked documents.\n"
     ]
    }
   ],
   "source": [
    "# Load the entire text file\n",
    "with open(\"./data/the_little_prince.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "# Preprocessing Data\n",
    "\n",
    "docs = preprocessing_data(content=content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1977d4ff",
   "metadata": {},
   "source": [
    "## Initial Setting {vectordb}\n",
    "\n",
    "This part walks you through the initial setup of **{vectordb}** .\n",
    "\n",
    "This section includes the following components:\n",
    "\n",
    "- Load Embedding Model\n",
    "\n",
    "- Load {vectordb} Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eee56b2",
   "metadata": {},
   "source": [
    "### Load Embedding Model\n",
    "\n",
    "In the **Load Embedding Model** section, you'll learn how to load an embedding model.\n",
    "\n",
    "This tutorial uses **OpenAI's** **API-Key** for loading the model.\n",
    "\n",
    "*ðŸ’¡ If you prefer to use another embedding model, see the instructions below.*\n",
    "- [Embedding Models](https://python.langchain.com/docs/integrations/text_embedding/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bd5c3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f65795",
   "metadata": {},
   "source": [
    "### Load {vectordb} Client\n",
    "\n",
    "In the **Load {vectordb} Client** section, we cover how to load the **database client object** using the **Python SDK** for **{vectordb}** .\n",
    "- [Python SDK Docs]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed0ebad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import certifi\n",
    "\n",
    "# Create Database Client Object Function\n",
    "\n",
    "\n",
    "\n",
    "def get_db_client(URI):\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    Initializes and returns a VectorStore client instance.\n",
    "\n",
    "\n",
    "    This function loads configuration (e.g., API key, host) from environment\n",
    "\n",
    "\n",
    "    variables or default values and creates a client object to interact\n",
    "\n",
    "\n",
    "    with the {vectordb} Python SDK.\n",
    "\n",
    "\n",
    "\n",
    "    Returns:\n",
    "\n",
    "\n",
    "        client:ClientType - An instance of the {vectordb} client.\n",
    "\n",
    "\n",
    "\n",
    "    Raises:\n",
    "\n",
    "\n",
    "        ValueError: If required configuration is missing.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    client = MongoClient(URI, tlsCAFile=certifi.where())\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b5f4116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DB Client Object\n",
    "URI = os.getenv(\"MONGODB_ATLAS_CLUSTER_URI\")\n",
    "client = get_db_client(URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0a54d1",
   "metadata": {},
   "source": [
    "### Create Collection\n",
    "\n",
    "If you are successfully connected to ```MongoDBAtlas```, there is a sample collection.\n",
    "\n",
    "But in this tutorial we will create a new collection with ```MongoDBAtlasCollectionManager```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "891a6995",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.mongodb_atlas import MongoDBAtlasCollectionManager\n",
    "\n",
    "# Get collectionManager\n",
    "collectionManager = MongoDBAtlasCollectionManager(\n",
    "    db_name=\"langchain-opentutorial-db\", client=client\n",
    ")\n",
    "\n",
    "# Create new collection\n",
    "collectionManager.create_collection(\"tutorial_collection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8d1198",
   "metadata": {},
   "source": [
    "### Create Vector Search Index\n",
    "\n",
    "To perform ector search in Atlas, you must create an **Atlas Vector Search Index**.\n",
    "\n",
    "First, either define **Atlas Search Index** or **Atlas Vector Search Index** using `SearchIndexModel` object.\n",
    "\n",
    "- `definition` : define the **Search Index**.\n",
    "\n",
    "- `name` : query the **Search Index** by name.\n",
    "\n",
    "To learn more about `definition` of `SearchIndexModel` , see [Review Atlas Search Index Syntax](https://www.mongodb.com/docs/atlas/atlas-search/index-definitions/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b7e2efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo.operations import SearchIndexModel\n",
    "\n",
    "TEST_SEARCH_INDEX_NAME = \"test_search_index\"\n",
    "TEST_VECTOR_SEARCH_INDEX_NAME = \"test_vector_index\"\n",
    "\n",
    "search_index = SearchIndexModel(\n",
    "    definition={\n",
    "        \"mappings\": {\"dynamic\": True},\n",
    "    },\n",
    "    name=TEST_SEARCH_INDEX_NAME,\n",
    ")\n",
    "\n",
    "vector_index = SearchIndexModel(\n",
    "    definition={\n",
    "        \"fields\": [\n",
    "            {\n",
    "                \"type\": \"vector\",\n",
    "                \"numDimensions\": 1536,\n",
    "                \"path\": \"embedding\",\n",
    "                \"similarity\": \"cosine\",\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    name=TEST_VECTOR_SEARCH_INDEX_NAME,\n",
    "    type=\"vectorSearch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619aae20",
   "metadata": {},
   "source": [
    "Now we can create **index** based on ```SearchIndexModel``` defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bddcfa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create actual index\n",
    "collectionManager.create_index(TEST_SEARCH_INDEX_NAME, search_index)\n",
    "collectionManager.create_index(TEST_VECTOR_SEARCH_INDEX_NAME, vector_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5a97a0",
   "metadata": {},
   "source": [
    "## Document Manager\n",
    "\n",
    "To support the **Langchain-Opentutorial** , we implemented a custom set of **CRUD** functionalities for VectorDBs. \n",
    "\n",
    "The following operations are included:\n",
    "\n",
    "- ```upsert``` : Update existing documents or insert if they donâ€™t exist\n",
    "\n",
    "- ```upsert_parallel``` : Perform upserts in parallel for large-scale data\n",
    "\n",
    "- ```similarity_search``` : Search for similar documents based on embeddings\n",
    "\n",
    "- ```delete``` : Remove documents based on filter conditions\n",
    "\n",
    "Each of these features is implemented as class methods specific to each VectorDB.\n",
    "\n",
    "In this tutorial, you can easily utilize these methods to interact with your VectorDB.\n",
    "\n",
    "*We plan to continuously expand the functionality by adding more common operations in the future.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a40601",
   "metadata": {},
   "source": [
    "### Create Instance\n",
    "\n",
    "First, we create an instance of the **{vectordb}** helper class to use its CRUD functionalities.\n",
    "\n",
    "This class is initialized with the **{vectordb} Python SDK client instance** and the **embedding model instance** , both of which were defined in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dccab807",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.mongodb_atlas import MongoDBAtlasCRUDManager\n",
    "\n",
    "crud_manager = MongoDBAtlasCRUDManager(\n",
    "    client=client,\n",
    "    db_name=\"langchain-opentutorial-db\",\n",
    "    collection_name=\"tutorial_collection\",\n",
    "    embedding=embedding,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c0c67f",
   "metadata": {},
   "source": [
    "Now you can use the following **CRUD** operations with the ```crud_manager``` instance.\n",
    "\n",
    "These instance allow you to easily manage documents in your **{vectordb}** ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6c53c5",
   "metadata": {},
   "source": [
    "### Upsert Document\n",
    "\n",
    "**Update** existing documents or **insert** if they donâ€™t exist\n",
    "\n",
    "**âœ… Args**\n",
    "\n",
    "- ```texts``` : Iterable[str] â€“ List of text contents to be inserted/updated.\n",
    "\n",
    "- ```metadatas``` : Optional[List[Dict]] â€“ List of metadata dictionaries for each text (optional).\n",
    "\n",
    "- ```ids``` : Optional[List[str]] â€“ Custom IDs for the documents. If not provided, IDs will be auto-generated.\n",
    "\n",
    "- ```**kwargs``` : Extra arguments for the underlying vector store.\n",
    "\n",
    "**ðŸ”„ Return**\n",
    "\n",
    "- None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3a6c32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "ids = [str(uuid4()) for _ in docs]\n",
    "\n",
    "\n",
    "\n",
    "args = {\n",
    "    \"texts\": [doc.page_content for doc in docs[:2]],\n",
    "    \"metadatas\": [doc.metadata for doc in docs[:2]],\n",
    "    \"ids\": ids[:2],\n",
    "    # if you want args, add params.\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "crud_manager.upsert(**args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278fe1ed",
   "metadata": {},
   "source": [
    "### Upsert Parallel Document\n",
    "\n",
    "Perform **upserts** in **parallel** for large-scale data\n",
    "\n",
    "**âœ… Args**\n",
    "\n",
    "- ```texts``` : Iterable[str] â€“ List of text contents to be inserted/updated.\n",
    "\n",
    "- ```metadatas``` : Optional[List[Dict]] â€“ List of metadata dictionaries for each text (optional).\n",
    "\n",
    "- ```ids``` : Optional[List[str]] â€“ Custom IDs for the documents. If not provided, IDs will be auto-generated.\n",
    "\n",
    "- ```batch_size``` : int â€“ Number of documents per batch (default: 32).\n",
    "\n",
    "- ```workers``` : int â€“ Number of parallel workers (default: 10).\n",
    "\n",
    "- ```**kwargs``` : Extra arguments for the underlying vector store.\n",
    "\n",
    "**ðŸ”„ Return**\n",
    "\n",
    "- None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a89dd8e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "UpdateResult({'n': 1, 'electionId': ObjectId('7fffffff00000000000000e6'), 'opTime': {'ts': Timestamp(1746730571, 8), 't': 230}, 'nModified': 1, 'ok': 1.0, '$clusterTime': {'clusterTime': Timestamp(1746730571, 8), 'signature': {'hash': b'Yx\\xcdv\\x8b\\xca)6\\xc5\\xd3\\xe3\\xa8XFDV>4s\\x8d', 'keyId': 7449669926517735428}}, 'operationTime': Timestamp(1746730571, 8), 'updatedExisting': True}, acknowledged=True) is not a valid request",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 10\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01muuid\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m uuid4\n\u001b[0;32m      3\u001b[0m args \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtexts\u001b[39m\u001b[38;5;124m\"\u001b[39m: [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs],\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadatas\u001b[39m\u001b[38;5;124m\"\u001b[39m: [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs],\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m: ids,\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# if you want args, add params.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m }\n\u001b[1;32m---> 10\u001b[0m \u001b[43mcrud_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsert_parallel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\workspace\\LangChain_project\\LangChain-OpenTutorial\\09-VectorStore\\utils\\mongodb_atlas.py:313\u001b[0m, in \u001b[0;36mMongoDBAtlasCRUDManager.upsert_parallel\u001b[1;34m(self, texts, metadatas, ids, batch_size, workers, **kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m     futures\u001b[38;5;241m.\u001b[39mappend(future)\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m as_completed(futures):\n\u001b[1;32m--> 313\u001b[0m     \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\harry\\.conda\\envs\\cp311\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\harry\\.conda\\envs\\cp311\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\harry\\.conda\\envs\\cp311\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mf:\\workspace\\LangChain_project\\LangChain-OpenTutorial\\09-VectorStore\\utils\\mongodb_atlas.py:274\u001b[0m, in \u001b[0;36mMongoDBAtlasCRUDManager.upsert_parallel.<locals>.upsert_batch\u001b[1;34m(batch, batch_ids)\u001b[0m\n\u001b[0;32m    272\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insert_one(doc)\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m requests:\n\u001b[1;32m--> 274\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbulk_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequests\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\harry\\.conda\\envs\\cp311\\Lib\\site-packages\\pymongo\\_csot.py:119\u001b[0m, in \u001b[0;36mapply.<locals>.csot_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _TimeoutContext(timeout):\n\u001b[0;32m    118\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\harry\\.conda\\envs\\cp311\\Lib\\site-packages\\pymongo\\synchronous\\collection.py:788\u001b[0m, in \u001b[0;36mCollection.bulk_write\u001b[1;34m(self, requests, ordered, bypass_document_validation, session, comment, let)\u001b[0m\n\u001b[0;32m    786\u001b[0m         request\u001b[38;5;241m.\u001b[39m_add_to_bulk(blk)\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m--> 788\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequest\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m is not a valid request\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    790\u001b[0m write_concern \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_concern_for(session)\n\u001b[0;32m    791\u001b[0m bulk_api_result \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mexecute(write_concern, session, _Op\u001b[38;5;241m.\u001b[39mINSERT)\n",
      "\u001b[1;31mTypeError\u001b[0m: UpdateResult({'n': 1, 'electionId': ObjectId('7fffffff00000000000000e6'), 'opTime': {'ts': Timestamp(1746730571, 8), 't': 230}, 'nModified': 1, 'ok': 1.0, '$clusterTime': {'clusterTime': Timestamp(1746730571, 8), 'signature': {'hash': b'Yx\\xcdv\\x8b\\xca)6\\xc5\\xd3\\xe3\\xa8XFDV>4s\\x8d', 'keyId': 7449669926517735428}}, 'operationTime': Timestamp(1746730571, 8), 'updatedExisting': True}, acknowledged=True) is not a valid request"
     ]
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "args = {\n",
    "    \"texts\": [doc.page_content for doc in docs],\n",
    "    \"metadatas\": [doc.metadata for doc in docs],\n",
    "    \"ids\": ids,\n",
    "    # if you want args, add params.\n",
    "}\n",
    "\n",
    "crud_manager.upsert_parallel(**args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beea197",
   "metadata": {},
   "source": [
    "### Similarity Search\n",
    "\n",
    "Search for **similar documents** based on **embeddings** .\n",
    "\n",
    "This method uses **\"cosine similarity\"** .\n",
    "\n",
    "\n",
    "**âœ… Args**\n",
    "\n",
    "- ```query``` : str â€“ The text query for similarity search.\n",
    "\n",
    "- ```k``` : int â€“ Number of top results to return (default: 10).\n",
    "\n",
    "```**kwargs``` : Additional search options (e.g., filters).\n",
    "\n",
    "**ðŸ”„ Return**\n",
    "\n",
    "- ```results``` : List[Document] â€“ A list of LangChain Document objects ranked by similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5859782b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search by Query\n",
    "\n",
    "# results = crud_manager.search(query=\"What is essential is invisible to the eye.\",k=3)\n",
    "# for idx,doc in enumerate(results):\n",
    "#     print(f\"Rank {idx} | Title : {doc.metadata['title']}\")\n",
    "#     print(f\"Contents : {doc.page_content}\")\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2577dd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter Search\n",
    "\n",
    "# results = crud_manager.search(query=\"Which asteroid did the little prince come from?\",k=3,<filters>={\"title\":\"Chapter 4\"})\n",
    "# for idx,doc in enumerate(results):\n",
    "#     print(f\"Rank {idx} | Title : {doc.metadata['title']}\")\n",
    "#     print(f\"Contents : {doc.page_content}\")\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f140c0e2",
   "metadata": {},
   "source": [
    "### As_retrever\n",
    "\n",
    "The ```as_retriever()``` method creates a LangChain-compatible retriever wrapper.\n",
    "\n",
    "This function allows a ```DocumentManager``` class to return a retriever object by wrapping the internal ```search()``` method, while staying lightweight and independent from full LangChain ```VectorStore``` dependencies.\n",
    "\n",
    "The retriever obtained through this function can be used the same as the existing LangChain retriever and is **compatible with LangChain Pipeline(e.g. RetrievalQA,ConversationalRetrievalChain,Tool,...)**.\n",
    "\n",
    "**âœ… Args**\n",
    "\n",
    "- ```search_fn``` : Callable - The function used to retrieve relevant documents. Typically this is ```self.search``` from a ```DocumentManager``` instance.\n",
    "\n",
    "- ```search_kwargs``` : Optional[Dict] - A dictionary of keyword arguments passed to ```search_fn```, such as ```k``` for top-K results or metadata filters.\n",
    "\n",
    "**ðŸ”„ Return**\n",
    "\n",
    "- ```LightCustomRetriever``` :BaseRetriever - A lightweight LangChain-compatible retriever that internally uses the given ```search_fn``` and ```search_kwargs```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86de7842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ret = crud_manager.as_retriever(\n",
    "#     search_fn=crud_manager.search, search_kwargs=<kwargs> # e.g. {\"k\": 1, \"where\": {\"title\": \"\"}}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7142d29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ret.invoke(\"Which asteroid did the little prince come from?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad0ed0c",
   "metadata": {},
   "source": [
    "### Delete Document\n",
    "\n",
    "Remove documents based on filter conditions\n",
    "\n",
    "**âœ… Args**\n",
    "\n",
    "- ```ids``` : Optional[List[str]] â€“ List of document IDs to delete. If None, deletion is based on filter.\n",
    "\n",
    "- ```filters``` : Optional[Dict] â€“ Dictionary specifying filter conditions (e.g., metadata match).\n",
    "\n",
    "- ```**kwargs``` : Any additional parameters.\n",
    "\n",
    "**ðŸ”„ Return**\n",
    "\n",
    "- None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3a2c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete by ids\n",
    "\n",
    "# ids = [] # The 'ids' value you want to delete\n",
    "# crud_manager.delete(ids=ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bcb4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete by ids with filters\n",
    "\n",
    "# ids = [] # The `ids` value corresponding to chapter 6\n",
    "# crud_manager.delete(ids=ids,filters={\"title\":\"chapter 6\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d42d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete All\n",
    "\n",
    "# crud_manager.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cp311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
