{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pinecone\n",
    "\n",
    "- Author: [ro__o_jun](https://github.com/ro-jun)\n",
    "- Design: []()\n",
    "- Peer Review: \n",
    "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/08-Embeeding/01-OpenAIEmbeddings.ipynb) [![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/08-Embeeding/01-OpenAIEmbeddings.ipynb)\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial provides a comprehensive guide to integrating `Pinecone` with `LangChain` for creating and managing high-performance vector databases.  \n",
    "\n",
    "It explains how to set up `Pinecone` , `preprocess documents` , `handle stop words` , and utilize Pinecone's APIs for vector indexing and `document retrieval` .  \n",
    "\n",
    "Additionally, it demonstrates advanced features like `hybrid search` using `dense` and `sparse embeddings` , `metadata filtering` , and `dynamic reranking` to build efficient and scalable search systems.  \n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [Overview](#overview)\n",
    "- [Environment Setup](#environment-setup)\n",
    "- [What is Pinecone?](#what-is-pinecone)\n",
    "- [Pinecone setup guide](#Pinecone-setup-guide)\n",
    "- [Handling Stop Words](#handling-stop-words)\n",
    "- [Data preprocessing](#data-preprocessing)\n",
    "- [Pinecone and LangChain Integration Guide: Step by Step](#pinecone-and-langchain-integration-guide-step-by-step)\n",
    "- [Pinecone: Add to DB Index (Upsert)](#pinecone-add-to-db-index-upsert)\n",
    "- [Index inquiry/delete](#index-inquirydelete)\n",
    "- [Create HybridRetrieve](#create-hybridretrieve)\n",
    "\n",
    "\n",
    "### References\n",
    "\n",
    "- [Langchain-PineconeVectorStore](https://python.langchain.com/api_reference/pinecone/vectorstores/langchain_pinecone.vectorstores.PineconeVectorStore.html)\n",
    "- [Langchain-Retrievers](https://python.langchain.com/docs/integrations/retrievers/pinecone_hybrid_search/)\n",
    "- [Pinecone-Docs](https://docs.pinecone.io/guides/get-started/overview)\n",
    "- [Pinecone-Docs-integrations](https://docs.pinecone.io/integrations/langchain)\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
    "\n",
    "**[Note]**\n",
    "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
    "- You can checkout the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain-opentutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "from langchain_opentutorial import package\n",
    "\n",
    "package.install(\n",
    "    [\n",
    "        \"langchain-pinecone\",\n",
    "        \"pinecone-client\",\n",
    "        \"nltk\",\n",
    "        \"langchain_community\",\n",
    "        \"pymupdf\",\n",
    "        \"pinecone-text\",\n",
    "    ],\n",
    "    verbose=False,\n",
    "    upgrade=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been set successfully.\n"
     ]
    }
   ],
   "source": [
    "# Set environment variables\n",
    "from langchain_opentutorial import set_env\n",
    "\n",
    "set_env(\n",
    "    {\n",
    "        \"OPENAI_API_KEY\": \"\",\n",
    "        \"PINECONE_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
    "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
    "        \"LANGCHAIN_PROJECT\": \"Pinecone\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Note] If you are using a `.env` file, proceed as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Pinecone?\n",
    "\n",
    "`Pinecone` is a **cloud-based** , high-performance vector database for **efficient vector storage and retrieval** in AI and machine learning applications.\n",
    "\n",
    "**Features** :\n",
    "1. **Supports SDKs** for Python, Node.js, Java, and Go.\n",
    "2. **Fully managed** : Reduces the burden of infrastructure management.\n",
    "3. **Real-time updates** : Supports real-time insertion, updates, and deletions.\n",
    "\n",
    "**Advantages** :\n",
    "1. Scalability for large datasets.\n",
    "2. Real-time data processing.\n",
    "3. High availability with cloud infrastructure.\n",
    "\n",
    "**Disadvantages** :\n",
    "1. Relatively higher cost compared to other vector databases.\n",
    "2. Limited customization options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pinecone setup guide\n",
    "\n",
    "This section explains how to set up `Pinecone` , including `API key` creation.\n",
    "\n",
    "**[steps]**\n",
    "\n",
    "1. Log in to [Pinecone](https://www.pinecone.io/)\n",
    "2. Create an API key under the `API Keys` tab.\n",
    "\n",
    "![example](./assets/04-pinecone-api-key-name.png)  \n",
    "![example](./assets/04-pinecone-api-key.png)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Stop Words\n",
    "- Process stopwords before vectorizing text data to improve the quality of embeddings and focus on meaningful words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\thdgh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\thdgh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customizing stopword users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stop words : 179\n",
      "Print 10 stop words : ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n",
      "\n",
      "Number of stop words: 182\n",
      "Print 10 stop words: ['', 'again', 'will', 'all', \"haven't\", \"couldn't\", 'didn', \"isn't\", 'few', 'over']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "default_stop_words = stopwords.words(\"english\")\n",
    "print(\"Number of stop words :\", len(default_stop_words))\n",
    "print(\"Print 10 stop words :\", default_stop_words[:10])\n",
    "print()\n",
    "\n",
    "# Add any stop words you want to add.\n",
    "user_defined_stop_words = [\n",
    "    \"example1\",\n",
    "    \"example2\",\n",
    "    \"\",\n",
    "]\n",
    "\n",
    "combined_stop_words = list(set(default_stop_words + user_defined_stop_words))\n",
    "\n",
    "print(\"Number of stop words:\", len(combined_stop_words))\n",
    "print(\"Print 10 stop words:\", combined_stop_words[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "Below is the preprocessing process for general documents.  \n",
    "Reads all `.pdf` files under `ROOT_DIR` and saves them in `document_lsit.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents after processing: 414\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import glob\n",
    "\n",
    "# Text cleaning function\n",
    "def clean_text(text):\n",
    "    # Remove non-ASCII characters\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "    # Remove multiple spaces and trim the text\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    # Remove abnormal strings with special characters and numbers\n",
    "    text = re.sub(r\"[0-9#%$&()*+,\\-./:;<=>?@\\[\\]^_`{|}~]{3,}\", '', text)\n",
    "    return text\n",
    "\n",
    "# Initialize text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "\n",
    "split_docs = []\n",
    "\n",
    "# Read and preprocess PDF files\n",
    "files = sorted(glob.glob(\"data/*.pdf\"))\n",
    "\n",
    "for file in files:\n",
    "    loader = PyMuPDFLoader(file)\n",
    "    raw_docs = loader.load_and_split(text_splitter)\n",
    "    \n",
    "    for doc in raw_docs:\n",
    "        # Filter non-text data\n",
    "        doc.page_content = clean_text(doc.page_content)\n",
    "        split_docs.append(doc)\n",
    "\n",
    "# Check the number of documents\n",
    "print(f\"Number of documents after processing: {len(split_docs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'up. I have a serious reason: he is the best friend I have in the world. I have another reason: this grown-up understands everything, even books about children. I have a third reason: he lives in France where he is hungry and cold. He needs cheering up. If all these'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_docs[12].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'data\\\\TheLittlePrince.pdf',\n",
       " 'file_path': 'data\\\\TheLittlePrince.pdf',\n",
       " 'page': 2,\n",
       " 'total_pages': 64,\n",
       " 'format': 'PDF 1.3',\n",
       " 'title': '',\n",
       " 'author': 'Paula MacDowell',\n",
       " 'subject': '',\n",
       " 'keywords': '',\n",
       " 'creator': 'Safari',\n",
       " 'producer': 'Mac OS X 10.10.5 Quartz PDFContext',\n",
       " 'creationDate': \"D:20160209011144Z00'00'\",\n",
       " 'modDate': \"D:20160209011144Z00'00'\",\n",
       " 'trapped': ''}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_docs[12].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performs document processing to save DB in Pinecone. You can select `Metadata_Keys` during this process.\n",
    "\n",
    "You can additionally tag metadata and, if desired, add and process metadata ahead of time in a preprocessing task.\n",
    "\n",
    "- `split_docs` : List[Document] containing the results of document splitting.\n",
    "- `metadata_keys` : List containing metadata keys to be added to the document.\n",
    "- `min_length` : Specifies the minimum length of the document. Documents shorter than this length are excluded.\n",
    "- `use_basename` : Specifies whether to use the file name based on the source path. The default is `False` ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing of documents**\n",
    "\n",
    "- Extract the required `metadata` information.\n",
    "- Filters only data longer than the minimum length.\n",
    "- Specifies whether to use the document's `basename` . The default is `False` .\n",
    "- Here, `basename` refers to the very last part of the file.\n",
    "- For example, `/data/final-Research-Paper-5.pdf` becomes `final-Research-Paper-5.pdf`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'data\\\\TheLittlePrince.pdf',\n",
       " 'file_path': 'data\\\\TheLittlePrince.pdf',\n",
       " 'page': 3,\n",
       " 'total_pages': 64,\n",
       " 'format': 'PDF 1.3',\n",
       " 'title': '',\n",
       " 'author': 'Paula MacDowell',\n",
       " 'subject': '',\n",
       " 'keywords': '',\n",
       " 'creator': 'Safari',\n",
       " 'producer': 'Mac OS X 10.10.5 Quartz PDFContext',\n",
       " 'creationDate': \"D:20160209011144Z00'00'\",\n",
       " 'modDate': \"D:20160209011144Z00'00'\",\n",
       " 'trapped': ''}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_docs[16].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 414/414 [00:00<00:00, 74337.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed contents: ['copy of the drawing. In the book it said: \"Boa constrictors swallow their prey whole, without chewing it. After that they are not able to move, and they sleep through the six months that they need for digestion.\"', 'I pondered deeply, then, over the adventures of the jungle. And after some work with a colored pencil I succeeded in making my first drawing. My Drawing Number One. It looked something like this: I showed my masterpiece to the grown-ups, and asked them whether the drawing frightened them.', 'But they answered: \"Frighten? Why should any one be frightened by a hat?\" My drawing was not a picture of a hat. It was a picture of a boa constrictor digesting an elephant. But since the grown-ups were not able to understand it, I made another drawing: I drew the inside of a boa', \"constrictor, so that the grown-ups could see it clearly. They always need to have things explained. My Drawing Number Two looked like this: The grown-ups' response, this time, was to advise me to lay aside my drawings of boa constrictors, whether\", 'from the inside or the outside, and devote myself instead to geography, history, arithmetic, and grammar. That is why, at the age of six, I gave up what might have been a magnificent career as a painter. I had been']\n",
      "\n",
      "Processed metadatas keys: dict_keys(['source', 'page', 'author'])\n",
      "\n",
      "Source metadata examples: ['TheLittlePrince.pdf', 'TheLittlePrince.pdf', 'TheLittlePrince.pdf', 'TheLittlePrince.pdf', 'TheLittlePrince.pdf']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Add the metadata key you want to add from document metadata to the vector database.\n",
    "metadata_keys = [\n",
    "    \"source\",\n",
    "    \"page\",\n",
    "    \"author\",\n",
    "]\n",
    "min_length = 5  # Set minimum length to enter vector storage\n",
    "use_basename = True  # If True, extract only the file name (not the full path) for the \"source\" metadata key.\n",
    "\n",
    "# Initialize variables to store results\n",
    "contents = []\n",
    "metadatas = {key: [] for key in metadata_keys}\n",
    "\n",
    "# Document preprocessing tasks\n",
    "for doc in tqdm(split_docs):\n",
    "    content = doc.page_content.strip()\n",
    "    if (\n",
    "        content and len(content) >= min_length\n",
    "    ):  # Condition: Not empty and at least minimum length\n",
    "        contents.append(content)\n",
    "        for k in metadata_keys:\n",
    "            value = doc.metadata.get(k)  # Get metadata key\n",
    "            if k == \"source\" and use_basename:  # use_basename processing\n",
    "                value = os.path.basename(value)\n",
    "            try:\n",
    "                metadatas[k].append(int(value))\n",
    "            except (ValueError, TypeError):\n",
    "                metadatas[k].append(value)\n",
    "\n",
    "# Check documents, metadata to be saved in VectorStore\n",
    "print(\"Processed contents:\", contents[15:20])\n",
    "print()\n",
    "print(\"Processed metadatas keys:\", metadatas.keys())\n",
    "print()\n",
    "print(\"Source metadata examples:\", metadatas[\"source\"][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(414, 414, 414, 414)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check number of documents, check number of sources, check number of pages\n",
    "len(contents), len(metadatas[\"source\"]), len(metadatas[\"page\"]), len(\n",
    "    metadatas[\"author\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pinecone and LangChain Integration Guide: Step by Step\n",
    "\n",
    "This guide outlines the integration of Pinecone and LangChain to set up and utilize a vector database. \n",
    "\n",
    "Below are the key steps to complete the integration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pinecone client initialization and vector database setup\n",
    "\n",
    "The provided code performs the initialization of a Pinecone client, sets up an index in Pinecone, and defines a vector database to store embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[caution]**    \n",
    "\n",
    "If you are considering HybridSearch, specify the metric as dotproduct.  \n",
    "Basic users cannot use PodSpec.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pinecone index settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This explains how to create and check indexes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Index Data: {'indexes': [{'deletion_protection': 'disabled',\n",
      "              'dimension': 3072,\n",
      "              'host': 'langchain-opentutorial-index-9v46jum.svc.aped-4627-b74a.pinecone.io',\n",
      "              'metric': 'dotproduct',\n",
      "              'name': 'langchain-opentutorial-index',\n",
      "              'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
      "              'status': {'ready': True, 'state': 'Ready'}}]}\n",
      "Extracted Index Names: ['langchain-opentutorial-index']\n",
      "Using existing index: langchain-opentutorial-index\n",
      "Index 'langchain-opentutorial-index' is ready.\n"
     ]
    }
   ],
   "source": [
    "import os, time\n",
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec, PodSpec\n",
    "\n",
    "# Initialize Pinecone client with API key from environment variables\n",
    "pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))\n",
    "\n",
    "# Set to True when using the serverless method, and False when using the PodSpec method.\n",
    "use_serverless = True\n",
    "\n",
    "if use_serverless:\n",
    "    spec = ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "else:\n",
    "    spec = PodSpec(environment=\"us-west1-gcp\", pod_type=\"p1.x1\", pods=1)\n",
    "\n",
    "index_name = \"langchain-opentutorial-index\"\n",
    "\n",
    "# Check existing index name\n",
    "all_indexes = pc.list_indexes()\n",
    "print(f\"Full Index Data: {all_indexes}\")\n",
    "existing_indexes = [index.name for index in all_indexes]\n",
    "print(f\"Extracted Index Names: {existing_indexes}\")\n",
    "\n",
    "# Check existing index and handle deletion/creation\n",
    "if index_name in existing_indexes:\n",
    "    print(f\"Using existing index: {index_name}\")\n",
    "    index = pc.Index(index_name)\n",
    "else:\n",
    "    print(f\"Creating new index: {index_name}\")\n",
    "    pc.create_index(\n",
    "        index_name,\n",
    "        dimension=3072,\n",
    "        metric=\"dotproduct\",\n",
    "        spec=spec,\n",
    "    )\n",
    "    index = pc.Index(index_name)\n",
    "\n",
    "# Check index readiness\n",
    "while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "    time.sleep(1)\n",
    "print(f\"Index '{index_name}' is ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is how to check the inside of an index.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension': 3072,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'': {'vector_count': 0}},\n",
      " 'total_vector_count': 0}\n"
     ]
    }
   ],
   "source": [
    "index = pc.Index(index_name)\n",
    "print(index.describe_index_stats())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![04-pinecone-index.png](./assets/04-pinecone-index.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is how to clear an index.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'indexes': []}\n"
     ]
    }
   ],
   "source": [
    "index_name = \"langchain-opentutorial-index\"\n",
    "\n",
    "pc.delete_index(index_name)\n",
    "print(pc.list_indexes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sparse Encoder\n",
    "\n",
    "- Create a sparse encoder.\n",
    "\n",
    "- Perform stopword processing.\n",
    "\n",
    "- Learn contents using Sparse Encoder. The encode learned here is used to create a Sparse Vector when storing documents in VectorStore.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simplified NLTK-based BM25 tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from typing import List, Optional\n",
    "import nltk\n",
    "\n",
    "\n",
    "class NLTKBM25Tokenizer:\n",
    "    def __init__(self, stop_words: Optional[List[str]] = None):\n",
    "        # Set stop words and punctuation\n",
    "        self._stop_words = set(stop_words) if stop_words else set()\n",
    "        self._punctuation = set(string.punctuation)\n",
    "\n",
    "    def __call__(self, text: str) -> List[str]:\n",
    "        # Tokenization using NLTK\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        # Remove stop words and punctuation\n",
    "        return [\n",
    "            word.lower()\n",
    "            for word in tokens\n",
    "            if word not in self._punctuation and word.lower() not in self._stop_words\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25Encoder with NLTK tokenizer applied successfully!\n"
     ]
    }
   ],
   "source": [
    "from pinecone_text.sparse import BM25Encoder\n",
    "\n",
    "# BM25Encoder initialization\n",
    "sparse_encoder = BM25Encoder(language=\"english\")\n",
    "\n",
    "# Setting up a custom tokenizer on BM25Encoder\n",
    "sparse_encoder._tokenizer = NLTKBM25Tokenizer(stop_words=default_stop_words)\n",
    "\n",
    "print(\"BM25Encoder with NLTK tokenizer applied successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the corpus on Sparse Encoder.\n",
    "\n",
    "- `save_path` : Path to save Sparse Encoder. Later, the Sparse Encoder saved in pickle format will be loaded and used for query embedding. Therefore, specify the path to save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4620eb9ac4e4ee595de6a65766dd1b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/414 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fit_sparse_encoder]\n",
      "Saved Sparse Encoder to: ./sparse_encoder.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "save_path = \"./sparse_encoder.pkl\"\n",
    "\n",
    "# Learn and save Sparse Encoder.\n",
    "sparse_encoder.fit(contents)\n",
    "with open(save_path, \"wb\") as f:\n",
    "    pickle.dump(sparse_encoder, f)\n",
    "print(f\"[fit_sparse_encoder]\\nSaved Sparse Encoder to: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Optional]  \n",
    "Below is the code to use when you need to reload the learned and saved Sparse Encoder later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[load_sparse_encoder]\n",
      "Loaded Sparse Encoder from: ./sparse_encoder.pkl\n"
     ]
    }
   ],
   "source": [
    "file_path = \"./sparse_encoder.pkl\"\n",
    "\n",
    "# It is used later to load the learned sparse encoder.\n",
    "try:\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        loaded_file = pickle.load(f)\n",
    "    print(f\"[load_sparse_encoder]\\nLoaded Sparse Encoder from: {file_path}\")\n",
    "    sparse_encoder = loaded_file\n",
    "except Exception as e:\n",
    "    print(f\"[load_sparse_encoder]\\n{e}\")\n",
    "    sparse_encoder = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pinecone: Add to DB Index (Upsert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![04-pinecone-upsert-data](./assets/04-pinecone-upsert-data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `context`: This is the content of the document.\n",
    "- `page` : The page number of the document.\n",
    "- `source` : This is the source of the document.\n",
    "- `values` : This is an embedding of a document obtained through Embedder.\n",
    "- `sparse values` : This is an embedding of a document obtained through Sparse Encoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upsert documents in batches without distributed processing.\n",
    "If the amount of documents is not large, use the method below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Function to handle vector creation and Pinecone upsert simultaneously\n",
    "def upsert_documents(\n",
    "    index, contents, metadatas, embedder, sparse_encoder, namespace, batch_size=32\n",
    "):\n",
    "    total_batches = (len(contents) + batch_size - 1) // batch_size\n",
    "\n",
    "    for batch_start in tqdm(\n",
    "        range(0, len(contents), batch_size),\n",
    "        desc=\"Processing Batches\",\n",
    "        total=total_batches,\n",
    "    ):\n",
    "        batch_end = min(batch_start + batch_size, len(contents))\n",
    "\n",
    "        # Extract current batch data\n",
    "        context_batch = contents[batch_start:batch_end]\n",
    "        metadata_batch = {\n",
    "            key: metadatas[key][batch_start:batch_end] for key in metadatas\n",
    "        }\n",
    "\n",
    "        # Dense vector creation (batch)\n",
    "        dense_vectors = embedder.embed_documents(context_batch)\n",
    "\n",
    "        # Sparse vector creation (batch)\n",
    "        sparse_vectors = sparse_encoder.encode_documents(context_batch)\n",
    "\n",
    "        # Configuring data to upsert into Pinecone\n",
    "        vectors = [\n",
    "            {\n",
    "                \"id\": f\"doc-{batch_start + i}\",\n",
    "                \"values\": dense_vectors[i],\n",
    "                \"sparse_values\": {\n",
    "                    \"indices\": sparse_vectors[i][\"indices\"],\n",
    "                    \"values\": sparse_vectors[i][\"values\"],\n",
    "                },\n",
    "                \"metadata\": {\n",
    "                    **{\n",
    "                        key: metadata_batch[key][i] for key in metadata_batch\n",
    "                    },\n",
    "                    \"context\": content,  # add content\n",
    "                },\n",
    "            }\n",
    "            for i, content in enumerate(context_batch)\n",
    "        ]\n",
    "\n",
    "        # Upsert to Pinecone\n",
    "        index.upsert(vectors=vectors, namespace=namespace)\n",
    "\n",
    "    print(index.describe_index_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 13/13 [00:33<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension': 3072,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'langchain-opentutorial-01': {'vector_count': 414}},\n",
      " 'total_vector_count': 414}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "openai_embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "# Please set\n",
    "embedder = openai_embeddings\n",
    "batch_size = 32\n",
    "namespace = \"langchain-opentutorial-01\"\n",
    "\n",
    "# Running upsert on Pinecone\n",
    "upsert_documents(\n",
    "    index=index,\n",
    "    contents=contents,\n",
    "    metadatas=metadatas,\n",
    "    embedder=openai_embeddings,\n",
    "    sparse_encoder=sparse_encoder,\n",
    "    namespace=namespace,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, distributed processing is performed to quickly upsert large documents. Use this for large uploads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Functions to process individual batches\n",
    "def process_batch(\n",
    "    index,\n",
    "    context_batch,\n",
    "    metadata_batch,\n",
    "    embedder,\n",
    "    sparse_encoder,\n",
    "    namespace,\n",
    "    batch_start,\n",
    "):\n",
    "    # Dense vectors creation\n",
    "    dense_vectors = embedder.embed_documents(context_batch)\n",
    "\n",
    "    # Sparse vector creation\n",
    "    sparse_vectors = sparse_encoder.encode_documents(context_batch)\n",
    "\n",
    "    # Configuring data to upsert into Pinecone\n",
    "    vectors = [\n",
    "        {\n",
    "            \"id\": f\"doc-{batch_start + i}\",\n",
    "            \"values\": dense_vectors[i],\n",
    "            \"sparse_values\": {\n",
    "                \"indices\": sparse_vectors[i][\"indices\"],\n",
    "                \"values\": sparse_vectors[i][\"values\"],\n",
    "            },\n",
    "            \"metadata\": {\n",
    "                **{\n",
    "                    key: metadata_batch[key][i] for key in metadata_batch\n",
    "                },\n",
    "                \"context\": content,  # add content\n",
    "            },\n",
    "        }\n",
    "        for i, content in enumerate(context_batch)\n",
    "    ]\n",
    "\n",
    "    index.upsert(vectors=vectors, namespace=namespace)\n",
    "\n",
    "# Distributed processing upsert function\n",
    "def upsert_documents_parallel(\n",
    "    index,\n",
    "    contents,\n",
    "    metadatas,\n",
    "    embedder,\n",
    "    sparse_encoder,\n",
    "    namespace,\n",
    "    batch_size=32,\n",
    "    max_workers=8,\n",
    "):\n",
    "    # total_batches = (len(contents) + batch_size - 1) // batch_size  # Batch Count\n",
    "    batches = [\n",
    "        (\n",
    "            contents[batch_start : batch_start + batch_size],\n",
    "            {\n",
    "                key: metadatas[key][batch_start : batch_start + batch_size]\n",
    "                for key in metadatas\n",
    "            },\n",
    "            batch_start,\n",
    "        )\n",
    "        for batch_start in range(0, len(contents), batch_size)\n",
    "    ]\n",
    "\n",
    "    # Parallel processing using ThreadPoolExecutor\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [\n",
    "            executor.submit(\n",
    "                process_batch,\n",
    "                index,\n",
    "                batch[0],\n",
    "                batch[1],\n",
    "                embedder,\n",
    "                sparse_encoder,\n",
    "                namespace,\n",
    "                batch[2],\n",
    "            )\n",
    "            for batch in batches\n",
    "        ]\n",
    "\n",
    "        # Display parallel job status with tqdm\n",
    "        for future in tqdm(\n",
    "            as_completed(futures),\n",
    "            total=len(futures),\n",
    "            desc=\"Processing Batches in Parallel\",\n",
    "        ):\n",
    "            future.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches in Parallel: 100%|██████████| 13/13 [00:06<00:00,  2.14it/s]\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "openai_embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "embedder = openai_embeddings\n",
    "# Set batch size and number of workers\n",
    "batch_size = 32\n",
    "max_workers = 8\n",
    "namespace = \"langchain-opentutorial-02\"\n",
    "\n",
    "# Running Upsert in Parallel on Pinecone\n",
    "upsert_documents_parallel(\n",
    "    index=index,\n",
    "    contents=contents,\n",
    "    metadatas=metadatas,\n",
    "    embedder=openai_embeddings,\n",
    "    sparse_encoder=sparse_encoder,\n",
    "    namespace=namespace,\n",
    "    batch_size=batch_size,\n",
    "    max_workers=max_workers,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension': 3072,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'langchain-opentutorial-01': {'vector_count': 414},\n",
      "                'langchain-opentutorial-02': {'vector_count': 414}},\n",
      " 'total_vector_count': 828}\n"
     ]
    }
   ],
   "source": [
    "print(index.describe_index_stats())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![04-pinecone-namespaces.png](./assets/04-pinecone-namespaces.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index inquiry/delete\n",
    "\n",
    "The `describe_index_stats` method provides statistical information about the contents of an index. This method allows you to obtain information such as the number of vectors and dimensions per namespace.\n",
    "\n",
    "**Parameter** * `filter` (Optional[Dict[str, Union[str, float, int, bool, List, dict]]]): A filter that returns statistics only for vectors that meet certain conditions. Default is None * `**kwargs`: Additional keyword arguments\n",
    "\n",
    "**Return value** * `DescribeIndexStatsResponse`: Object containing statistical information about the index\n",
    "\n",
    "**Usage example** * Default usage: `index.describe_index_stats()` * Apply filter: `index.describe_index_stats(filter={'key': 'value'})`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 3072,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'langchain-opentutorial-01': {'vector_count': 414},\n",
       "                'langchain-opentutorial-02': {'vector_count': 414}},\n",
       " 'total_vector_count': 828}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index lookup\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Search for documents in the index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'matches': [{'id': 'doc-303',\n",
      "              'metadata': {'author': 'Paula MacDowell',\n",
      "                           'content': \"o'clock in the afternoon, then at three \"\n",
      "                                      \"o'clock I shall begin to be happy. I \"\n",
      "                                      'shall feel happier and happier as the '\n",
      "                                      \"hour advances. At four o'clock, I shall \"\n",
      "                                      'already be worrying and jumping about. '\n",
      "                                      'I shall show you how',\n",
      "                           'page': 46.0,\n",
      "                           'source': 'TheLittlePrince.pdf'},\n",
      "              'score': 0.6972045,\n",
      "              'sparse_values': {'indices': [], 'values': []},\n",
      "              'values': []},\n",
      "             {'id': 'doc-302',\n",
      "              'metadata': {'author': 'Paula MacDowell',\n",
      "                           'content': 'of misunderstandings. But you will sit '\n",
      "                                      'a little closer to me, every day . . .\" '\n",
      "                                      'The next day the little prince came '\n",
      "                                      'back. \"It would have been better to '\n",
      "                                      'come back at the same hour,\" said the '\n",
      "                                      'fox. \"If, for example, you come at four',\n",
      "                           'page': 46.0,\n",
      "                           'source': 'TheLittlePrince.pdf'},\n",
      "              'score': 0.39097124,\n",
      "              'sparse_values': {'indices': [], 'values': []},\n",
      "              'values': []},\n",
      "             {'id': 'doc-304',\n",
      "              'metadata': {'author': 'Paula MacDowell',\n",
      "                           'content': 'happy I am! But if you come at just any '\n",
      "                                      'time, I shall never know at what hour '\n",
      "                                      'my heart is to be ready to greet you . '\n",
      "                                      '. . One must observe the proper rites . '\n",
      "                                      '. .\" \"What is a rite?\" asked the little '\n",
      "                                      'prince.',\n",
      "                           'page': 46.0,\n",
      "                           'source': 'TheLittlePrince.pdf'},\n",
      "              'score': 0.37224084,\n",
      "              'sparse_values': {'indices': [], 'values': []},\n",
      "              'values': []}],\n",
      " 'namespace': 'langchain-opentutorial-01',\n",
      " 'usage': {'read_units': 6}}\n"
     ]
    }
   ],
   "source": [
    "# Define your query\n",
    "query = \"If you come at 4 PM, I will be happy from 3 PM. As time goes by, I will become happier.\"\n",
    "\n",
    "# Convert the query into dense and sparse vectors\n",
    "dense_vector = embedder.embed_query(query)\n",
    "sparse_vector = sparse_encoder.encode_documents(query)\n",
    "\n",
    "# Perform hybrid search using both dense and sparse vectors\n",
    "results = index.query(\n",
    "    namespace=\"langchain-opentutorial-01\",\n",
    "    vector=dense_vector,\n",
    "    top_k=3,\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Delete namespace**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.delete(delete_all=True, namespace=\"langchain-opentutorial-02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![04-pinecone-namespaces2.png](./assets/04-pinecone-namespaces2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 3072,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'langchain-opentutorial-01': {'vector_count': 414}},\n",
       " 'total_vector_count': 414}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are features exclusive to paid users. Metadata filtering is available to paid users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while deleting using filter:\n",
      "UNKNOWN:Error received from peer  {created_time:\"2025-01-12T09:54:47.7906081+00:00\", grpc_status:3, grpc_message:\"Invalid request.\"}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dimension': 3072,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'langchain-opentutorial-01': {'vector_count': 414}},\n",
       " 'total_vector_count': 414}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinecone.exceptions import PineconeException\n",
    "\n",
    "try:\n",
    "    index.delete(filter={\"source\": {\"$eq\": \"TheLittlePrince.pdf\"}}, namespace=\"langchain-opentutorial-01\")\n",
    "except PineconeException as e:\n",
    "    print(f\"Error while deleting using filter:\\n{e}\")\n",
    "\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create HybridRetrieve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PineconeHybridRetriever initialization parameter settings**\n",
    "\n",
    "The `init_pinecone_index` function and the `PineconeHybridRetriever` class implement a hybrid search system using Pinecone. This system combines dense and sparse vectors to perform effective document retrieval.\n",
    "\n",
    "Pinecone index initialization\n",
    "\n",
    "The `init_pinecone_index` function initializes the Pinecone index and sets up the necessary components.\n",
    "\n",
    "Parameters \n",
    "* `index_name` (str): Pinecone index name \n",
    "* `namespace` (str): Namespace to use \n",
    "* `api_key` (str): Pinecone API key \n",
    "* `sparse_encoder_pkl_path` (str): Sparse encoder pickle file path \n",
    "* `stopwords` (List[str]): List of stop words \n",
    "* `tokenizer` (str): Tokenizer to use (default: \"nltk\") \n",
    "* `embeddings` (Embeddings): Embedding model \n",
    "* `top_k` (int): Maximum number of documents to return (default: 10) \n",
    "* `alpha` (float): Weight of dense and sparse vectors Adjustment parameter (default: 0.5)\n",
    "\n",
    "**Main features** \n",
    "1. Pinecone index initialization and statistical information output\n",
    "2. Sparse encoder (BM25) loading and tokenizer settings\n",
    "3. Specify namespace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import PineconeHybridSearchRetriever\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "import os\n",
    "\n",
    "# Step 1: Initialize Pinecone\n",
    "pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))\n",
    "index_name = \"langchain-opentutorial-index\"\n",
    "namespace = \"langchain-opentutorial-01\"\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# Step 2: Configure Dense and Sparse Components\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "sparse_encoder = sparse_encoder  # Pre-initialized BM25Encoder\n",
    "\n",
    "# Step 3: Define the Retriever\n",
    "class CustomPineconeHybridSearchRetriever(PineconeHybridSearchRetriever):\n",
    "    def invoke(self, query, **search_kwargs):\n",
    "        # Update settings dynamically\n",
    "        if \"top_k\" in search_kwargs:\n",
    "            self.top_k = search_kwargs[\"top_k\"]\n",
    "        if \"alpha\" in search_kwargs:\n",
    "            self.alpha = search_kwargs[\"alpha\"]\n",
    "        # Apply metadata filtering if provided\n",
    "        if \"filter\" in search_kwargs:\n",
    "            kwargs = {\"filter\": search_kwargs[\"filter\"]}\n",
    "        else:\n",
    "            kwargs = {}\n",
    "\n",
    "        # Call the parent class method with additional kwargs\n",
    "        return super().invoke(query, **kwargs)\n",
    "    \n",
    "# Step 4: Define the Retriever\n",
    "retriever = CustomPineconeHybridSearchRetriever(\n",
    "    embeddings=embeddings,\n",
    "    sparse_encoder=sparse_encoder,\n",
    "    index=index,\n",
    "    namespace=namespace,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main properties** \n",
    "* `embeddings` : Embedding model for dense vector transformations \n",
    "* `sparse_encoder:` Encoder for sparse vector transformations \n",
    "* `index` : Pinecone index object \n",
    "* `top_k` : Maximum number of documents to return \n",
    "* `alpha` : Weight adjustment parameters for dense and sparse vectors \n",
    "* `namespace` : Namespace within the Pinecone index.\n",
    "\n",
    "**Features** \n",
    "* HybridSearch Retriever combining dense and sparse vectors \n",
    "* Search strategy can be optimized through weight adjustment \n",
    "* Various dynamic metadata filtering can be applied (using `search_kwargs` : `filter` , `top_k` , etc.)\n",
    "\n",
    "**Use example** \n",
    "1. Initialize required components with the `init_pinecone_index` function   \n",
    "2. Create a `PineconeHybridRetriever` instance with initialized components.  \n",
    "3. Perform a hybrid search using the generated retriever to create a `PineconeHybridRetriever`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**general search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o'clock in the afternoon, then at three o'clock I shall begin to be happy. I shall feel happier and happier as the hour advances. At four o'clock, I shall already be worrying and jumping about. I shall show you how\n",
      "{'page': 46.0, 'author': 'Paula MacDowell', 'source': 'TheLittlePrince.pdf', 'score': 0.69743073}\n",
      "\n",
      "====================\n",
      "\n",
      "of misunderstandings. But you will sit a little closer to me, every day . . .\" The next day the little prince came back. \"It would have been better to come back at the same hour,\" said the fox. \"If, for example, you come at four\n",
      "{'page': 46.0, 'author': 'Paula MacDowell', 'source': 'TheLittlePrince.pdf', 'score': 0.39021924}\n",
      "\n",
      "====================\n",
      "\n",
      "happy I am! But if you come at just any time, I shall never know at what hour my heart is to be ready to greet you . . . One must observe the proper rites . . .\" \"What is a rite?\" asked the little prince.\n",
      "{'page': 46.0, 'author': 'Paula MacDowell', 'source': 'TheLittlePrince.pdf', 'score': 0.37222207}\n",
      "\n",
      "====================\n",
      "\n",
      "\"I am very fond of sunsets. Come, let us go look at a sunset now.\" \"But we must wait,\" I said. \"Wait? For what?\" \"For the sunset. We must wait until it is time.\" At first you seemed to be very much surprised. And then you laughed to yourself. You said to me:\n",
      "{'page': 15.0, 'author': 'Paula MacDowell', 'source': 'TheLittlePrince.pdf', 'score': 0.37146252}\n",
      "\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"If you come at 4 PM, I will be happy from 3 PM. As time goes by, I will become happier.\"\n",
    "search_results = retriever.invoke(query)\n",
    "for result in search_results:\n",
    "    print(result.page_content)\n",
    "    print(result.metadata)\n",
    "    print(\"\\n====================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using dynamic search_kwargs - k: specify maximum number of documents to return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o'clock in the afternoon, then at three o'clock I shall begin to be happy. I shall feel happier and happier as the hour advances. At four o'clock, I shall already be worrying and jumping about. I shall show you how\n",
      "{'page': 46.0, 'author': 'Paula MacDowell', 'source': 'TheLittlePrince.pdf', 'score': 0.41688234}\n",
      "\n",
      "====================\n",
      "\n",
      "happy I am! But if you come at just any time, I shall never know at what hour my heart is to be ready to greet you . . . One must observe the proper rites . . .\" \"What is a rite?\" asked the little prince.\n",
      "{'page': 46.0, 'author': 'Paula MacDowell', 'source': 'TheLittlePrince.pdf', 'score': 0.23662259}\n",
      "\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"If you come at 4 PM, I will be happy from 3 PM. As time goes by, I will become happier.\"\n",
    "\n",
    "search_kwargs = {\"top_k\": 2}\n",
    "search_results = retriever.invoke(query, **search_kwargs)\n",
    "\n",
    "for result in search_results:\n",
    "    print(result.page_content)\n",
    "    print(result.metadata)\n",
    "    print(\"\\n====================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Use dynamic `search_kwargs` - `alpha` : Weight adjustment parameters for dense and sparse vectors. Specify a value between 0 and 1. `0.5` is the default, the closer it is to 1, the higher the weight of the dense vector is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o'clock in the afternoon, then at three o'clock I shall begin to be happy. I shall feel happier and happier as the hour advances. At four o'clock, I shall already be worrying and jumping about. I shall show you how\n",
      "{'page': 46.0, 'author': 'Paula MacDowell', 'source': 'TheLittlePrince.pdf', 'score': 0.6966725}\n",
      "\n",
      "====================\n",
      "\n",
      "of misunderstandings. But you will sit a little closer to me, every day . . .\" The next day the little prince came back. \"It would have been better to come back at the same hour,\" said the fox. \"If, for example, you come at four\n",
      "{'page': 46.0, 'author': 'Paula MacDowell', 'source': 'TheLittlePrince.pdf', 'score': 0.39095855}\n",
      "\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"If you come at 4 PM, I will be happy from 3 PM. As time goes by, I will become happier.\"\n",
    "\n",
    "search_kwargs = {\"alpha\": 1, \"top_k\": 2}\n",
    "search_results = retriever.invoke(query, **search_kwargs)\n",
    "\n",
    "for result in search_results:\n",
    "    print(result.page_content)\n",
    "    print(result.metadata)\n",
    "    print(\"\\n====================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o'clock in the afternoon, then at three o'clock I shall begin to be happy. I shall feel happier and happier as the hour advances. At four o'clock, I shall already be worrying and jumping about. I shall show you how\n",
      "{'page': 46.0, 'author': 'Paula MacDowell', 'source': 'TheLittlePrince.pdf', 'score': 0.13690874}\n",
      "\n",
      "====================\n",
      "\n",
      "happy I am! But if you come at just any time, I shall never know at what hour my heart is to be ready to greet you . . . One must observe the proper rites . . .\" \"What is a rite?\" asked the little prince.\n",
      "{'page': 46.0, 'author': 'Paula MacDowell', 'source': 'TheLittlePrince.pdf', 'score': 0.10070026}\n",
      "\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"If you come at 4 PM, I will be happy from 3 PM. As time goes by, I will become happier.\"\n",
    "\n",
    "search_kwargs = {\"alpha\": 0, \"top_k\": 2}\n",
    "search_results = retriever.invoke(query, **search_kwargs)\n",
    "\n",
    "for result in search_results:\n",
    "    print(result.page_content)\n",
    "    print(result.metadata)\n",
    "    print(\"\\n====================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metadata filtering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![example](./assets/04-pinecone-metadata.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using dynamic search_kwargs - filter: Apply metadata filtering\n",
    "\n",
    "(Example) Only documents with page less than 5 are searched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"I am very fond of sunsets. Come, let us go look at a sunset now.\" \"But we must wait,\" I said. \"Wait? For what?\" \"For the sunset. We must wait until it is time.\" At first you seemed to be very much surprised. And then you laughed to yourself. You said to me:\n",
      "{'page': 15.0, 'author': 'Paula MacDowell', 'source': 'TheLittlePrince.pdf', 'score': 0.37146252}\n",
      "\n",
      "====================\n",
      "\n",
      "Hum! That will be about--about--that will be this evening about twenty minutes to eight. And you will see how well I am obeyed!\" The little prince yawned. He was regretting his lost sunset. And then, too, he was already beginning to be a little bored.\n",
      "{'page': 24.0, 'author': 'Paula MacDowell', 'source': 'TheLittlePrince.pdf', 'score': 0.3529621}\n",
      "\n",
      "====================\n",
      "\n",
      "\"I am always thinking that I am at home!\" Just so. Everybody knows that when it is noon in the United States the sun is setting over France. If you could fly to France in one minute, you could go straight into the sunset, right from noon.\n",
      "{'page': 15.0, 'author': 'Paula MacDowell', 'source': 'TheLittlePrince.pdf', 'score': 0.2984888}\n",
      "\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"If you come at 4 PM, I will be happy from 3 PM. As time goes by, I will become happier.\"\n",
    "\n",
    "search_kwargs = {\"alpha\": 1, \"top_k\": 3, \"filter\": {\"page\": {\"$lt\": 25}}}\n",
    "search_results = retriever.invoke(query, **search_kwargs)\n",
    "for result in search_results:\n",
    "    print(result.page_content)\n",
    "    print(result.metadata)\n",
    "    print(\"\\n====================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He should be able, for example, to order me to be gone by the end of one minute. It seems to me that conditions are favorable . . .\" As the king made no answer, the little prince hesitated a moment. Then, with a sigh, he took his leave.\n",
      "{'page': 25.0, 'author': 'Paula MacDowell', 'source': 'TheLittlePrince.pdf', 'score': 0.21899617}\n",
      "\n",
      "====================\n",
      "\n",
      "way.\" \"No,\" said the king. But the little prince, having now completed his preparations for departure, had no wish to grieve the old monarch. \"If Your Majesty wishes to be promptly obeyed,\" he said, \"he should be able to give me a reasonable order.\n",
      "{'page': 25.0, 'author': 'Paula MacDowell', 'source': 'TheLittlePrince.pdf', 'score': 0.18327388}\n",
      "\n",
      "====================\n",
      "\n",
      "\"And you actually believe that the flowers--\" \"Oh, no!\" I cried. \"No, no, no! I don't believe anything. I answered you with the first thing that came into my head. Don't you see--I am very busy with matters of consequence!\" He stared at me, thunderstruck. \"Matters of consequence!\"\n",
      "{'page': 16.0, 'author': 'Paula MacDowell', 'source': 'TheLittlePrince.pdf', 'score': 0.13634408}\n",
      "\n",
      "====================\n",
      "\n",
      "I did not answer. At that instant I was saying to myself: \"If this bolt still won't turn, I am going to knock it out with the hammer.\" Again the little prince disturbed my thoughts: \"And you actually believe that the flowers--\"\n",
      "{'page': 16.0, 'author': 'Paula MacDowell', 'source': 'TheLittlePrince.pdf', 'score': 0.12568295}\n",
      "\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"If you come at 4 PM, I will be happy from 3 PM. As time goes by, I will become happier.\"\n",
    "\n",
    "search_kwargs = {\"alpha\": 1, \"top_k\": 4, \"filter\": {\"page\": {\"$in\": [25, 16]}}}\n",
    "search_results = retriever.invoke(query, **search_kwargs)\n",
    "for result in search_results:\n",
    "    print(result.page_content)\n",
    "    print(result.metadata)\n",
    "    print(\"\\n====================\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-opentutorial-XrZComUd-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
