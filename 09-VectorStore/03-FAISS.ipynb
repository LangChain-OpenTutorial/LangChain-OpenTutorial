{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FAISS\n",
        "\n",
        "\n",
        "- Author: [Jeongeun Lim](https://www.linkedin.com/in/jeongeun-lim-808978188/)\n",
        "- Design: []()\n",
        "- Peer Review : \n",
        "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
        "\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/03-OutputParser/08-OutputFixingParser.ipynb) [![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/03-OutputParser/08-OutputFixingParser.ipynb)\n",
        "\n",
        "\n",
        "## Overview\n",
        "\n",
        "\n",
        "`FAISS` is a library designed for the efficient similarity search and clustering of dense vectors. It provides robust algorithms for searching vector sets of any size, including those that may not fit entirely in `RAM`.\n",
        "\n",
        "\n",
        "In addition to the core search functionality, `FAISS` includes support code for evaluation and parameter tuning, making it a versatile tool for various applications in machine learning and artificial intelligence.\n",
        "\n",
        "\n",
        "----\n",
        "Key Benefits:\n",
        "\n",
        "\n",
        "- Efficient Large-Scale Search:\n",
        "`FAISS` ensures fast and accurate vector searches, even with millions of high-dimensional vectors.\n",
        "\n",
        "\n",
        "- Memory Optimization:\n",
        "Offers advanced quantization techniques to reduce memory usage without sacrificing performance.\n",
        "\n",
        "\n",
        "- Customizable Search Accuracy:\n",
        "Users can fine-tune parameters to balance between search accuracy and speed according to specific requirements.\n",
        "\n",
        "\n",
        "- Versatile Applications:\n",
        "From machine learning to AI-powered recommendation systems, Faiss supports a wide range of use cases.\n",
        "\n",
        "\n",
        "---- \n",
        "Implementation Steps:\n",
        "\n",
        "\n",
        "To effectively integrate `FAISS` into your workflow, follow these steps:\n",
        "\n",
        "\n",
        "1. Data Preparation:\n",
        "Prepare and normalize your data, ensuring vectors are in a dense representation format.\n",
        "\n",
        "\n",
        "2. Index Creation:\n",
        "Select and build a Faiss index based on your dataset size and performance requirements. Common options include IndexFlat for brute-force search or IVF for scalable inverted file-based search.\n",
        "\n",
        "\n",
        "3. Index Training (if needed):\n",
        "For certain indices, such as `IVF` or `PQ`, train the index with representative data samples to optimize performance.\n",
        "\n",
        "\n",
        "4. Search Execution:\n",
        "Use the index to search for nearest neighbors, leveraging optional GPU acceleration for faster performance.\n",
        "\n",
        "\n",
        "5. Evaluation and Tuning:\n",
        "Test and evaluate the performance of your index, adjusting parameters like quantization levels or clustering size for improved results.\n",
        "\n",
        "\n",
        "### Table of Contents\n",
        "\n",
        "\n",
        "- [Overview](#overview)\n",
        "- [Environment Setup](#environment-setup)\n",
        "- [Load a Sample Dataset](#load-a-sample-dataset)\n",
        "- [Create a VectorStore](#create-a-vectorstore)\n",
        "    - [Create a FAISS VectorStore(from_documents)](#create-a-faiss-vectorstorefrom_documents)\n",
        "    - [Create a FAISS VectorStore(from_texts)](#create-a-faiss-vectorstorefrom_texts)\n",
        "- [Similarity Search](#similarity-search)\n",
        "- [Data Addition Methods](#data-addition-methods)\n",
        "- [Delete Documents](#delete-documents)\n",
        "- [Local Persistence](#local-persistence)\n",
        "- [FAISS Object Merge (Merge From)](#faiss-object-merge-merge-from)\n",
        "- [Convert to Searcher (as_retriever)](#convert-to-searcher-as_retriever)\n",
        "\n",
        "\n",
        "### References\n",
        "\n",
        "\n",
        "- [LangChain : Faiss](https://python.langchain.com/docs/integrations/vectorstores/faiss)\n",
        "- [Faiss Docs](https://faiss.ai/)\n",
        "\n",
        "\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Environment Setup\n",
        "\n",
        "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
        "\n",
        "**[Note]**\n",
        "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
        "- You can checkout the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install langchain-opentutorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "from langchain_opentutorial import package\n",
        "\n",
        "package.install(\n",
        "    [\n",
        "        \"langsmith\",\n",
        "        \"langchain\",\n",
        "        \"langchain_openai\",\n",
        "        \"langchain_community\",\n",
        "    ],\n",
        "    verbose=False,\n",
        "    upgrade=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment variables have been set successfully.\n"
          ]
        }
      ],
      "source": [
        "# Set environment variables\n",
        "from langchain_opentutorial import set_env\n",
        "\n",
        "set_env(\n",
        "    {\n",
        "        \"OPENAI_API_KEY\": \"\",\n",
        "        \"LANGCHAIN_API_KEY\": \"\",\n",
        "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
        "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
        "        \"LANGCHAIN_PROJECT\": \"FAISS\",\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can alternatively set `OPENAI_API_KEY` in `.env` file and load it. \n",
        "\n",
        "[Note] This is not necessary if you've already set `OPENAI_API_KEY` in previous steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv(override=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load a Sample Dataset\n",
        "Demonstrates how to load text files using LangChain’s `TextLoader` and split them into smaller chunks with `RecursiveCharacterTextSplitter`. \n",
        "The resulting documents are prepared for further embedding and storage in a FAISS vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Will be reflected in a fixed sample dataset in the future\n",
        "\"\"\"\n",
        "\n",
        "# from langchain_community.document_loaders import TextLoader\n",
        "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# # 텍스트 분할\n",
        "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=600, chunk_overlap=0)\n",
        "\n",
        "# # 텍스트 파일을 load -> List[Document] 형태로 변환\n",
        "# loader1 = TextLoader(\"data/nlp-keywords.txt\")\n",
        "# loader2 = TextLoader(\"data/finance-keywords.txt\")\n",
        "\n",
        "# # 문서 분할\n",
        "# split_doc1 = loader1.load_and_split(text_splitter)\n",
        "# split_doc2 = loader2.load_and_split(text_splitter)\n",
        "\n",
        "# # 문서 개수 확인\n",
        "# len(split_doc1), len(split_doc2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of split documents: 18\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Will be reflected in a fixed sample dataset in the future\n",
        "\"\"\"\n",
        "\n",
        "from uuid import uuid4\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "# Define the dataset\n",
        "document_1 = Document(\n",
        "    page_content=\"I had chocolate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "document_2 = Document(\n",
        "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        ")\n",
        "document_3 = Document(\n",
        "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "document_4 = Document(\n",
        "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        ")\n",
        "document_5 = Document(\n",
        "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "document_6 = Document(\n",
        "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
        "    metadata={\"source\": \"website\"},\n",
        ")\n",
        "document_7 = Document(\n",
        "    page_content=\"The top 10 soccer players in the world right now.\",\n",
        "    metadata={\"source\": \"website\"},\n",
        ")\n",
        "document_8 = Document(\n",
        "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "document_9 = Document(\n",
        "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        ")\n",
        "document_10 = Document(\n",
        "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "documents = [\n",
        "    document_1,\n",
        "    document_2,\n",
        "    document_3,\n",
        "    document_4,\n",
        "    document_5,\n",
        "    document_6,\n",
        "    document_7,\n",
        "    document_8,\n",
        "    document_9,\n",
        "    document_10,\n",
        "]\n",
        "\n",
        "# Define the text splitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=50, chunk_overlap=10)\n",
        "\n",
        "# Split documents into smaller chunks and create a new list\n",
        "split_documents = []\n",
        "for doc in documents:\n",
        "    split_content = text_splitter.split_text(doc.page_content)\n",
        "    for chunk in split_content:\n",
        "        split_documents.append(Document(page_content=chunk, metadata=doc.metadata))\n",
        "\n",
        "# Generate a unique UUID for each split document\n",
        "uuids = [str(uuid4()) for _ in range(len(split_documents))]\n",
        "\n",
        "# Add the split documents to the VectorStore\n",
        "# db.add_documents(documents=split_documents, ids=uuids)\n",
        "\n",
        "# Verify the result (Print the number of split documents)\n",
        "print(f\"Number of split documents: {len(split_documents)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a VectorStore\n",
        "\n",
        "Key Initialization Parameters:\n",
        "\n",
        "- Indexing Parameters\n",
        "    - `embedding_function` (Embeddings): The embedding function to be used.\n",
        "- Client Parameters\n",
        "    - `index` (Any): The FAISS index to be used.\n",
        "    - `docstore` (Docstore): The document store to be utilized.\n",
        "    - `index_to_docstore_id` (Dict[int, str]): A mapping from the index to document store IDs.\n",
        "\n",
        "**[Note]** \n",
        "\n",
        "- `FAISS` is a high-performance library for vector search and clustering.\n",
        "- This class integrates `FAISS` with LangChain's VectorStore interface.\n",
        "- By combining the `embedding function`, `FAISS index`, and `document store`, you can build an efficient vector search system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1536\n"
          ]
        }
      ],
      "source": [
        "import faiss\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# Embedding\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "# Calculate the size of the embedding dimension\n",
        "dimension_size = len(embeddings.embed_query(\"hello world\"))\n",
        "print(dimension_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a FAISS vector store\n",
        "db = FAISS(\n",
        "    embedding_function=OpenAIEmbeddings(),\n",
        "    index=faiss.IndexFlatL2(dimension_size),\n",
        "    docstore=InMemoryDocstore(),\n",
        "    index_to_docstore_id={},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a FAISS VectorStore(from_documents)\n",
        "\n",
        "The `from_documents` class method creates a FAISS vector store using a list of documents and an embedding function.\n",
        "\n",
        "- Parameters:\n",
        "    - `documents` (List[Document]): A list of documents to be added to the vector store.\n",
        "    - `embedding` (Embeddings): The embedding function to be used.\n",
        "    - `**kwargs`: Additional keyword arguments.\n",
        "\n",
        "- How It Works:\n",
        "1. Extracts the text content (`page_content`) and metadata from the list of documents.\n",
        "2. Calls the `from_texts` method using the extracted text and metadata.\n",
        "\n",
        "- Return Value:\n",
        "    - `VectorStore`: An instance of the vector store initialized with the provided documents and embeddings.\n",
        "\n",
        "**[Note]** \n",
        "- This method internally calls the `from_texts` method to create the vector store.\n",
        "- The `page_content` of each document is used as text, while `metadata` is used as the document's metadata.\n",
        "- Additional configurations can be passed through `kwargs`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a FAISS vector store from the documents\n",
        "db = FAISS.from_documents(documents=split_documents, embedding=OpenAIEmbeddings())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'd7e03a33-c8d5-4139-a9a5-0ee287908e1a',\n",
              " 1: '9a727937-e0af-4003-a3a8-4997f8dddf00',\n",
              " 2: '9eb165f9-ab7a-4a8d-8fc2-547c575d5cf6',\n",
              " 3: 'd8e0189a-17df-4ee4-860c-2c838e404c02',\n",
              " 4: '77422209-888e-4f2e-b656-85a347ba56f7',\n",
              " 5: '557c5ff3-6303-43e3-8919-ac78081e16b8',\n",
              " 6: '43751c22-f479-4ce9-9c92-83b4a6bea494',\n",
              " 7: 'dc2f4d57-fdd9-43c4-b355-4b188a89ce5b',\n",
              " 8: 'f7a3f798-4459-45f0-9064-d91cf31bb466',\n",
              " 9: 'f8cc3819-4f71-4256-9d9a-9b6fba8712c6',\n",
              " 10: 'c5c40a21-ce67-447d-819c-d6971ffcb2d6',\n",
              " 11: 'fd6a6f48-eda2-4753-93e9-aacb991b0519',\n",
              " 12: 'ce25d341-1c44-4a7a-82b1-5d5ff139c137',\n",
              " 13: '8a089124-0f45-419b-8c96-a8a6aacd5c0f',\n",
              " 14: 'e203e4b6-4703-43b3-ac46-b46b9e825c00',\n",
              " 15: 'fa0f3f69-3754-4ccf-8d97-096553677cdc',\n",
              " 16: '02b8f2ad-2aa7-4b26-930b-762ab6b0204e',\n",
              " 17: 'c261874c-5393-4d7c-80a0-e67c5f115fda'}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check the document store IDs\n",
        "db.index_to_docstore_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'d7e03a33-c8d5-4139-a9a5-0ee287908e1a': Document(id='d7e03a33-c8d5-4139-a9a5-0ee287908e1a', metadata={'source': 'tweet'}, page_content='I had chocolate chip pancakes and scrambled eggs'),\n",
              " '9a727937-e0af-4003-a3a8-4997f8dddf00': Document(id='9a727937-e0af-4003-a3a8-4997f8dddf00', metadata={'source': 'tweet'}, page_content='eggs for breakfast this morning.'),\n",
              " '9eb165f9-ab7a-4a8d-8fc2-547c575d5cf6': Document(id='9eb165f9-ab7a-4a8d-8fc2-547c575d5cf6', metadata={'source': 'news'}, page_content='The weather forecast for tomorrow is cloudy and'),\n",
              " 'd8e0189a-17df-4ee4-860c-2c838e404c02': Document(id='d8e0189a-17df-4ee4-860c-2c838e404c02', metadata={'source': 'news'}, page_content='and overcast, with a high of 62 degrees.'),\n",
              " '77422209-888e-4f2e-b656-85a347ba56f7': Document(id='77422209-888e-4f2e-b656-85a347ba56f7', metadata={'source': 'tweet'}, page_content='Building an exciting new project with LangChain -'),\n",
              " '557c5ff3-6303-43e3-8919-ac78081e16b8': Document(id='557c5ff3-6303-43e3-8919-ac78081e16b8', metadata={'source': 'tweet'}, page_content='- come check it out!'),\n",
              " '43751c22-f479-4ce9-9c92-83b4a6bea494': Document(id='43751c22-f479-4ce9-9c92-83b4a6bea494', metadata={'source': 'news'}, page_content='Robbers broke into the city bank and stole $1'),\n",
              " 'dc2f4d57-fdd9-43c4-b355-4b188a89ce5b': Document(id='dc2f4d57-fdd9-43c4-b355-4b188a89ce5b', metadata={'source': 'news'}, page_content='stole $1 million in cash.'),\n",
              " 'f7a3f798-4459-45f0-9064-d91cf31bb466': Document(id='f7a3f798-4459-45f0-9064-d91cf31bb466', metadata={'source': 'tweet'}, page_content=\"Wow! That was an amazing movie. I can't wait to\"),\n",
              " 'f8cc3819-4f71-4256-9d9a-9b6fba8712c6': Document(id='f8cc3819-4f71-4256-9d9a-9b6fba8712c6', metadata={'source': 'tweet'}, page_content='wait to see it again.'),\n",
              " 'c5c40a21-ce67-447d-819c-d6971ffcb2d6': Document(id='c5c40a21-ce67-447d-819c-d6971ffcb2d6', metadata={'source': 'website'}, page_content='Is the new iPhone worth the price? Read this'),\n",
              " 'fd6a6f48-eda2-4753-93e9-aacb991b0519': Document(id='fd6a6f48-eda2-4753-93e9-aacb991b0519', metadata={'source': 'website'}, page_content='Read this review to find out.'),\n",
              " 'ce25d341-1c44-4a7a-82b1-5d5ff139c137': Document(id='ce25d341-1c44-4a7a-82b1-5d5ff139c137', metadata={'source': 'website'}, page_content='The top 10 soccer players in the world right now.'),\n",
              " '8a089124-0f45-419b-8c96-a8a6aacd5c0f': Document(id='8a089124-0f45-419b-8c96-a8a6aacd5c0f', metadata={'source': 'tweet'}, page_content='LangGraph is the best framework for building'),\n",
              " 'e203e4b6-4703-43b3-ac46-b46b9e825c00': Document(id='e203e4b6-4703-43b3-ac46-b46b9e825c00', metadata={'source': 'tweet'}, page_content='building stateful, agentic applications!'),\n",
              " 'fa0f3f69-3754-4ccf-8d97-096553677cdc': Document(id='fa0f3f69-3754-4ccf-8d97-096553677cdc', metadata={'source': 'news'}, page_content='The stock market is down 500 points today due to'),\n",
              " '02b8f2ad-2aa7-4b26-930b-762ab6b0204e': Document(id='02b8f2ad-2aa7-4b26-930b-762ab6b0204e', metadata={'source': 'news'}, page_content='due to fears of a recession.'),\n",
              " 'c261874c-5393-4d7c-80a0-e67c5f115fda': Document(id='c261874c-5393-4d7c-80a0-e67c5f115fda', metadata={'source': 'tweet'}, page_content='I have a bad feeling I am going to get deleted :(')}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check the ID of the stored document: Document\n",
        "db.docstore._dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a FAISS VectorStore(from_texts)\n",
        "\n",
        "The `from_texts` class method creates a FAISS vector store using a list of texts and an embedding function.\n",
        "\n",
        "- Parameters:\n",
        "    - `texts` (List[str]): A list of texts to be added to the vector store.\n",
        "    - `embedding` (Embeddings): The embedding function to use.\n",
        "    - `metadatas` (Optional[List[dict]]): A list of metadata. Default is None.\n",
        "    - `ids` (Optional[List[str]]): A list of document IDs. Default is None.\n",
        "    - `**kwargs`: Additional keyword arguments.\n",
        "\n",
        "- How It Works:\n",
        "    1. Texts are embedded using the provided embedding function.\n",
        "    2. The `__from` method is called with the embedded vectors to create a `FAISS` instance.\n",
        "\n",
        "- Return Value:\n",
        "    - `FAISS`: The created FAISS vector store instance.\n",
        "\n",
        "**[Note]**\n",
        "- This method provides a user-friendly interface, handling document embedding, in-memory document storage, and `FAISS` database initialization in a single step.\n",
        "- It’s a convenient way to get started quickly.\n",
        "\n",
        "**[Caution]**\n",
        "- Be mindful of memory usage when processing a large number of texts.\n",
        "- When using metadata or IDs, ensure they are provided as lists with the same length as the text list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'doc1': Document(id='doc1', metadata={'source': 'text document'}, page_content=\"Hello, it's nice to meet you.\"),\n",
              " 'doc2': Document(id='doc2', metadata={'source': 'text document'}, page_content='My name is Teddy.')}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create using a list of strings\n",
        "db2 = FAISS.from_texts(\n",
        "    [\"Hello, it's nice to meet you.\", \"My name is Teddy.\"],\n",
        "    embedding=OpenAIEmbeddings(),\n",
        "    metadatas=[{\"source\": \"text document\"}, {\"source\": \"text document\"}],\n",
        "    ids=[\"doc1\", \"doc2\"],\n",
        ")\n",
        "\n",
        "# Stored content\n",
        "db2.docstore._dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Similarity Search\n",
        "\n",
        "The `similarity_search` method allows you to search for documents most similar to a given query.\n",
        "\n",
        "- Parameters:\n",
        "    - `query` (str): The search query text for finding similar documents.\n",
        "    - `k` (int): The number of documents to return. Default is 4.\n",
        "    - `filter` (Optional[Union[Callable, Dict[str, Any]]]): A metadata filtering function or dictionary. Default is None.\n",
        "    - `fetch_k` (int): The number of documents to retrieve before applying filtering. Default is 20.\n",
        "    - `**kwargs`: Additional keyword arguments.\n",
        "\n",
        "- Returns:\n",
        "    - `List[Document]`: A list of documents most similar to the query.\n",
        "\n",
        "- How It Works:\n",
        "    1. Internally calls the `similarity_search_with_score` method to search for documents along with their similarity scores.\n",
        "    2. Extracts and returns only the documents from the results, excluding the scores.\n",
        "\n",
        "- Key Features:\n",
        "    - The `filter` parameter enables metadata-based filtering.\n",
        "    - The `fetch_k` parameter allows control over the number of documents retrieved before filtering, ensuring enough documents remain after filtering.\n",
        "\n",
        "- Considerations:\n",
        "    - Search performance heavily depends on the quality of the embedding model used.\n",
        "    - In large datasets, it is important to adjust the values of `k` and `fetch_k` to balance search speed and accuracy.\n",
        "    - For complex filtering needs, pass a custom function to the `filter` parameter for fine-grained control.\n",
        "\n",
        "- Optimization Tips:\n",
        "    - Cache the results for frequently used queries to improve the speed of repeated searches.\n",
        "    - Avoid setting `fetch_k` too high, as it may slow down search performance. Experiment to find an appropriate value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(id='77422209-888e-4f2e-b656-85a347ba56f7', metadata={'source': 'tweet'}, page_content='Building an exciting new project with LangChain -'),\n",
              " Document(id='8a089124-0f45-419b-8c96-a8a6aacd5c0f', metadata={'source': 'tweet'}, page_content='LangGraph is the best framework for building'),\n",
              " Document(id='fd6a6f48-eda2-4753-93e9-aacb991b0519', metadata={'source': 'website'}, page_content='Read this review to find out.'),\n",
              " Document(id='e203e4b6-4703-43b3-ac46-b46b9e825c00', metadata={'source': 'tweet'}, page_content='building stateful, agentic applications!')]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Similarity Search\n",
        "db.similarity_search(\"Tell me about the LangChain project.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(id='77422209-888e-4f2e-b656-85a347ba56f7', metadata={'source': 'tweet'}, page_content='Building an exciting new project with LangChain -'),\n",
              " Document(id='8a089124-0f45-419b-8c96-a8a6aacd5c0f', metadata={'source': 'tweet'}, page_content='LangGraph is the best framework for building')]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Specify the value of k (number of documents to return)\n",
        "db.similarity_search(\"Tell me about the LangChain project.\", k=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(id='77422209-888e-4f2e-b656-85a347ba56f7', metadata={'source': 'tweet'}, page_content='Building an exciting new project with LangChain -'),\n",
              " Document(id='8a089124-0f45-419b-8c96-a8a6aacd5c0f', metadata={'source': 'tweet'}, page_content='LangGraph is the best framework for building')]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Use a filter to narrow results based on metadata\n",
        "db.similarity_search(\n",
        "    \"Tell me about the LangChain project.\", filter={\"source\": \"tweet\"}, k=2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Addition Methods\n",
        "The Data Addition Methods describes how to add data to a `FAISS` vector store using either documents or texts. These methods provide flexibility for different input types and allow the user to efficiently populate the vector store.\n",
        "\n",
        "### Add from Document (add_documents)\n",
        "The `add_documents` method allows you to add or update documents in the vector store.\n",
        "\n",
        "- Parameters:\n",
        "    - `documents` (List[Document]): A list of Document objects to be added to the vector store.\n",
        "    - `**kwargs`: Additional keyword arguments.\n",
        "\n",
        "- Return Value:\n",
        "    - `List[str]`: A list of IDs for the added texts.\n",
        "\n",
        "- Functionality:\n",
        "    1. Extracts text content and metadata from the documents.\n",
        "    2. Calls the `add_texts` method to perform the actual addition process.\n",
        "\n",
        "- Key Features:\n",
        "    - Convenient for handling Document objects directly.\n",
        "    - Includes ID handling logic to ensure the uniqueness of the documents.\n",
        "    - Operates based on the `add_texts` method, promoting code reusability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['new_doc1']"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "# Specify page_content and metadata\n",
        "db.add_documents(\n",
        "    [\n",
        "        Document(\n",
        "            page_content=\"Hello! This time, I will add a new document.\",\n",
        "            # Metadata specifying the source of the document\n",
        "            metadata={\"source\": \"mydata.txt\"},\n",
        "        )\n",
        "    ],\n",
        "    # Unique ID for the new document\n",
        "    ids=[\"new_doc1\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(id='new_doc1', metadata={'source': 'mydata.txt'}, page_content='Hello! This time, I will add a new document.')]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Verify the added data by performing a similarity search\n",
        "db.similarity_search(\"hello\", k=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Add from text (add_texts)\n",
        "\n",
        "\n",
        "The `add_texts` method provides the functionality to embed texts and add them to the vector store.\n",
        "\n",
        "\n",
        "- Parameters:\n",
        "    - `texts` (Iterable[str]): An iterable of texts to be added to the vector store.\n",
        "    - `metadatas` (Optional[List[dict]]): A list of metadata associated with the texts (optional).\n",
        "    - `ids` (Optional[List[str]]): A list of unique identifiers for the texts (optional).\n",
        "    - `**kwargs`: Additional keyword arguments.\n",
        "\n",
        "\n",
        "- Return Value:\n",
        "    - `List[str]`: A list of IDs of the texts added to the vector store.\n",
        "\n",
        "\n",
        "- How it works:\n",
        "    1. The input texts iterable is converted into a list.\n",
        "    2. The `_embed_documents` method is used to embed the texts.\n",
        "    3. The `__add` method is called to add the embedded texts to the vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['new_doc2', 'new_doc3']"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Add new text data\n",
        "db.add_texts(\n",
        "    [\n",
        "        \"This time, we're adding text data.\",\n",
        "        \"This is the second text data being added.\",\n",
        "    ],\n",
        "    metadatas=[{\"source\": \"mydata.txt\"}, {\"source\": \"mydata.txt\"}],\n",
        "    ids=[\"new_doc2\", \"new_doc3\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'd7e03a33-c8d5-4139-a9a5-0ee287908e1a',\n",
              " 1: '9a727937-e0af-4003-a3a8-4997f8dddf00',\n",
              " 2: '9eb165f9-ab7a-4a8d-8fc2-547c575d5cf6',\n",
              " 3: 'd8e0189a-17df-4ee4-860c-2c838e404c02',\n",
              " 4: '77422209-888e-4f2e-b656-85a347ba56f7',\n",
              " 5: '557c5ff3-6303-43e3-8919-ac78081e16b8',\n",
              " 6: '43751c22-f479-4ce9-9c92-83b4a6bea494',\n",
              " 7: 'dc2f4d57-fdd9-43c4-b355-4b188a89ce5b',\n",
              " 8: 'f7a3f798-4459-45f0-9064-d91cf31bb466',\n",
              " 9: 'f8cc3819-4f71-4256-9d9a-9b6fba8712c6',\n",
              " 10: 'c5c40a21-ce67-447d-819c-d6971ffcb2d6',\n",
              " 11: 'fd6a6f48-eda2-4753-93e9-aacb991b0519',\n",
              " 12: 'ce25d341-1c44-4a7a-82b1-5d5ff139c137',\n",
              " 13: '8a089124-0f45-419b-8c96-a8a6aacd5c0f',\n",
              " 14: 'e203e4b6-4703-43b3-ac46-b46b9e825c00',\n",
              " 15: 'fa0f3f69-3754-4ccf-8d97-096553677cdc',\n",
              " 16: '02b8f2ad-2aa7-4b26-930b-762ab6b0204e',\n",
              " 17: 'c261874c-5393-4d7c-80a0-e67c5f115fda',\n",
              " 18: 'new_doc1',\n",
              " 19: 'new_doc2',\n",
              " 20: 'new_doc3'}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check the added data\n",
        "db.index_to_docstore_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Delete Documents\n",
        "\n",
        "\n",
        "The `delete` method is used to remove documents from the vector store based on their specified IDs.\n",
        "\n",
        "\n",
        "- Parameters:\n",
        "    - `ids` (Optional[List[str]]): A list of document IDs to delete.\n",
        "    - `**kwargs`: Additional keyword arguments (not utilized in this method).\n",
        "\n",
        "\n",
        "- Return Value:\n",
        "    - `Optional[bool]`: Returns True if the deletion is successful, False if it fails, or None if the functionality is not implemented.\n",
        "\n",
        "\n",
        "- How It Works:\n",
        "    1. Validates the provided IDs.\n",
        "    2, Finds the indices corresponding to the IDs to be deleted.\n",
        "    3. Removes the entries with the given IDs from the `FAISS` index.\n",
        "    4. Deletes the documents associated with the IDs from the document store.\n",
        "    5. Updates the index-to-ID mapping.\n",
        "\n",
        "\n",
        "- Key Features:\n",
        "    - Ensures precise document management using ID-based deletion.\n",
        "    - Performs deletion on both the `FAISS` index and the document store for consistency.\n",
        "    - Maintains data integrity by reordering the index after deletion.\n",
        "\n",
        "\n",
        "- Caution:\n",
        "    - Deletion is irreversible, so it should be done with care.\n",
        "    - The method lacks concurrency control, which requires caution in multi-threaded environments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['delete_doc1', 'delete_doc2']\n"
          ]
        }
      ],
      "source": [
        "# Add data for deletion\n",
        "ids = db.add_texts(\n",
        "    [\"Adding data for deletion.\", \"This is the second data entry for deletion.\"],\n",
        "    metadatas=[{\"source\": \"mydata.txt\"}, {\"source\": \"mydata.txt\"}],\n",
        "    ids=[\"delete_doc1\", \"delete_doc2\"],\n",
        ")\n",
        "\n",
        "# Verify the IDs of the added data\n",
        "print(ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `delete` method can remove documents by providing their IDs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Delete by IDs\n",
        "db.delete(ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'd7e03a33-c8d5-4139-a9a5-0ee287908e1a',\n",
              " 1: '9a727937-e0af-4003-a3a8-4997f8dddf00',\n",
              " 2: '9eb165f9-ab7a-4a8d-8fc2-547c575d5cf6',\n",
              " 3: 'd8e0189a-17df-4ee4-860c-2c838e404c02',\n",
              " 4: '77422209-888e-4f2e-b656-85a347ba56f7',\n",
              " 5: '557c5ff3-6303-43e3-8919-ac78081e16b8',\n",
              " 6: '43751c22-f479-4ce9-9c92-83b4a6bea494',\n",
              " 7: 'dc2f4d57-fdd9-43c4-b355-4b188a89ce5b',\n",
              " 8: 'f7a3f798-4459-45f0-9064-d91cf31bb466',\n",
              " 9: 'f8cc3819-4f71-4256-9d9a-9b6fba8712c6',\n",
              " 10: 'c5c40a21-ce67-447d-819c-d6971ffcb2d6',\n",
              " 11: 'fd6a6f48-eda2-4753-93e9-aacb991b0519',\n",
              " 12: 'ce25d341-1c44-4a7a-82b1-5d5ff139c137',\n",
              " 13: '8a089124-0f45-419b-8c96-a8a6aacd5c0f',\n",
              " 14: 'e203e4b6-4703-43b3-ac46-b46b9e825c00',\n",
              " 15: 'fa0f3f69-3754-4ccf-8d97-096553677cdc',\n",
              " 16: '02b8f2ad-2aa7-4b26-930b-762ab6b0204e',\n",
              " 17: 'c261874c-5393-4d7c-80a0-e67c5f115fda',\n",
              " 18: 'new_doc1',\n",
              " 19: 'new_doc2',\n",
              " 20: 'new_doc3'}"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Output the result after deletion\n",
        "db.index_to_docstore_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Local Persistence\n",
        "\n",
        "\n",
        "### Save Local\n",
        "\n",
        "\n",
        "The `save_local` method enables saving the `FAISS` index, document store, and index-to-document ID mapping to the local disk.\n",
        "\n",
        "\n",
        "- Parameters:\n",
        "    - `folder_path` (str): The folder path where the data will be saved.\n",
        "    - `index_name` (str): The name of the index file to be saved (default: \"index\").\n",
        "\n",
        "\n",
        "- How It Works:\n",
        "    1. Creates the specified folder path (ignored if it already exists).\n",
        "    2. Saves the `FAISS` index as a separate file.\n",
        "    3. Stores the document store and index-to-document ID mapping in pickle format.\n",
        "\n",
        "\n",
        "- Usage Considerations:\n",
        "    - Write permissions are required for the specified save path.\n",
        "    - For large datasets, significant storage space and time may be required.\n",
        "    - Be mindful of potential security risks associated with using pickle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save to local disk\n",
        "db.save_local(folder_path=\"faiss_db\", index_name=\"faiss_index\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Local\n",
        "\n",
        "\n",
        "The `load_local` class method allows loading a `FAISS` index, document store, and index-to-document ID mapping saved on the local disk.\n",
        "\n",
        "\n",
        "- Parameters:\n",
        "    - `folder_path` (str): The folder path where the saved files are located.\n",
        "    - `embeddings` (Embeddings): The embedding object used for generating queries.\n",
        "    - `index_name` (str): The name of the index file to load (default: \"index\").\n",
        "    - `allow_dangerous_deserialization` (bool): Whether to allow deserialization of pickle files (default: False).\n",
        "\n",
        "\n",
        "- Returns:\n",
        "    - `FAISS`: The loaded `FAISS` object.\n",
        "\n",
        "\n",
        "- How It Works:\n",
        "    1. Ensures deserialization risks are considered and requires explicit user permission.\n",
        "    2. Loads the `FAISS` index separately.\n",
        "    3. Uses pickle to deserialize the document store and index-to-document ID mapping.\n",
        "    4. Creates and returns a `FAISS` object using the loaded data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'd7e03a33-c8d5-4139-a9a5-0ee287908e1a',\n",
              " 1: '9a727937-e0af-4003-a3a8-4997f8dddf00',\n",
              " 2: '9eb165f9-ab7a-4a8d-8fc2-547c575d5cf6',\n",
              " 3: 'd8e0189a-17df-4ee4-860c-2c838e404c02',\n",
              " 4: '77422209-888e-4f2e-b656-85a347ba56f7',\n",
              " 5: '557c5ff3-6303-43e3-8919-ac78081e16b8',\n",
              " 6: '43751c22-f479-4ce9-9c92-83b4a6bea494',\n",
              " 7: 'dc2f4d57-fdd9-43c4-b355-4b188a89ce5b',\n",
              " 8: 'f7a3f798-4459-45f0-9064-d91cf31bb466',\n",
              " 9: 'f8cc3819-4f71-4256-9d9a-9b6fba8712c6',\n",
              " 10: 'c5c40a21-ce67-447d-819c-d6971ffcb2d6',\n",
              " 11: 'fd6a6f48-eda2-4753-93e9-aacb991b0519',\n",
              " 12: 'ce25d341-1c44-4a7a-82b1-5d5ff139c137',\n",
              " 13: '8a089124-0f45-419b-8c96-a8a6aacd5c0f',\n",
              " 14: 'e203e4b6-4703-43b3-ac46-b46b9e825c00',\n",
              " 15: 'fa0f3f69-3754-4ccf-8d97-096553677cdc',\n",
              " 16: '02b8f2ad-2aa7-4b26-930b-762ab6b0204e',\n",
              " 17: 'c261874c-5393-4d7c-80a0-e67c5f115fda',\n",
              " 18: 'new_doc1',\n",
              " 19: 'new_doc2',\n",
              " 20: 'new_doc3'}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the saved data\n",
        "loaded_db = FAISS.load_local(\n",
        "    folder_path=\"faiss_db\",\n",
        "    index_name=\"faiss_index\",\n",
        "    embeddings=embeddings,\n",
        "    allow_dangerous_deserialization=True,\n",
        ")\n",
        "\n",
        "# Verify the loaded data\n",
        "loaded_db.index_to_docstore_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## FAISS Object Merge (Merge From)\n",
        "\n",
        "\n",
        "The `merge_from` method allows merging another `FAISS` object into the current `FAISS` object.\n",
        "\n",
        "\n",
        "- Parameters:\n",
        "    - `target` (`FAISS`): The target `FAISS` object to be merged into the current object.\n",
        "\n",
        "\n",
        "- How It Works:\n",
        "    1. Checks if the document stores are compatible for merging.\n",
        "    2. Assigns new indices to the incoming documents based on the length of the existing index.\n",
        "    3. Merges the `FAISS` index.\n",
        "    4. Extracts documents and ID information from the target `FAISS` object.\n",
        "    5. Adds the extracted information to the current document store and index-to-document ID mapping.\n",
        "\n",
        "\n",
        "- Key Features:\n",
        "    - Merges the indices, document stores, and index-to-document ID mappings of two `FAISS` objects.\n",
        "    - Maintains continuity of index numbering during the merge.\n",
        "    - Ensures compatibility of document stores before proceeding with the merge.\n",
        "\n",
        "\n",
        "- Cautions:\n",
        "    - The structure of the target `FAISS` object must be compatible with the current object.\n",
        "    - Be cautious of duplicate IDs, as the current implementation does not check for duplicates.\n",
        "    - If an exception occurs during the merge process, it may leave the system in a partially merged state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'd7e03a33-c8d5-4139-a9a5-0ee287908e1a',\n",
              " 1: '9a727937-e0af-4003-a3a8-4997f8dddf00',\n",
              " 2: '9eb165f9-ab7a-4a8d-8fc2-547c575d5cf6',\n",
              " 3: 'd8e0189a-17df-4ee4-860c-2c838e404c02',\n",
              " 4: '77422209-888e-4f2e-b656-85a347ba56f7',\n",
              " 5: '557c5ff3-6303-43e3-8919-ac78081e16b8',\n",
              " 6: '43751c22-f479-4ce9-9c92-83b4a6bea494',\n",
              " 7: 'dc2f4d57-fdd9-43c4-b355-4b188a89ce5b',\n",
              " 8: 'f7a3f798-4459-45f0-9064-d91cf31bb466',\n",
              " 9: 'f8cc3819-4f71-4256-9d9a-9b6fba8712c6',\n",
              " 10: 'c5c40a21-ce67-447d-819c-d6971ffcb2d6',\n",
              " 11: 'fd6a6f48-eda2-4753-93e9-aacb991b0519',\n",
              " 12: 'ce25d341-1c44-4a7a-82b1-5d5ff139c137',\n",
              " 13: '8a089124-0f45-419b-8c96-a8a6aacd5c0f',\n",
              " 14: 'e203e4b6-4703-43b3-ac46-b46b9e825c00',\n",
              " 15: 'fa0f3f69-3754-4ccf-8d97-096553677cdc',\n",
              " 16: '02b8f2ad-2aa7-4b26-930b-762ab6b0204e',\n",
              " 17: 'c261874c-5393-4d7c-80a0-e67c5f115fda',\n",
              " 18: 'new_doc1',\n",
              " 19: 'new_doc2',\n",
              " 20: 'new_doc3'}"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the saved data\n",
        "db = FAISS.load_local(\n",
        "    folder_path=\"faiss_db\",\n",
        "    index_name=\"faiss_index\",\n",
        "    embeddings=embeddings,\n",
        "    allow_dangerous_deserialization=True,\n",
        ")\n",
        "\n",
        "# Create a new FAISS vector store\n",
        "db2 = FAISS.from_documents(documents=split_documents, embedding=OpenAIEmbeddings())\n",
        "\n",
        "# Check the data in db\n",
        "db.index_to_docstore_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'd49df9e3-dfc6-409b-a4f9-bd6bd39dd9e3',\n",
              " 1: 'bebe6ee4-d20b-4bb6-b158-cb4d57a299da',\n",
              " 2: 'b818c6d2-0cdc-4e27-b0d7-f0785df46d6a',\n",
              " 3: '4e084641-b3d5-4ca9-9dbc-3351b1557d82',\n",
              " 4: 'e1f9d47c-44a9-446a-9099-ded8c035b774',\n",
              " 5: 'fe8dde72-e51b-4a93-86f8-cd89e9a394a5',\n",
              " 6: '5485f7d6-9bc1-4105-910e-02da99121941',\n",
              " 7: '74f01d67-66e8-40ea-b26c-a312c4a0d757',\n",
              " 8: 'eb6966fe-57f8-49ee-8d07-617f661a04cd',\n",
              " 9: 'f82e34df-65e7-450b-ae3a-f722da200b60',\n",
              " 10: '13e95ae8-df7d-4405-8de9-906ec94f3952',\n",
              " 11: 'f75e5201-d3ee-4d9f-987f-b2f8ca38a646',\n",
              " 12: '15ef205e-bfeb-4654-bee7-42ddef7ab7e5',\n",
              " 13: 'e2dcce5a-4cd4-4a93-ab4f-bb03f408e00a',\n",
              " 14: '4763a9c6-41fb-4b13-94bd-516f2262223b',\n",
              " 15: 'edfb52b2-fe9d-48b6-9abf-8e9f998b441e',\n",
              " 16: '9bb69c8c-d73a-4812-9a7a-f610a232894c',\n",
              " 17: 'edcf1a0f-6929-430b-bc60-d588080c3f59'}"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check the data in db2\n",
        "db2.index_to_docstore_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use `merge_from` to combine the two databases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'd7e03a33-c8d5-4139-a9a5-0ee287908e1a',\n",
              " 1: '9a727937-e0af-4003-a3a8-4997f8dddf00',\n",
              " 2: '9eb165f9-ab7a-4a8d-8fc2-547c575d5cf6',\n",
              " 3: 'd8e0189a-17df-4ee4-860c-2c838e404c02',\n",
              " 4: '77422209-888e-4f2e-b656-85a347ba56f7',\n",
              " 5: '557c5ff3-6303-43e3-8919-ac78081e16b8',\n",
              " 6: '43751c22-f479-4ce9-9c92-83b4a6bea494',\n",
              " 7: 'dc2f4d57-fdd9-43c4-b355-4b188a89ce5b',\n",
              " 8: 'f7a3f798-4459-45f0-9064-d91cf31bb466',\n",
              " 9: 'f8cc3819-4f71-4256-9d9a-9b6fba8712c6',\n",
              " 10: 'c5c40a21-ce67-447d-819c-d6971ffcb2d6',\n",
              " 11: 'fd6a6f48-eda2-4753-93e9-aacb991b0519',\n",
              " 12: 'ce25d341-1c44-4a7a-82b1-5d5ff139c137',\n",
              " 13: '8a089124-0f45-419b-8c96-a8a6aacd5c0f',\n",
              " 14: 'e203e4b6-4703-43b3-ac46-b46b9e825c00',\n",
              " 15: 'fa0f3f69-3754-4ccf-8d97-096553677cdc',\n",
              " 16: '02b8f2ad-2aa7-4b26-930b-762ab6b0204e',\n",
              " 17: 'c261874c-5393-4d7c-80a0-e67c5f115fda',\n",
              " 18: 'new_doc1',\n",
              " 19: 'new_doc2',\n",
              " 20: 'new_doc3',\n",
              " 21: 'd49df9e3-dfc6-409b-a4f9-bd6bd39dd9e3',\n",
              " 22: 'bebe6ee4-d20b-4bb6-b158-cb4d57a299da',\n",
              " 23: 'b818c6d2-0cdc-4e27-b0d7-f0785df46d6a',\n",
              " 24: '4e084641-b3d5-4ca9-9dbc-3351b1557d82',\n",
              " 25: 'e1f9d47c-44a9-446a-9099-ded8c035b774',\n",
              " 26: 'fe8dde72-e51b-4a93-86f8-cd89e9a394a5',\n",
              " 27: '5485f7d6-9bc1-4105-910e-02da99121941',\n",
              " 28: '74f01d67-66e8-40ea-b26c-a312c4a0d757',\n",
              " 29: 'eb6966fe-57f8-49ee-8d07-617f661a04cd',\n",
              " 30: 'f82e34df-65e7-450b-ae3a-f722da200b60',\n",
              " 31: '13e95ae8-df7d-4405-8de9-906ec94f3952',\n",
              " 32: 'f75e5201-d3ee-4d9f-987f-b2f8ca38a646',\n",
              " 33: '15ef205e-bfeb-4654-bee7-42ddef7ab7e5',\n",
              " 34: 'e2dcce5a-4cd4-4a93-ab4f-bb03f408e00a',\n",
              " 35: '4763a9c6-41fb-4b13-94bd-516f2262223b',\n",
              " 36: 'edfb52b2-fe9d-48b6-9abf-8e9f998b441e',\n",
              " 37: '9bb69c8c-d73a-4812-9a7a-f610a232894c',\n",
              " 38: 'edcf1a0f-6929-430b-bc60-d588080c3f59'}"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Merge db + db2\n",
        "db.merge_from(db2)\n",
        "\n",
        "# Check the merged data\n",
        "db.index_to_docstore_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Convert to Searcher (as_retriever)\n",
        "\n",
        "\n",
        "The `as_retriever` method creates a `VectorStoreRetriever` object based on the current vector store.\n",
        "\n",
        "\n",
        "- Parameters:\n",
        "    - `**kwargs`: Keyword arguments passed to the search function.\n",
        "    - `search_type` (Optional[str]): Type of search to perform (`\"similarity\"`, `\"mmr\"`, or `\"similarity_score_threshold\"`).\n",
        "    - `search_kwargs` (Optional[Dict]): Additional keyword arguments for the search function.\n",
        "\n",
        "\n",
        "- Return Value:\n",
        "    - `VectorStoreRetriever`: A retriever object based on the vector store.\n",
        "\n",
        "\n",
        "- Key Features:\n",
        "    - Supports Multiple Search Types\n",
        "        - `\"similarity\"`: Default similarity-based search.\n",
        "        - `\"mmr\"`: Maximal Marginal Relevance search.\n",
        "        - `\"similarity_score_threshold\"`: Similarity threshold-based search.\n",
        "    - Customizable Search Parameters\n",
        "        - `k`: Number of documents to return.\n",
        "        - `score_threshold`: Similarity score threshold.\n",
        "        - `fetch_k`: Number of documents fetched for the MMR algorithm.\n",
        "        - `lambda_mult`: Parameter to adjust diversity in `MMR`.\n",
        "        - `filter`: Filter documents based on metadata.\n",
        "\n",
        "\n",
        "- Usage Considerations:\n",
        "    - Choose appropriate search types and parameters to balance the quality and diversity of search results.\n",
        "    - Adjust `fetch_k` and `k` values for large datasets to balance performance and accuracy.\n",
        "    - Use the filter option to search only documents that match specific conditions.\n",
        "\n",
        "\n",
        "- Optimization Tips:\n",
        "    - For `MMR` searches, increase `fetch_k` and adjust `lambda_mult` to balance diversity and relevance.\n",
        "    - Use threshold-based search to return only highly relevant documents.\n",
        "\n",
        "\n",
        "- Cautions:\n",
        "    - Improper parameter settings may impact search performance or result quality.\n",
        "    - High `k` values on large datasets can significantly increase search time. By default, similarity search retrieves 4 documents to ensure manageable results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Will be Update\n",
        "\"\"\"\n",
        "\n",
        "# Create a new FAISS vector store\n",
        "db = FAISS.from_documents(\n",
        "    # Will be Update\n",
        "    documents=split_documents + split_documents,\n",
        "    embedding=OpenAIEmbeddings(),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The default retriever returns 4 documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(id='0a176035-9a36-4cdb-ab70-35306af9b254', metadata={'source': 'website'}, page_content='Is the new iPhone worth the price? Read this'),\n",
              " Document(id='344fc8d3-bf2f-4493-9166-b9a0a0ea0a00', metadata={'source': 'website'}, page_content='Is the new iPhone worth the price? Read this'),\n",
              " Document(id='baab5057-277d-4893-9937-f233cb707eec', metadata={'source': 'website'}, page_content='Read this review to find out.'),\n",
              " Document(id='a294ed5d-dad6-49ed-a718-4888e1b489ce', metadata={'source': 'website'}, page_content='Read this review to find out.')]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert to retriever\n",
        "retriever = db.as_retriever()\n",
        "\n",
        "# Perform search\n",
        "retriever.invoke(\"What can you tell me about iPhones?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Higher diversity with more document retrieval\n",
        "\n",
        "\n",
        "- `k`: The number of documents to return (default: 4)\n",
        "- `fetch_k`: The number of documents to pass to the `MMR` algorithm (default: 20)\n",
        "- `lambda_mult`: Adjusts the diversity of `MMR` results (range: 0 to 1, default: 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(id='0a176035-9a36-4cdb-ab70-35306af9b254', metadata={'source': 'website'}, page_content='Is the new iPhone worth the price? Read this'),\n",
              " Document(id='b3571c49-6256-472b-9ffa-c1f5f733bd2c', metadata={'source': 'tweet'}, page_content='building stateful, agentic applications!'),\n",
              " Document(id='9daebe2f-0bfc-4ebb-bf84-001f040afd85', metadata={'source': 'website'}, page_content='The top 10 soccer players in the world right now.'),\n",
              " Document(id='926d5ce9-6c0b-480e-8278-c69c517af9b6', metadata={'source': 'tweet'}, page_content='- come check it out!'),\n",
              " Document(id='baab5057-277d-4893-9937-f233cb707eec', metadata={'source': 'website'}, page_content='Read this review to find out.'),\n",
              " Document(id='344fc8d3-bf2f-4493-9166-b9a0a0ea0a00', metadata={'source': 'website'}, page_content='Is the new iPhone worth the price? Read this')]"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Perform MMR search\n",
        "retriever = db.as_retriever(\n",
        "    search_type=\"mmr\", search_kwargs={\"k\": 6, \"lambda_mult\": 0.25, \"fetch_k\": 10}\n",
        ")\n",
        "# Invoke search with a query\n",
        "retriever.invoke(\"What can you tell me about iPhones?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fetch more documents for the `MMR` algorithm, but return only the top 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(id='0a176035-9a36-4cdb-ab70-35306af9b254', metadata={'source': 'website'}, page_content='Is the new iPhone worth the price? Read this'),\n",
              " Document(id='b3571c49-6256-472b-9ffa-c1f5f733bd2c', metadata={'source': 'tweet'}, page_content='building stateful, agentic applications!')]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Perform MMR search, return only the top 2 documents\n",
        "retriever = db.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 2, \"fetch_k\": 10})\n",
        "retriever.invoke(\"What can you tell me about iPhones?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Perform search for documents with a similarity score above a certain threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(id='0a176035-9a36-4cdb-ab70-35306af9b254', metadata={'source': 'website'}, page_content='Is the new iPhone worth the price? Read this'),\n",
              " Document(id='344fc8d3-bf2f-4493-9166-b9a0a0ea0a00', metadata={'source': 'website'}, page_content='Is the new iPhone worth the price? Read this')]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Perform threshold-based similarity search\n",
        "retriever = db.as_retriever(\n",
        "    search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.8}\n",
        ")\n",
        "\n",
        "retriever.invoke(\"What can you tell me about iPhones?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Retrieve only the most similar document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(id='0a176035-9a36-4cdb-ab70-35306af9b254', metadata={'source': 'website'}, page_content='Is the new iPhone worth the price? Read this')]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Perform search to retrieve the most similar single document with k=1\n",
        "retriever = db.as_retriever(search_kwargs={\"k\": 1})\n",
        "\n",
        "retriever.invoke(\"What can you tell me about iPhones?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Apply specific metadata filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(id='f9d46fec-ad45-459c-8103-815574b168d6', metadata={'source': 'news'}, page_content='The weather forecast for tomorrow is cloudy and'),\n",
              " Document(id='12d76ef2-5345-4e14-bde3-16870b6de65d', metadata={'source': 'news'}, page_content='The weather forecast for tomorrow is cloudy and')]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Apply filter based on metadata and retrieve top 2 documents\n",
        "retriever = db.as_retriever(search_kwargs={\"filter\": {\"source\": \"news\"}, \"k\": 2})\n",
        "retriever.invoke(\"What is the weather forecast for tomorrow?\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "langchain-opentutorial-fOxWcZdD-py3.11",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
