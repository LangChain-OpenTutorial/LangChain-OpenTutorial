Query: What is the definition of an agent in Generative AI?
Result: [Document(id='3df12b17-61eb-460f-b7ef-e5d3b978be93', metadata={'source': './data/Newwhitepaper_Agents2.pdf', 'file_path': './data/Newwhitepaper_Agents2.pdf', 'page': 4, 'total_pages': 42, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 20.0 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': "D:20241113100853-07'00'", 'modDate': "D:20241113100858-07'00'", 'trapped': ''}, page_content='Agents\n5\nSeptember 2024\nWhat is an agent?\nIn its most fundamental form, a Generative AI agent can be defined as an application that \nattempts to achieve a goal by observing the world and acting upon it using the tools that it \nhas at its disposal. Agents are autonomous and can act independently of human intervention, \nespecially when provided with proper goals or objectives they are meant to achieve. Agents \ncan also be proactive in their approach to reaching their goals. Even in the absence of'), Document(id='95248484-0c19-4d75-963d-5f55fe36d3f8', metadata={'source': './data/Newwhitepaper_Agents2.pdf', 'file_path': './data/Newwhitepaper_Agents2.pdf', 'page': 39, 'total_pages': 42, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 20.0 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': "D:20241113100853-07'00'", 'modDate': "D:20241113100858-07'00'", 'trapped': ''}, page_content='Agents\n40\nSeptember 2024\nSummary\nIn this whitepaper we’ve discussed the foundational building blocks of Generative AI \nagents, their compositions, and effective ways to implement them in the form of cognitive \narchitectures. Some key takeaways from this whitepaper include:\n1.\t Agents extend the capabilities of language models by leveraging tools to access real-\ntime information, suggest real-world actions, and plan and execute complex tasks'), Document(id='599b8a5b-9493-4f31-b6cb-5ee80bf2eeae', metadata={'source': './data/Newwhitepaper_Agents2.pdf', 'file_path': './data/Newwhitepaper_Agents2.pdf', 'page': 3, 'total_pages': 42, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 20.0 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': "D:20241113100853-07'00'", 'modDate': "D:20241113100858-07'00'", 'trapped': ''}, page_content="Agents\n4\nSeptember 2024\nIntroduction\nHumans are fantastic at messy pattern recognition tasks. However, they often rely on tools \n- like books, Google Search, or a calculator - to supplement their prior knowledge before \narriving at a conclusion. Just like humans, Generative AI models can be trained to use tools \nto access real-time information or suggest a real-world action. For example, a model can \nleverage a database retrieval tool to access specific information, like a customer's purchase"), Document(id='a3e8f15a-7a71-43e4-a759-a157df42e190', metadata={'source': './data/Newwhitepaper_Agents2.pdf', 'file_path': './data/Newwhitepaper_Agents2.pdf', 'page': 3, 'total_pages': 42, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 20.0 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': "D:20241113100853-07'00'", 'modDate': "D:20241113100858-07'00'", 'trapped': ''}, page_content='that are all connected to a Generative AI model invokes the concept of an agent, or a \nprogram that extends beyond the standalone capabilities of a Generative AI model. This \nwhitepaper dives into all these and associated aspects in more detail.\nThis combination of reasoning, \nlogic, and access to external \ninformation that are all connected \nto a Generative AI model invokes \nthe concept of an agent.')]

Query: What are the key components of an agent's cognitive architecture?
Result: [Document(id='14aab5d5-9b98-4aae-a63c-0eca9b141025', metadata={'source': './data/Newwhitepaper_Agents2.pdf', 'file_path': './data/Newwhitepaper_Agents2.pdf', 'page': 4, 'total_pages': 42, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 20.0 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': "D:20241113100853-07'00'", 'modDate': "D:20241113100858-07'00'", 'trapped': ''}, page_content='components that drive the agent’s behavior, actions, and decision making. The combination \nof these components can be described as a cognitive architecture, and there are many \nsuch architectures that can be achieved by the mixing and matching of these components. \nFocusing on the core functionalities, there are three essential components in an agent’s \ncognitive architecture as shown in Figure 1.'), Document(id='5429915b-1af2-4d63-85da-3a6c0e3e5930', metadata={'source': './data/Newwhitepaper_Agents2.pdf', 'file_path': './data/Newwhitepaper_Agents2.pdf', 'page': 6, 'total_pages': 42, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 20.0 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': "D:20241113100853-07'00'", 'modDate': "D:20241113100858-07'00'", 'trapped': ''}, page_content='implementation of the agent orchestration layers in the cognitive architecture section.'), Document(id='cb9c9a92-5601-4053-8d22-4289680d464a', metadata={'source': './data/Newwhitepaper_Agents2.pdf', 'file_path': './data/Newwhitepaper_Agents2.pdf', 'page': 8, 'total_pages': 42, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 20.0 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': "D:20241113100853-07'00'", 'modDate': "D:20241113100858-07'00'", 'trapped': ''}, page_content='ingredients are depleted or customer feedback is received, and uses the set of previous \noutcomes to determine the next plan of action. This cycle of information intake, planning, \nexecuting, and adjusting describes a unique cognitive architecture that the chef employs to \nreach their goal.\nJust like the chef, agents can use cognitive architectures to reach their end goals by \niteratively processing information, making informed decisions, and refining next actions'), Document(id='268f847d-3b5b-479b-afb8-0faeb79ec384', metadata={'source': './data/Newwhitepaper_Agents2.pdf', 'file_path': './data/Newwhitepaper_Agents2.pdf', 'page': 8, 'total_pages': 42, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 20.0 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': "D:20241113100853-07'00'", 'modDate': "D:20241113100858-07'00'", 'trapped': ''}, page_content='based on previous outputs. At the core of agent cognitive architectures lies the orchestration \nlayer, responsible for maintaining memory, state, reasoning and planning. It uses the rapidly \nevolving field of prompt engineering and associated frameworks to guide reasoning and \nplanning, enabling the agent to interact more effectively with its environment and complete \ntasks. Research in the area of prompt engineering frameworks and task planning for')]

Query: How does the ReAct framework function in agent reasoning?
Result: [Document(id='9a2e0ea1-e40e-4509-9abb-95c5f528ebbf', metadata={'source': './data/Newwhitepaper_Agents2.pdf', 'file_path': './data/Newwhitepaper_Agents2.pdf', 'page': 9, 'total_pages': 42, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 20.0 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': "D:20241113100853-07'00'", 'modDate': "D:20241113100858-07'00'", 'trapped': ''}, page_content='that is programmed to use the ReAct framework to choose the correct actions and tools for \nthe user query. The sequence of events might go something like this:\n1.\t User sends query to the agent\n2.\t Agent begins the ReAct sequence\n3.\t The agent provides a prompt to the model, asking it to generate one of the next ReAct \nsteps and its corresponding output:\na.\t Question: The input question from the user query, provided with the prompt\nb.\t Thought: The model’s thoughts about what it should do next'), Document(id='3305d7ae-6422-4e55-8fba-2e69a22d22ee', metadata={'source': './data/Newwhitepaper_Agents2.pdf', 'file_path': './data/Newwhitepaper_Agents2.pdf', 'page': 41, 'total_pages': 42, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 20.0 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': "D:20241113100853-07'00'", 'modDate': "D:20241113100858-07'00'", 'trapped': ''}, page_content="Agents\n42\nSeptember 2024\nEndnotes\n1.\t Shafran, I., Cao, Y. et al., 2022, 'ReAct: Synergizing Reasoning and Acting in Language Models'. Available at: \nhttps://arxiv.org/abs/2210.03629\n2.\t Wei, J., Wang, X. et al., 2023, 'Chain-of-Thought Prompting Elicits Reasoning in Large Language Models'. \nAvailable at: https://arxiv.org/pdf/2201.11903.pdf.\n3.\t Wang, X. et al., 2022, 'Self-Consistency Improves Chain of Thought Reasoning in Language Models'. \nAvailable at: https://arxiv.org/abs/2203.11171."), Document(id='f4280f51-e109-48f3-a236-9f8c62facba3', metadata={'source': './data/Newwhitepaper_Agents2.pdf', 'file_path': './data/Newwhitepaper_Agents2.pdf', 'page': 10, 'total_pages': 42, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 20.0 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': "D:20241113100853-07'00'", 'modDate': "D:20241113100858-07'00'", 'trapped': ''}, page_content='Agents\n11\nSeptember 2024\nd.\t Action input: The model’s decision on what inputs to provide to the tool (if any)\ne.\t Observation: The result of the action / action input sequence\ni.\t This thought / action / action input / observation could repeat N-times as needed\nf.\t Final answer: The model’s final answer to provide to the original user query\n4.\t The ReAct loop concludes and a final answer is provided back to the user\nFigure 2. Example agent with ReAct reasoning in the orchestration layer'), Document(id='4e9bfe85-40e4-4fc8-a67f-4187be03ad47', metadata={'source': './data/Newwhitepaper_Agents2.pdf', 'file_path': './data/Newwhitepaper_Agents2.pdf', 'page': 39, 'total_pages': 42, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 20.0 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': "D:20241113100853-07'00'", 'modDate': "D:20241113100858-07'00'", 'trapped': ''}, page_content='techniques such as ReAct, Chain-of-Thought, and Tree-of-Thoughts, provide a framework \nfor the orchestration layer to take in information, perform internal reasoning, and generate \ninformed decisions or responses. \n3.\t Tools, such as Extensions, Functions, and Data Stores, serve as the keys to the outside \nworld for agents, allowing them to interact with external systems and access knowledge \nbeyond their training data. Extensions provide a bridge between agents and external APIs,')]

Query: What are the differences between Extensions and Functions in agent tools?
Result: [Document(id='6b98d63a-5b4b-4811-9ce9-99248adc65f8', metadata={'source': './data/Newwhitepaper_Agents2.pdf', 'file_path': './data/Newwhitepaper_Agents2.pdf', 'page': 17, 'total_pages': 42, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 20.0 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': "D:20241113100853-07'00'", 'modDate': "D:20241113100858-07'00'", 'trapped': ''}, page_content='differ from Extensions in a few ways, most notably:\n1.\t A model outputs a Function and its arguments, but doesn’t make a live API call.\n2.\t Functions are executed on the client-side, while Extensions are executed on \nthe agent-side.\nUsing our Google Flights example again, a simple setup for functions might look like the \nexample in Figure 7.'), Document(id='45fb3da9-68d9-40e8-8710-5da03f5d2b88', metadata={'source': './data/Newwhitepaper_Agents2.pdf', 'file_path': './data/Newwhitepaper_Agents2.pdf', 'page': 31, 'total_pages': 42, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 20.0 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': "D:20241113100853-07'00'", 'modDate': "D:20241113100858-07'00'", 'trapped': ''}, page_content='Agents\n32\nSeptember 2024\nTools recap\nTo summarize, extensions, functions and data stores make up a few different tool types \navailable for agents to use at runtime. Each has their own purpose and they can be used \ntogether or independently at the discretion of the agent developer. \nExtensions\nFunction Calling\nData Stores\nExecution\nAgent-Side Execution\nClient-Side Execution\nAgent-Side Execution\nUse Case\n•\t Developer wants \nagent to control \ninteractions with the \nAPI endpoints\n•\t Useful when'), Document(id='fa7ec561-d5f5-4b7d-97f3-2c9a60d77d56', metadata={'source': './data/Newwhitepaper_Agents2.pdf', 'file_path': './data/Newwhitepaper_Agents2.pdf', 'page': 18, 'total_pages': 42, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 20.0 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': "D:20241113100853-07'00'", 'modDate': "D:20241113100858-07'00'", 'trapped': ''}, page_content='This offers the developer more granular control over the flow of data in the application. There \nare many reasons why a Developer might choose to use functions over Extensions, but a few \ncommon use cases are:\n•\t API calls need to be made at another layer of the application stack, outside of the direct \nagent architecture flow (e.g. a middleware system, a front end framework, etc.)\n•\t Security or Authentication restrictions that prevent the agent from calling an API directly'), Document(id='0192f617-99cf-4ac6-9553-2b3e7ee65bdb', metadata={'source': './data/Newwhitepaper_Agents2.pdf', 'file_path': './data/Newwhitepaper_Agents2.pdf', 'page': 17, 'total_pages': 42, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 20.0 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': "D:20241113100853-07'00'", 'modDate': "D:20241113100858-07'00'", 'trapped': ''}, page_content='Agents\n18\nSeptember 2024\nTo summarize, Extensions provide a way for agents to perceive, interact, and influence the \noutside world in a myriad of ways. The selection and invocation of these Extensions is guided \nby the use of Examples, all of which are defined as part of the Extension configuration.\nFunctions \nIn the world of software engineering, functions are defined as self-contained modules \nof code that accomplish a specific task and can be reused as needed. When a software')]

Query: How do agents use Data Stores to enhance their knowledge?
Result: [Document(id='dd02b4b5-0a8c-41cd-974b-510c4c898d81', metadata={'source': './data/Newwhitepaper_Agents2.pdf', 'file_path': './data/Newwhitepaper_Agents2.pdf', 'page': 27, 'total_pages': 42, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 20.0 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': "D:20241113100853-07'00'", 'modDate': "D:20241113100858-07'00'", 'trapped': ''}, page_content='Agents\n28\nSeptember 2024\nData Stores allow developers to provide additional data in its original format to an agent, \neliminating the need for time-consuming data transformations, model retraining, or fine-\ntuning. The Data Store converts the incoming document into a set of vector database \nembeddings that the agent can use to extract the information it needs to supplement its next \naction or response to the user.'), Document(id='3f6df18c-246d-4b5a-a10a-d7e8a152b74e', metadata={'source': './data/Newwhitepaper_Agents2.pdf', 'file_path': './data/Newwhitepaper_Agents2.pdf', 'page': 26, 'total_pages': 42, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 20.0 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': "D:20241113100853-07'00'", 'modDate': "D:20241113100858-07'00'", 'trapped': ''}, page_content='Agents\n27\nSeptember 2024\nData stores\nImagine a language model as a vast library of books, containing its training data. But unlike \na library that continuously acquires new volumes, this one remains static, holding only the \nknowledge it was initially trained on. This presents a challenge, as real-world knowledge is \nconstantly evolving. Data Stores address this limitation by providing access to more dynamic'), Document(id='9b840890-1d54-4602-a795-42751585f324', metadata={'source': './data/Newwhitepaper_Agents2.pdf', 'file_path': './data/Newwhitepaper_Agents2.pdf', 'page': 27, 'total_pages': 42, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 20.0 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': "D:20241113100853-07'00'", 'modDate': "D:20241113100858-07'00'", 'trapped': ''}, page_content='action or response to the user.\nFigure 11. Data Stores connect Agents to new real-time data sources of various types.\nImplementation and application\nIn the context of Generative AI agents, Data Stores are typically implemented as a vector \ndatabase that the developer wants the agent to have access to at runtime. While we won’t \ncover vector databases in depth here, the key point to understand is that they store data'), Document(id='d333edbf-c179-4785-98f6-de64e1f27701', metadata={'source': './data/Newwhitepaper_Agents2.pdf', 'file_path': './data/Newwhitepaper_Agents2.pdf', 'page': 39, 'total_pages': 42, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 20.0 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': "D:20241113100853-07'00'", 'modDate': "D:20241113100858-07'00'", 'trapped': ''}, page_content='enabling the execution of API calls and retrieval of real-time information. functions provide \na more nuanced control for the developer through the division of labor, allowing agents \nto generate Function parameters which can be executed client-side. Data Stores provide \nagents with access to structured or unstructured data, enabling data-driven applications.\nThe future of agents holds exciting advancements and we’ve only begun to scratch the')]

Query: What are the advantages of using Tree-of-Thoughts reasoning for agents?
Result: [Document(id='4e9bfe85-40e4-4fc8-a67f-4187be03ad47', metadata={'source': './data/Newwhitepaper_Agents2.pdf', 'file_path': './data/Newwhitepaper_Agents2.pdf', 'page': 39, 'total_pages': 42, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 20.0 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': "D:20241113100853-07'00'", 'modDate': "D:20241113100858-07'00'", 'trapped': ''}, page_content='techniques such as ReAct, Chain-of-Thought, and Tree-of-Thoughts, provide a framework \nfor the orchestration layer to take in information, perform internal reasoning, and generate \ninformed decisions or responses. \n3.\t Tools, such as Extensions, Functions, and Data Stores, serve as the keys to the outside \nworld for agents, allowing them to interact with external systems and access knowledge \nbeyond their training data. Extensions provide a bridge between agents and external APIs,'), Document(id='407ac60a-a4d3-459b-b14c-b2866f2b1a65', metadata={'source': './data/Newwhitepaper_Agents2.pdf', 'file_path': './data/Newwhitepaper_Agents2.pdf', 'page': 9, 'total_pages': 42, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 20.0 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': "D:20241113100853-07'00'", 'modDate': "D:20241113100858-07'00'", 'trapped': ''}, page_content='exploration or strategic lookahead tasks. It generalizes over chain-of-thought prompting \nand allows the model to explore various thought chains that serve as intermediate steps \nfor general problem solving with language models.\nAgents can utilize one of the above reasoning techniques, or many other techniques, to \nchoose the next best action for the given user request. For example, let’s consider an agent'), Document(id='0c715dc2-e86e-43f2-aa24-6b0e97f281dd', metadata={'source': './data/Newwhitepaper_Agents2.pdf', 'file_path': './data/Newwhitepaper_Agents2.pdf', 'page': 5, 'total_pages': 42, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 20.0 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': "D:20241113100853-07'00'", 'modDate': "D:20241113100858-07'00'", 'trapped': ''}, page_content='reasoning setup) of the agent. However, it’s possible to further refine the model for the \nagent’s tasks by providing it with examples that showcase the agent’s capabilities, including \ninstances of the agent using specific tools or reasoning steps in various contexts.'), Document(id='5bad6ca6-47bf-498e-a5a6-fb324e0e6018', metadata={'source': './data/Newwhitepaper_Agents2.pdf', 'file_path': './data/Newwhitepaper_Agents2.pdf', 'page': 9, 'total_pages': 42, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 20.0 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': "D:20241113100853-07'00'", 'modDate': "D:20241113100858-07'00'", 'trapped': ''}, page_content='Agents\n10\nSeptember 2024\n•\t Chain-of-Thought (CoT), a prompt engineering framework that enables reasoning \ncapabilities through intermediate steps. There are various sub-techniques of CoT including \nself-consistency, active-prompt, and multimodal CoT that each have strengths and \nweaknesses depending on the specific application.\n•\t Tree-of-thoughts (ToT),, a prompt engineering framework that is well suited for')]

Query: How do LangChain-based agents utilize external tools?
Result: [Document(id='d6016df5-0c0a-4e28-884d-142eaf7a1afd', metadata={'source': './data/Newwhitepaper_Agents2.pdf', 'file_path': './data/Newwhitepaper_Agents2.pdf', 'page': 34, 'total_pages': 42, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 20.0 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': "D:20241113100853-07'00'", 'modDate': "D:20241113100858-07'00'", 'trapped': ''}, page_content='Agents\n35\nSeptember 2024\nAgent quick start with LangChain\nIn order to provide a real-world executable example of an agent in action, we’ll build a quick \nprototype with the LangChain and LangGraph libraries. These popular open source libraries \nallow users to build customer agents by “chaining” together sequences of logic, reasoning, \nand tool calls to answer a user’s query. We’ll use our gemini-1.5-flash-001 model and'), Document(id='4e9bfe85-40e4-4fc8-a67f-4187be03ad47', metadata={'source': './data/Newwhitepaper_Agents2.pdf', 'file_path': './data/Newwhitepaper_Agents2.pdf', 'page': 39, 'total_pages': 42, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 20.0 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': "D:20241113100853-07'00'", 'modDate': "D:20241113100858-07'00'", 'trapped': ''}, page_content='techniques such as ReAct, Chain-of-Thought, and Tree-of-Thoughts, provide a framework \nfor the orchestration layer to take in information, perform internal reasoning, and generate \ninformed decisions or responses. \n3.\t Tools, such as Extensions, Functions, and Data Stores, serve as the keys to the outside \nworld for agents, allowing them to interact with external systems and access knowledge \nbeyond their training data. Extensions provide a bridge between agents and external APIs,'), Document(id='591eb8e2-81bf-4750-8c84-78973b67726a', metadata={'source': './data/Newwhitepaper_Agents2.pdf', 'file_path': './data/Newwhitepaper_Agents2.pdf', 'page': 2, 'total_pages': 42, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 20.0 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': "D:20241113100853-07'00'", 'modDate': "D:20241113100858-07'00'", 'trapped': ''}, page_content='33\nAgent quick start with LangChain\x08\n35\nProduction applications with Vertex AI agents\x08\n38\nSummary\x08\n40\nEndnotes\x08\n42\nTable of contents'), Document(id='12f88d65-fdc3-4dc8-b179-4fa07a46ebf3', metadata={'source': './data/Newwhitepaper_Agents2.pdf', 'file_path': './data/Newwhitepaper_Agents2.pdf', 'page': 6, 'total_pages': 42, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 20.0 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': "D:20241113100853-07'00'", 'modDate': "D:20241113100858-07'00'", 'trapped': ''}, page_content='Agents\n7\nSeptember 2024\nThe tools\nFoundational models, despite their impressive text and image generation, remain constrained \nby their inability to interact with the outside world. Tools bridge this gap, empowering agents \nto interact with external data and services while unlocking a wider range of actions beyond \nthat of the underlying model alone. Tools can take a variety of forms and have varying \ndepths of complexity, but typically align with common web API methods like GET, POST,')]

Query: What is the purpose of the orchestration layer in an agent's architecture?
Result: [Document(id='5429915b-1af2-4d63-85da-3a6c0e3e5930', metadata={'source': './data/Newwhitepaper_Agents2.pdf', 'file_path': './data/Newwhitepaper_Agents2.pdf', 'page': 6, 'total_pages': 42, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 20.0 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': "D:20241113100853-07'00'", 'modDate': "D:20241113100858-07'00'", 'trapped': ''}, page_content='implementation of the agent orchestration layers in the cognitive architecture section.'), Document(id='1fbc7180-c905-47fc-b888-b19014001076', metadata={'source': './data/Newwhitepaper_Agents2.pdf', 'file_path': './data/Newwhitepaper_Agents2.pdf', 'page': 6, 'total_pages': 42, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 20.0 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': "D:20241113100853-07'00'", 'modDate': "D:20241113100858-07'00'", 'trapped': ''}, page_content='achieve on its own. We’ll discuss tools in more detail below, but the most important thing \nto understand is that tools bridge the gap between the agent’s internal capabilities and the \nexternal world, unlocking a broader range of possibilities.\nThe orchestration layer\nThe orchestration layer describes a cyclical process that governs how the agent takes in \ninformation, performs some internal reasoning, and uses that reasoning to inform its next'), Document(id='aac82f88-055c-40b8-bced-e60d3cbc016f', metadata={'source': './data/Newwhitepaper_Agents2.pdf', 'file_path': './data/Newwhitepaper_Agents2.pdf', 'page': 39, 'total_pages': 42, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 20.0 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': "D:20241113100853-07'00'", 'modDate': "D:20241113100858-07'00'", 'trapped': ''}, page_content='autonomously. agents can leverage one or more language models to decide when and \nhow to transition through states and use external tools to complete any number of \ncomplex tasks that would be difficult or impossible for the model to complete on its own.\n2.\t At the heart of an agent’s operation is the orchestration layer, a cognitive architecture that \nstructures reasoning, planning, decision-making and guides its actions. Various reasoning'), Document(id='4e9bfe85-40e4-4fc8-a67f-4187be03ad47', metadata={'source': './data/Newwhitepaper_Agents2.pdf', 'file_path': './data/Newwhitepaper_Agents2.pdf', 'page': 39, 'total_pages': 42, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 20.0 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': "D:20241113100853-07'00'", 'modDate': "D:20241113100858-07'00'", 'trapped': ''}, page_content='techniques such as ReAct, Chain-of-Thought, and Tree-of-Thoughts, provide a framework \nfor the orchestration layer to take in information, perform internal reasoning, and generate \ninformed decisions or responses. \n3.\t Tools, such as Extensions, Functions, and Data Stores, serve as the keys to the outside \nworld for agents, allowing them to interact with external systems and access knowledge \nbeyond their training data. Extensions provide a bridge between agents and external APIs,')]

Query: What are the primary use cases for Retrieval Augmented Generation (RAG) in agents?
Result: [Document(id='ca921519-b422-4daf-99ba-044a382a75f4', metadata={'source': './data/Newwhitepaper_Agents2.pdf', 'file_path': './data/Newwhitepaper_Agents2.pdf', 'page': 31, 'total_pages': 42, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 20.0 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': "D:20241113100853-07'00'", 'modDate': "D:20241113100858-07'00'", 'trapped': ''}, page_content='in real-time. (i.e. batch \noperations, human-in-\nthe-loop review, etc.)\n•\t API that is not exposed \nto the internet, or \nnon-accessible by \nGoogle systems\nDeveloper wants to \nimplement Retrieval \nAugmented Generation \n(RAG) with any of the \nfollowing data types:\n•\t Website Content from \npre-indexed domains \nand URLs\n•\t Structured Data in \nformats like PDF, \nWord Docs, CSV, \nSpreadsheets, etc.\n•\t Relational / Non- \nRelational Databases\n•\t Unstructured Data in \nformats like HTML, PDF, \nTXT, etc.'), Document(id='68ef5cbc-c90d-4616-9a07-0bc4de49299e', metadata={'source': './data/Newwhitepaper_Agents2.pdf', 'file_path': './data/Newwhitepaper_Agents2.pdf', 'page': 28, 'total_pages': 42, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 20.0 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': "D:20241113100853-07'00'", 'modDate': "D:20241113100858-07'00'", 'trapped': ''}, page_content='Agents\n29\nSeptember 2024\nGeneration (RAG) based applications. These applications seek to extend the breadth and \ndepth of a model’s knowledge beyond the foundational training data by giving the model \naccess to data in various formats like:\n•\t Website content\n•\t Structured Data in formats like PDF, Word Docs, CSV, Spreadsheets, etc.\n•\t Unstructured Data in formats like HTML, PDF, TXT, etc.\nFigure 12. 1-to-many relationship between agents and data stores, which can represent various types of'), Document(id='21b2df61-8e2d-4216-8d7b-d047b0db0cbb', metadata={'source': './data/Newwhitepaper_Agents2.pdf', 'file_path': './data/Newwhitepaper_Agents2.pdf', 'page': 29, 'total_pages': 42, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 20.0 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': "D:20241113100853-07'00'", 'modDate': "D:20241113100858-07'00'", 'trapped': ''}, page_content='the user, or perform an additional vector search to further refine the results.\nA sample interaction with an agent that implements RAG with ReAct reasoning/planning can \nbe seen in Figure 14.'), Document(id='ea28e3a7-b4b1-4f0b-add0-e5a6ad814360', metadata={'source': './data/Newwhitepaper_Agents2.pdf', 'file_path': './data/Newwhitepaper_Agents2.pdf', 'page': 6, 'total_pages': 42, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 20.0 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': "D:20241113100853-07'00'", 'modDate': "D:20241113100858-07'00'", 'trapped': ''}, page_content='PATCH, and DELETE. For example, a tool could update customer information in a database \nor fetch weather data to influence a travel recommendation that the agent is providing to \nthe user. With tools, agents can access and process real-world information. This empowers \nthem to support more specialized systems like retrieval augmented generation (RAG), \nwhich significantly extends an agent’s capabilities beyond what the foundational model can')]

Query: How do agents connect with external APIs through Extensions?
Result: [Document(id='62a07a05-64a2-4b4a-b672-78dd6af5898d', metadata={'source': './data/Newwhitepaper_Agents2.pdf', 'file_path': './data/Newwhitepaper_Agents2.pdf', 'page': 13, 'total_pages': 42, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 20.0 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': "D:20241113100853-07'00'", 'modDate': "D:20241113100858-07'00'", 'trapped': ''}, page_content='Agents\n14\nSeptember 2024\nA more resilient approach would be to use an Extension. An Extension bridges the gap \nbetween an agent and an API by:\n1.\t Teaching the agent how to use the API endpoint using examples.\n2.\t Teaching the agent what arguments or parameters are needed to successfully call the \nAPI endpoint.\nFigure 4. Extensions connect Agents to External APIs\nExtensions can be crafted independently of the agent, but should be provided as part of the'), Document(id='ef1a26e6-ebf7-485e-adb4-573070ff8e04', metadata={'source': './data/Newwhitepaper_Agents2.pdf', 'file_path': './data/Newwhitepaper_Agents2.pdf', 'page': 12, 'total_pages': 42, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 20.0 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': "D:20241113100853-07'00'", 'modDate': "D:20241113100858-07'00'", 'trapped': ''}, page_content='Agents\n13\nSeptember 2024\nExtensions \nThe easiest way to understand Extensions is to think of them as bridging the gap between \nan API and an agent in a standardized way, allowing agents to seamlessly execute APIs \nregardless of their underlying implementation. Let’s say that you’ve built an agent with a goal \nof helping users book flights. You know that you want to use the Google Flights API to retrieve'), Document(id='1a3a3a23-e5a0-44a9-9409-b7242ea47fe7', metadata={'source': './data/Newwhitepaper_Agents2.pdf', 'file_path': './data/Newwhitepaper_Agents2.pdf', 'page': 14, 'total_pages': 42, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 20.0 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': "D:20241113100853-07'00'", 'modDate': "D:20241113100858-07'00'", 'trapped': ''}, page_content='Agents\n15\nSeptember 2024\nThink of this the same way that a software developer decides which API endpoints to use \nwhile solving and solutioning for a user’s problem. If the user wants to book a flight, the \ndeveloper might use the Google Flights API. If the user wants to know where the nearest \ncoffee shop is relative to their location, the developer might use the Google Maps API. In \nthis same way, the agent / model stack uses a set of known Extensions to decide which one'), Document(id='a09a23ee-0d88-44b2-bde8-be2ad9314fc2', metadata={'source': './data/Newwhitepaper_Agents2.pdf', 'file_path': './data/Newwhitepaper_Agents2.pdf', 'page': 13, 'total_pages': 42, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 20.0 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': "D:20241113100853-07'00'", 'modDate': "D:20241113100858-07'00'", 'trapped': ''}, page_content='agent’s configuration. The agent uses the model and examples at run time to decide which \nExtension, if any, would be suitable for solving the user’s query. This highlights a key strength \nof Extensions, their built-in example types, that allow the agent to dynamically select the \nmost appropriate Extension for the task. \n \nFigure 5. 1-to-many relationship between Agents, Extensions and APIs')]

